## **Chapter 7. Continuous Probability Distribution**

Higher category: ã€Statisticsã€‘ [Statistics Overview](https://jb243.github.io/pages/1641)

---

**1.** [Uniform distribution](#1-uniform-distribution)

**2.** [Normal distribution](#2-normal-distribution)Â 

**3.** [Gamma distribution](#3-gamma-distribution)Â 

**4.** [Exponential distribution](#4-exponential-distribution)

**5.** [Beta distribution](#5-beta-distribution)Â 

**6.** [Pareto distribution](#6-pareto-distribution)Â 

**7.** [Logistic distribution](#7-logistic-distribution)

**8.** [Dirichlet distribution](#8-dirichlet-distribution)

**9.** [Gumbel model](#9-gumbel-model)

---

<br>

![image](https://github.com/user-attachments/assets/29f38641-ca88-41b5-8f1f-b734cfa6448e)

<br>

## **1\. Uniform distribution**

â‘´ definition: probability distribution with a constant probability for all random variables

â‘µ probability density function**:** X ~ u\[a, b\], p(x) = 1 / (b - a) _I_ï½›a â‰¤ x â‰¤ bï½Â 

<br>

<img width="402" height="404" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 24 43" src="https://github.com/user-attachments/assets/ff36838e-5b5c-4f7d-8124-5d3e7e1a703d" />

<br>
<b>Figure 1.</b> graph of x - p(x) on X ~ u[1, 9]

<br>

> â‘  Python programming**:**Â Bokeh is used for web-page visualizationÂ 

<br>

```python
from bokeh.plotting import figure, output_file, show

output_file("uniform_distribution.html")
p = figure(width=400, height=400, title = "Uniform Distribution", 
           tooltips=[("x", "$x"), ("y", "$y")])
p.line([1, 2, 3, 4, 5, 6, 7, 8, 9], [1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8], 
       line_width=2)
show(p)
```

<br>

â‘¶ statistics

> â‘  moment generating function

<br>

![image](https://github.com/user-attachments/assets/365c4287-5c4e-49f2-93eb-b2c64b75659f)

<br>

> â‘¡ average: E(X) = (a + b) / 2

<br>

![image](https://github.com/user-attachments/assets/06d38699-ac27-4269-b636-2ae10529fc66)

<br>

> â‘¢ Variance**:**Â VAR(X) = (b - a)2 / 12

<br>

![image](https://github.com/user-attachments/assets/66f36474-f4e1-4ee6-b7ca-b513e6e97fd5)

<br>

> â‘£ marginal probability distribution has the meaning of length Ã· total area

â‘· Example

> â‘  [Example problems for uniform distribution](https://blog.kakaocdn.net/dn/bW64At/btsLK2kduoI/UYGuCu9Qq3rJWkScbVfMxk/%E1%84%80%E1%85%B2%E1%86%AB%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9%2016%E1%84%8C%E1%85%A6.pdf?attach=1&knm=tfile.pdf)

> â‘¡ [Example problems for joint uniform distribution](https://blog.kakaocdn.net/dn/bjacE2/btsLKb91CRK/T6xKqoHCrhydQK1kMtnURK/%E1%84%80%E1%85%A7%E1%86%AF%E1%84%92%E1%85%A1%E1%86%B8%E1%84%80%E1%85%B2%E1%86%AB%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9%2010%E1%84%8C%E1%85%A6.pdf?attach=1&knm=tfile.pdf) 

<br>

<br>

## **2. Normal distribution**Â 

â‘´ definition: the limit of <sub>n</sub>C<sub>x</sub> Î¸<sup>x</sup> (1 - Î¸)<sup>n-x</sup> by n â†’ âˆ

> â‘  as it is universally observed, it is called normal distribution

> â‘¡Â generally, the standard normal distribution density function is expressed as Ï†(Â·) and the cumulative distribution function as Î¦(Â·)

> â‘¢ central limit theorem**:** if X = âˆ‘X<sub>i</sub>, taking n â†’ âˆ will lead us to the normal distribution

> â‘£ first induced to approximate binomial distribution (De Moivre, 1721)

> â‘¤ used to analyze model error in astronomy (Gaus, 1809)

>> â—‹ by the fact, this is also known as Gaussian distribution

â‘µ probability density function

<br>

![image](https://github.com/user-attachments/assets/60d4426b-2b8c-437b-9fa7-56d994eb7a1f)

<br>

<img width="402" height="399" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 25 10" src="https://github.com/user-attachments/assets/d319dc02-fb60-4059-80aa-2119ec6ab354" />

<br>

<b>Figure 2.</b> probability density function of standard normal distribution

<br>

> â‘  Python programming:Â [Bokeh](https://jb243.github.io/pages/2186) is used for web-page visualizationÂ 

<br>

```python
# see https://stackoverflow.com/questions/10138085/how-to-plot-normal-distribution
import numpy as np
import scipy.stats as stats
from bokeh.plotting import figure, output_file, show

output_file("normal_distribution.html")
x = np.linspace(-3, 3, 100)
y = stats.norm.pdf(x, 0, 1)

p = figure(width=400, height=400, title = "Normal Distribution", 
           tooltips=[("x", "$x"), ("y", "$y")])
p.line(x, y, line_width=2)
show(p)
```

<br>

â‘¶ statistics

> â‘  moment generating function

<br>

![image](https://github.com/user-attachments/assets/514d8980-94b3-419e-bbf9-f9423566e35e)

<br>

> â‘¡ average: E(X) = Î¼

<br>

![image](https://github.com/user-attachments/assets/3afca0f6-5ce6-4a8e-8aec-d1f6da7da572)

<br>

> â‘¢ variance: VAR(X) = Ïƒ<sup>2</sup>

<br>

![image](https://github.com/user-attachments/assets/75f1fad7-8dd7-4991-a022-2a901a681bac)

<br>

â‘· characteristic

> â‘  **characteristic 1.** symmetric around Î¼  

> â‘¡ **characteristic 2.** if X ~ N(Î¼, Ïƒ<sup>2</sup>), Y = aX + b ~ N(aÎ¼ + b, a<sup>2</sup>Ïƒ<sup>2</sup>)

<br>

![image](https://github.com/user-attachments/assets/c7c6126c-acd1-4dfa-bc45-9dedd4090a2e)

<br>

> â‘¢ **characteristic 3.** if X<sub>i</sub> ~ N(Î¼<sub>i</sub>, Ïƒ<sub>i</sub><sup>2</sup>), X = âˆ‘X<sub>i</sub> ~ N(âˆ‘Î¼<sub>i</sub>, âˆ‘Ïƒ<sub>i</sub><sup>2</sup>)

> â‘£ **characteristic 4.** [uncorrelatedness](https://jb243.github.io/pages/1625): if X and Y are jointly normal and uncorrelated, X and Y are independent

â‘¸ standard normal distributionÂ 

> â‘  definition**:** a normal distribution with a mean of 0 and a standard deviation of 1

> â‘¡ normalization**:** if X ~ N(Î¼, Ïƒ<sup>2</sup>), Z = (X - Î¼) / Ïƒ

> â‘¢ cumulative distribution function Î¦(z) of the standard normal distributionÂ 

<br>

![image](https://github.com/user-attachments/assets/c6dcac18-19a2-4776-8f9c-173b1a8f08bf)

<br>

> â‘£ z<sub>Î±</sub>: z<sub>Î±</sub> value is the value where the probability that X has a greater value than z<sub>Î±</sub> is Î±

â‘¹ normal distribution tableÂ 

<br>

![image](https://github.com/user-attachments/assets/19f0c409-09d3-47bf-9991-c6b65cd138f3)

<b>Table 1.</b> normal distribution table

<br>

â‘º Example

> â‘  [Example problems for normal distribution](https://blog.kakaocdn.net/dn/Ojx7X/btsLKn3z1QF/tRK0c0sPUjpz4xeKQIKt3k/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%80%E1%85%B2%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9%2033%E1%84%8C%E1%85%A6.pdf?attach=1&knm=tfile.pdf) 

> â‘¡ [Example problems for central limit theorem](https://blog.kakaocdn.net/dn/bZrTiS/btsLLN7WH5I/hkNU2YxK1H7nklUh04Ekc1/%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%89%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B3%E1%86%A8%E1%84%92%E1%85%A1%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%2020%E1%84%8C%E1%85%A6.pdf?attach=1&knm=tfile.pdf)

â‘» **Application 1.** Log-Normal Distribution  

> â‘  Definition: The distribution of a random variable whose logarithm follows a normal distribution. In other words, the random variable itself is an exponential function where the exponent is a normally distributed random variable.

> â‘¡ Mathematical Representation: If ln X ~ N(Î¼, Ïƒ<sup>2</sup>), then

>> â—‹  E[X] = exp(Î¼ + Ïƒ<sup>2</sup> / 2) (âˆµ derived from the moment-generating function)  

>> â—‹ E[X<sup>2</sup>] = exp(2Î¼ + 2Ïƒ<sup>2</sup>) (âˆµ derived from the moment-generating function)

>> â—‹ Var(X) = E[X<sup>2</sup>] - (E[X])<sup>2</sup> 

>> â—‹ The sample mean XÌ„ can be said to follow a normal distribution with a mean of exp(Î¼ + Ïƒ<sup>2</sup> / 2) and a variance of Var(X) / n.

> â‘¢ Example: In sequencing data, count values per sample/cell/spot often follow a log-normal distribution.  

â‘¼ **Application 2.** Cauchy Distribution  

> â‘  Definition: The ratio of two independent random variables X<sub>1</sub> and X<sub>2</sub> that follow a normal distribution. 

â‘½ **Application 3.** Rayleigh Distribution

> â‘  Definition: The instantaneous value of the envelope of a mean zero, narrowband noise signal.

> â‘¡ If X and Y are independent random variables following N(0, Ïƒ<sup>2</sup>), then (X<sup>2</sup> + Y<sup>2</sup>)<sup>1/2</sup> follows Rayleigh(Ïƒ<sup>2</sup>).

> â‘¢ Mathematical formulation  

>> â—‹ Probability density function 

<br>

<img width="299" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-03-03 á„‹á…©á„Œá…¥á†« 8 19 13" src="https://github.com/user-attachments/assets/ca8cb68d-3e68-4497-93cf-59ea5d86c2aa" />

<br>

>> â—‹ Cumulative distribution funciton 

<br>

<img width="223" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-03-03 á„‹á…©á„Œá…¥á†« 8 19 32" src="https://github.com/user-attachments/assets/95182a2b-e5d3-4218-90a1-777f17c237c5" />

<br>

>> â—‹ Mean and variance

<br>

<img width="342" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-03-03 á„‹á…©á„Œá…¥á†« 8 19 50" src="https://github.com/user-attachments/assets/ecae8d7a-43d0-4ca4-b045-82e35484ce20" />

<br>

<br>

## **3. Gamma distribution**Â 

â‘´ gamma function

> â‘  **definition 1.** for x ï¼ 0,Â 

<br>

![image](https://github.com/user-attachments/assets/86dad9c5-fdae-40f6-8959-0d7d567dc30a)

<br>

> â‘¡ **definition 2.**Â 

<br>

![image](https://github.com/user-attachments/assets/8d4e74af-f29e-4686-bd09-327b02e4b65e)

<br>

> â‘¢ characteristic

>> â—‹ Î“(-3/2) = 4/3 âˆšÏ€

>> â—‹ Î“(-1/2) = -2 âˆšÏ€Â 

>> â—‹ Î“(1/2) = âˆšÏ€Â 

>> â—‹ Î“(1) = 1

>> â—‹ Î“(3/2) = 1/2 âˆšÏ€

>> â—‹ Î“(a + 1) = aÎ“(a)

>> â—‹ Î“(n + 1) = n!Â 

â‘µ gamma distribution

> â‘  probability density function**:** for x, r, Î» ï¼ 0,Â 

<br>

![image](https://github.com/user-attachments/assets/1595cc91-af19-48f1-8a72-660d886c0e1c)

<br>

<img width="402" height="400" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 25 50" src="https://github.com/user-attachments/assets/9df23acf-343e-4e37-a308-020fad9a8e4d" />

<br>

<b>Figure 3.</b> probability density function of gamma distribution

<br>

>> â—‹Â Python programming**:**Â [Bokeh](https://jb243.github.io/pages/2186) is used for web-page visualizationÂ 

<br>

```python
# see https://www.statology.org/gamma-distribution-in-python/

import numpy as np
import scipy.stats as stats
from bokeh.plotting import figure, output_file, show

output_file("gamma_distribution.html")
x = np.linspace(0, 40, 100)
y1 = stats.gamma.pdf(x, a = 5, scale = 3)
y2 = stats.gamma.pdf(x, a = 2, scale = 5)
y3 = stats.gamma.pdf(x, a = 4, scale = 2)

p = figure(width=400, height=400, title = "Normal Distribution", 
           tooltips=[("x", "$x"), ("y", "$y")])
p.line(x, y1, line_width=2, color = 'red', legend_label = 'shape=5, scale=3')
p.line(x, y2, line_width=2, color = 'green', legend_label = 'shape=2, scale=5')
p.line(x, y3, line_width=2, color = 'blue', legend_label = 'shape=4, scale=2')

show(p)
```

<br>

> â‘¡ meaning

>> â—‹ the probability distribution of time until the r-th event occurs

>> â—‹ r (shape parameter)

>> â—‹ Î» (rate parameter)**:** the average number of events per unit period

>> â—‹ Î² (scale paramete)**:** Î² = 1 / Î»

â‘¶ statistics

> â‘  moment generating function

<br>

![image](https://github.com/user-attachments/assets/3dc30c27-b369-499e-878e-a8bed43bb716)

<br>

> â‘¡ average: E(X) = r / Î»Â 

<br>

![image](https://github.com/user-attachments/assets/e15a1431-e6dc-4711-8274-f290b4cc0cbc)

<br>

> â‘¢ variance**:** VAR(X) = r / Î»<sup>2</sup>

<br>

![image](https://github.com/user-attachments/assets/884e522a-dea2-4b70-8baf-f9b218e6953b)

<br>

â‘· relationship with different probability distributions

> â‘ Â  binomial distribution

<br>

![image](https://github.com/user-attachments/assets/a62649b9-5212-4d6d-9f79-49a810c04a08)

<br>

> â‘¡ negative binomial distributionÂ 

<br>

![image](https://github.com/user-attachments/assets/bf10aaf3-d6ba-4f19-9772-905c4dbf1893)

<br>

> â‘¢ beta distribution

<br>

![image](https://github.com/user-attachments/assets/dcbf52ee-f128-4963-a1c1-bb5b0a1cbd0e)

<br>

> â‘£ Chi-squared distribution: When Î» = 1/2 and r = Î½/2, a chi-squared distribution with Î½ degrees of freedom is obtained.

<br>

<img width="298" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-04-25 á„‹á…©á„’á…® 6 52 06" src="https://github.com/user-attachments/assets/c17cc61e-881c-46cd-9ce5-6919c6b04141" />

<br>

<br>

## **4\. Exponential distribution**

â‘´ Overview

> â‘  A probability distribution that measures the time elapsed from a designated point until a certain event occurs.

>> â—‹ In other words, the duration until the first occurrence of the event.

>> â—‹ Derivation: For an event that occurs Î» times per unit time,

<br>

<img width="503" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-04-25 á„‹á…©á„’á…® 6 53 14" src="https://github.com/user-attachments/assets/e0501077-24ed-4f34-9199-ca99dad66fa7" />

<br>

> â‘¡ Special case with Î± = 1 in gamma distribution

> â‘¢ meaning of parameter

>> â—‹ Î² (survival parameter

>> â—‹ Î» (rate parameter)**:** average number of events per unit period

> â‘£ [Poisson distribution](https://jb243.github.io/pages/1626): duration is fixed. number of events is the random variable

â‘µ probability density function**:** for x ï¼ 0,Â 

<br>

![image](https://github.com/user-attachments/assets/d4423b14-9bb4-42f9-9375-42605180650b)

<br>

<img width="402" height="402" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 26 11" src="https://github.com/user-attachments/assets/dfd729fe-e1ba-4934-9448-d6ba84d0a15a" />

<br>

<b>Figure 4.</b> probability density function of exponential distribution

<br>

> â‘ Â Python programming: [Bokeh](https://jb243.github.io/pages/2186) is used for web-page visualizationÂ 

<br>

```python
# see https://www.alphacodingskills.com/scipy/scipy-exponential-distribution.php

import numpy as np
from scipy.stats import expon
from bokeh.plotting import figure, output_file, show

output_file("exponential_distribution.html")
x = np.arange(-1, 10, 0.1)
y = expon.pdf(x, 0, 2)

p = figure(width=400, height=400, title = "Exponential Distribution", 
           tooltips=[("x", "$x"), ("y", "$y")])
p.line(x, y, line_width=2, legend_label = 'loc=0, scale=2')

show(p)
```

<br>

â‘¶ statistics

> â‘  moment generating function

<br>

![image](https://github.com/user-attachments/assets/92d4bdb5-0543-4ede-89fe-9078eb0d9b7d)

<br>

> â‘¡ average**:** E(X) = 1 / Î»

>> â—‹ meaning**:**Â intuitively, 1 / Î» can be seen

<br>

![image](https://github.com/user-attachments/assets/351bc56b-f0ff-4fc6-8739-1b1ed96a122c)

<br>

> â‘¢ variance**:** VAR(X) = 1 / Î»<sup>2</sup>

<br>

![image](https://github.com/user-attachments/assets/890c8fe9-aece-4724-84a3-1a152e83db76)

<br>

â‘· memorylessness

> â‘  definition

<br>

![image](https://github.com/user-attachments/assets/af7bfa0f-bba3-470e-b93e-cf8992f8e3e0)

<br>

> â‘¡ example**:** when battery life time follows exponential distribution, existing usage time doesn't affect the remaining life time

<br>

â‘¸ Example

> â‘  [Example problems for exponential distribution](https://blog.kakaocdn.net/dn/bpOdA6/btsLL4him9q/Ik3wiKeQ42gPrhzE53z7F0/%E1%84%8C%E1%85%B5%E1%84%89%E1%85%AE%E1%84%87%E1%85%AE%E1%86%AB%E1%84%91%E1%85%A9%2041%E1%84%8C%E1%85%A6.pdf?attach=1&knm=tfile.pdf) 

<br>

<br>

## **5\. Beta distribution**Â 

â‘´ beta function**:** for Î±, Î² ï¼ 0,Â 

<br>

![image](https://github.com/user-attachments/assets/3185be5a-0cf2-4ae8-a6e4-77c0eb21f6d6)

<br>

â‘µ beta distribution

<br>
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlK6Dt%2FbtrfsdFl3uz%2FnXfOPWtZ8r6keeQGsh8S30%2Fimg.png" alt="drawing" />
<br>

<img width="404" height="401" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 26 41" src="https://github.com/user-attachments/assets/ef06478a-1b3f-42c6-babd-0fae4538ef07" />

<br>

<b>Figure 5.</b> probability density function of beta distribution

<br>

> â‘ Â Python programming**:**Â [Bokeh](https://jb243.github.io/pages/2186) is used for web-page visualizationÂ 

<br>

```python
# see https://vitalflux.com/beta-distribution-explained-with-python-examples/
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import beta
from bokeh.plotting import figure, output_file, show

output_file("beta_distribution.html")
x = np.linspace(0, 1, 100)
y1 = beta.pdf(x, 2, 8)
y2 = beta.pdf(x, 5, 5)
y3 = beta.pdf(x, 8, 2)

p = figure(width=400, height=400, title = "Beta Distribution", 
           tooltips=[("x", "$x"), ("y", "$y")])
p.line(x, y1, line_width=2, color = 'red', legend_label = 'a=2, b=8')
p.line(x, y2, line_width=2, color = 'green', legend_label = 'a=5, b=5')
p.line(x, y3, line_width=2, color = 'blue', legend_label = 'a=8, b=2')

show(p)
```

<br>

> â‘¡ E(X) = Î± Ã· (Î± + Î²)Â 

> â‘¢ VAR(X) = Î±Î² Ã· ((Î± + Î²)<sup>2</sup>(Î± + Î² + 1))

â‘µ relationship with gamma function

<br>
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdbFC2k%2FbtrfDgm0Thq%2FqyEDseD6MfS0jDlwuikUb0%2Fimg.png" alt="drawing" />
<br>

â‘¶ characteristic

> â‘  commutative law**:** B(Î±, Î²) = B(Î², Î±)Â 

> â‘¡ equivalent expression

<br>
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FIWtIL%2FbtrfBrvAGQr%2Fhsj9yQ5pfatWNHgfv2ijSk%2Fimg.png" alt="drawing" />
<br>

> â‘¢ Beta Binomial Distribution

>> â—‹ The distribution of the number of successes when an event with a beta distribution is repeated several times

>> â—‹ The beta binomial distribution has greater variance than the binomial distribution

â‘· generalized beta distribution

<br>

<br>

## **6\. Pareto distribution**

â‘´ simple Pareto distribution

> â‘  probability density function**:** for shape parameter a,Â 

<br>
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fvo8uj%2FbtrvwIPHsAp%2F34927nZyzy2on1bLMdjipK%2Fimg.png" alt="drawing" />
<br>

<img width="404" height="406" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 27 05" src="https://github.com/user-attachments/assets/abfe3df0-133a-4c6d-9428-cbe65a00d241" />

<br>

<b>Figure 6.</b> probability density function of simple Pareto distribution

<br>

>> â—‹ Python programming**:**Â [Bokeh](https://jb243.github.io/pages/2186) is used for web-page visualizationÂ Â Â 

<br>

```python
# see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pareto.html

import matplotlib.pyplot as plt
from scipy.stats import pareto
from bokeh.plotting import figure, output_file, show

output_file("pareto_distribution.html")
x = np.linspace(1, 10, 100)
y1 = pareto.pdf(x, 1)
y2 = pareto.pdf(x, 2)
y3 = pareto.pdf(x, 3)

p = figure(width=400, height=400, title = "Pareto Distribution", 
           tooltips=[("x", "$x"), ("y", "$y")])
p.line(x, y1, line_width=2, color = 'red', legend_label = 'a=1')
p.line(x, y2, line_width=2, color = 'green', legend_label = 'a=2')
p.line(x, y3, line_width=2, color = 'blue', legend_label = 'a=3')

show(p)
```

<br>

> â‘¡ probability distribution function

<br>
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb4qVzF%2Fbtrvy3mxMIM%2FSiV0cGXcgfyIomK7yUK1F1%2Fimg.png" alt="drawing" />
<br>

â‘µ generalized Pareto distribution

> â‘  probability density function**:** for scale parameter b,

<br>
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FczUBYY%2FbtrvylViKZs%2FoCU8zZLmpAo99phHzbOWkK%2Fimg.png" alt="drawing" />
<br>

> â‘¡ probability distribution functionÂ 

<br>
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F5P6Ca%2FbtrvELxQM9I%2F3bZYp2Mucb4HAUzJtyxhb1%2Fimg.png" alt="drawing" />
<br>

<br>

## **7\. Logistic distribution**

â‘´ simple logistic distribution

> â‘  probability density function

<br>
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbHAXMz%2FbtrvDhD5ELN%2FFiXk4CAzAOYhMZVTzYorB1%2Fimg.png" alt="drawing" />
<br>

<img width="404" height="406" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 27 25" src="https://github.com/user-attachments/assets/ea498206-dd8d-461d-91d9-f47adfdb2bf8" />

<br>

<b>Figure 7.</b> simple logistic distribution

<br>

> â—‹ Python programming**:**Â [Bokeh](https://jb243.github.io/pages/2186) is used for web-page visualizationÂ 

<br>

```python
# see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.logistic.html

import matplotlib.pyplot as plt
from scipy.stats import logistic
from bokeh.plotting import figure, output_file, show

output_file("logistic_distribution.html")
x = np.linspace(1, 10, 100)
y = logistic.pdf(x)

p = figure(width=400, height=400, title = "Logistic Distribution", 
           tooltips=[("x", "$x"), ("y", "$y")])
p.line(x, y, line_width=2)

show(p)
```

<br>

â‘µ generalized logistic distribution

> â‘  probability density function

<br>
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcqJDSc%2FbtrfFEVsgUq%2FEARma1KNVQOkLkOQckWs9K%2Fimg.png" alt="drawing" />
<br>

<br>

## 8. Dirichlet distribution

â‘´ Overview

> â‘  A multivariate extension of the beta distribution, where each random variable always takes a value between 0 and 1, and their sum must be 1.

> â‘¡ Due to the constraint that the sum of the proportions in the Dirichlet distribution is fixed at 1, optimization using this distribution is somewhat more complex than with other distributions.

> â‘¢ It is notable for its ability to analyze a simplex.

â‘µ Probability density function: For x = (x<sub>1</sub>, Â·Â·Â·, x<sub>D</sub>) and positive parameters (Î»<sub>1</sub>, Â·Â·Â·, Î»<sub>D</sub>) 

<br>
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdahuCW%2FbtrUujZBkTu%2FlJURXKzI4oG0D0N0QJcxFK%2Fimg.png" alt="drawing" />
<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fos6zN%2FbtrUunVmgsW%2FVpCJihr6ZJo0rCznoSFb3k%2Fimg.jpg" alt="drawing" style="width:400px;"/>
<br>

<b>Figure 8. </b> Dirichlet distribution

<br>

â‘¶ Dirichlet-Multinomial conjugacy 

<br>

<img width="454" height="81" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 2 59 47" src="https://github.com/user-attachments/assets/1e4c923f-b997-44e1-bf9a-d4ce5dcbd8f4" />

<br>

<br>

## 9. Gumbel model

â‘´ Gumbel-Softmax  

> â‘  Let z be a categorical variable with class probabilities Ï€<sub>1</sub>, Ï€<sub>2</sub>, Â·Â·Â·, Ï€<sub>k</sub>.

>> â—‹ e.g., Ï€ = [0.2, 0.3, 0.5]

> â‘¡ Categorical samples are encoded as k-dimensional one-hot vectors lying on the (kâˆ’1)-dimensional simplex, âˆ†<sup>ğ‘˜âˆ’1</sup>.

>> â—‹ Reason: Since the sum of all probabilities is 1, the degrees of freedom are reduced by 1.

>> â—‹ e.g., Class 1, 2, and 3 correspond to [1, 0, 0], [0, 1, 0], and [0, 0, 1], respectively.

> â‘¢ Gumbel-Softmax uses softmax to produce **continuous outputs**, but as ğœ approaches 0, the Gumbel-Softmax output eventually becomes the **same as argmax**, resulting in a one-hot vector.

<br>

<img width="497" height="64" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 03 38" src="https://github.com/user-attachments/assets/7284931e-a15a-412b-8f09-33fb69a6b3f6" />

<br>

>> â—‹ The original x<sub>i</sub> = log â¡Ï€<sub>i</sub> cannot be reconstructed from ğ‘¦ after passing through the softmax function due to insufficient information, making the inverse transformation impossible.

>> â—‹ To compensate for this, we define an equivalent sampling process that subtracts off the last element, (x<sub>k</sub> + g<sub>k</sub>) âˆ• ğœ before the softmax:

<br>

<img width="351" height="71" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 05 02" src="https://github.com/user-attachments/assets/b3ef3d85-4029-47e3-a272-b8917dd1f26b" />

<br>

â‘µ Gumbel Model 

> â‘  The probability density of a Gumbel distribution with scale Î² = 1 and mean Î¼ at z is

<br>

<img width="194" height="38" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 05 59" src="https://github.com/user-attachments/assets/84e51fe6-36a5-4fd1-94f8-629f9e665d77" />

<br>

> â‘¡ We first derive the density for the "centered" multivariate Gumbel density:

<br>

<img width="396" height="32" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-07-15 á„‹á…©á„’á…® 3 06 49" src="https://github.com/user-attachments/assets/05be0cf2-f51d-4863-9000-63b162bbbd42" />

<br>

> â‘¢ We can now compute the density of this distribution by marginalizing g<sub>k</sub>:

<br>

<img width="654" height="623" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-10-04 á„‹á…©á„’á…® 8 38 48" src="https://github.com/user-attachments/assets/6c8aea94-8bd9-4e05-a882-37e4838e5443" />

<br>

â‘¶ [Categorical Reparameterization with Gumbel-Softmax](https://arxiv.org/abs/1611.01144)

> â‘  Given samples u<sub>1</sub>, Â·Â·Â·, u<sub>k-1</sub> from the centered Gumbel distribution, we can apply a deterministic transformation â„ to yield the first kâˆ’1 coordinates of the sample from the Gumbel-Softmax:

<br>

<img width="1280" height="1393" alt="image" src="https://github.com/user-attachments/assets/26249ad8-d530-416b-a633-1c2404c46767" />

<br>

> â‘¡ The primary contribution of this work is the reparameterization Gumbel-Softmax distribution, whose corresponding estimator affords **low-variance** path **derivative gradients for the categorical distribution**.

> â‘¢ For learning, there is a tradeoff between small temperatures, where samples are close to one-hot but the variance of the gradients is large, and large temperatures, where samples are smooth but the variance of the gradients is small. In practice, we **start at a high temperature and anneal to a small** but non-zero temperature.

> â‘£ Gumbel-Softmax allows us to backpropagate through y ~ q<sub>ğœ™</sub>(ğ‘¦ <span>â”‚</span> ğ‘¥) for single sample gradient estimation, and achieves a cost of ğ’ª(ğ·+ğ¼+ğº) per training step (**dramatic speedup**), where ğ·, ğ¼, ğº are the computational cost of sampling from q<sub>ğœ™</sub>(ğ‘¦ <span>â”‚</span> ğ‘¥), q<sub>ğœ™</sub>(ğ‘§ <span>â”‚</span> ğ‘¥, ğ‘¦), and p<sub>ğœ™</sub>(ğ‘¥ <span>â”‚</span> ğ‘¦, ğ‘§).

> â‘¤ Gumbel-Softmax and ST Gumbel-Softmax **outperform** existing stochastic gradient estimators: Score-Function (SF), DARN, MuProp, Straight-Through (ST), and Slope-Annealed ST.

<br>

---

*Input : 2019.06.19 00:27*
