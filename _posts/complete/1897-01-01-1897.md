## **Chapter 1. Vector Space**

Recommended reading: 【Linear Algebra】 [Linear Algebra Index](https://jb243.github.io/pages/1014)

---

**1.** [Matrix Operations](#1-matrix-operations)

**2.** [Vector Space](#2-vector-space)

---

<br>

## **1. Matrix Operations**

 ⑴ Definition of Matrix

> ① Define m × n matrix A, i-th row vector, j-th column vector as follows

<br>

<img width="338" alt="스크린샷 2024-11-22 오후 2 15 13" src="https://github.com/user-attachments/assets/282cb9ad-281c-4c1a-b703-fcc5e6bdb5e8">

<br>

> ② Zero matrix or null matrix: A matrix where all elements are 0

> ③ Square matrix

⑵ Matrix Addition

<br>

<img width="352" alt="스크린샷 2024-11-22 오후 2 15 30" src="https://github.com/user-attachments/assets/bdc0e07b-c10f-4cc9-8c2a-b325560453b7">

<br>

⑶ Matrix Multiplication

> ① The element at i-th row, j-th column of matrix X is denoted as X[i][j], and if A ∈ ℝl×m, B ∈ ℝm×n, C ∈ ℝl×n, and C = A × B, the following holds

<br>

<img width="258" alt="스크린샷 2024-11-22 오후 2 15 49" src="https://github.com/user-attachments/assets/4a1f0f85-47aa-4282-8d53-947b2737bc3a">

<br>

> ② **Property 1.** Generally, AB ≠ BA

<br>

<img width="297" alt="스크린샷 2024-11-22 오후 2 17 14" src="https://github.com/user-attachments/assets/34424319-5d40-4a7a-99a8-16e7e1ecf43e">

<br>

> ③ **Property 2.** AB = O does not imply A = O or B = O

<br>

<img width="252" alt="스크린샷 2024-11-22 오후 2 17 32" src="https://github.com/user-attachments/assets/3eb33498-0ce6-4ac3-931e-28ef9671c8ce">

<br>

> ④ **Property 3.** The following relationship holds between matrix multiplication and addition

>> ○ A(B+C) = AB + AC, (A+B)C = AC + BC

>> ○ A(BC) = (AB)C

>> ○ c(A + B) = cA + cB

> ⑤ **Theorem 1.** **Cayley–Hamilton Theorem**

<br>

<img width="431" alt="스크린샷 2024-11-22 오후 2 17 48" src="https://github.com/user-attachments/assets/339f468c-0a70-4e5a-afbc-84aea99e482d">

<br>

>> ○ Using this, A<sup>n</sup> can be calculated as A<sup>n</sup> = (A<sup>2</sup> - (a + d)A + (ad - bc)E) Q(A) + kA + sE for n ≥ 2

> ⑥ Programming Code

>> ○ [Matrix Multiplication Implementation in C Language](https://jb243.github.io/pages/62)

>> ○ Using numpy

<br>

```python
import numpy as np

# Definition of two matrices 
A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

# Output matrices 
print("Matrix A:")
print(A)
print("\nMatrix B:")
print(B)

# Matrix multiplication 
result = np.dot(A, B)
## Alternatively, result = A@B

print("\nNumpy matrix multiplication result:")
print(result)
```

<br>

>> ○ Using sympy

<br>

```python
from sympy import Matrix, init_printing

# Initialization of output style of LaTeX 
init_printing()

# Definition of two matrices 
A = Matrix([[1, 2], [3, 4]])
B = Matrix([[5, 6], [7, 8]])

# Output matrices 
print("Matrix A:")
display(A)

print("Matrix B:")
display(B)

# Matrix multiplication 
result = A * B

print("Sympy matrix multiplication result:")
display(result)
```

<br>

⑷ Transposed Matrix

> ① Definition

<br>

<img width="194" alt="스크린샷 2024-11-22 오후 2 20 13" src="https://github.com/user-attachments/assets/46a1f684-b0fd-4c9f-8ed5-4077f08ec875">

<br>

> ② Symmetric Matrix: If A is a square matrix and equals its transpose

> ③ When X ∈ ℝN×d (N data points of d dimensions) is given,

>> ○ XtX ∈ ℝd×d is the covariance matrix when μ = 0

>> ○ XXt ∈ ℝN×N is the dot matrix (similarity matrix)

> ④ **Property 1.** (At)t = A

> ⑤ **Property 2.** (A + B)t = At + Bt

> ⑥ **Property 3.** (rA)t = rAt

> ⑦ **Property 4.** Transpose of AB is (AB)t = BtAt

<br>

<img width="392" alt="스크린샷 2024-11-22 오후 2 20 36" src="https://github.com/user-attachments/assets/2bbc2ed5-f014-4c8c-bbc4-d7b78561e041">

<br>

> ⑧ **Property 5.** If A and B are symmetric and AB = BA, then AB is symmetric

<br>

<img width="230" alt="스크린샷 2024-11-22 오후 2 20 52" src="https://github.com/user-attachments/assets/a4853c89-c878-4f04-a30b-be67ace8d8e5">

<br>

⑸ Trace: Denoted as trace or tr

<br>

<img width="149" alt="스크린샷 2024-11-22 오후 2 21 08" src="https://github.com/user-attachments/assets/6ba69a12-4d42-49c3-adf8-df4c5ebf776e">

<br>

> ① **Property 1.** tr(E) = n, tr(O) = 0

> ② **Property 2.** tr(A + B) = tr(A) + tr(B)

> ③ **Property 3.** tr(cA) = ctr(A), c ∈ ℝ

> ④ **Property 4.** tr(AT) = tr(A)

> ⑤ **Property 5.** If A is an m×n matrix and B is an n×r matrix, then tr(AB) = tr(A) × tr(B)

⑹ Gaussian Elimination

> ① Linear System of Equations

<br>

<img width="430" alt="스크린샷 2024-11-22 오후 2 21 28" src="https://github.com/user-attachments/assets/d1e40837-b0b1-474c-aaa4-06422349df2f">

<br>

> ② Augmented Matrix: Refers to m × (n + ℓ) matrix (A <span>|</span> B)

<br>

<img width="254" alt="스크린샷 2024-11-22 오후 2 21 52" src="https://github.com/user-attachments/assets/d48c6a05-19e9-4a10-80bf-41865d83c4fb">

<br>

> ③ Gauss-Jordan Elimination: Operates row-wise

>> ○ **Operation 1.** Swap the positions of two row vectors: Changes the order of equations

>> ○ **Operation 2.** Multiply a specific row vector by c: Multiplies both sides of an equation by c

>> ○ **Operation 3.** Multiply one row vector by c and add it to another row vector: Multiplies one equation by c and adds it to another equation

>> ○ Final Step: Achieve reduced row echelon form (RREF)

<br>

<img width="123" alt="스크린샷 2024-11-22 오후 2 22 06" src="https://github.com/user-attachments/assets/745c3c60-7b91-43f9-8f02-f5cfe98e875d">

<br>

> ④ Advantage: Can be implemented programmatically

<br>

<br>

## **2. Vector Space**

 ⑴ Conditions for Vector Space

> ① Identity Element for Addition: There exists **0** in V such that **x** + **0** = **x** for any **x** in V

> ② Additive Inverse: If **x** ∈ V, there exists -**x** in V such that **x** + (-**x**) = **0**

> ③ Commutativity of Addition: If **x**, **y** ∈ V, then **x** + **y** = **y** + **x**

> ④ Associativity of Addition: If **x**, **y**, **z** ∈ V, then (x + y) + z = x + (y + z)

> ⑤ Distributive Law: c(**x** + **y**) = c**x** + c**y**

> ⑥ Distributive Law: (c1 + c2)**x** = c1**x** + c2**x**

> ⑦ Multiplicative Identity: 1**x** = **x**

> ⑧ Associativity of Scalar Multiplication: c1(c2**x**) = (c1c2)**x**

 ⑵ Linear Transformation

> ① Linear Transformation: A mapping T: U → V is linear if it satisfies the following for **x**, **y** ∈ U and c ∈ F

<br>

<img width="223" alt="스크린샷 2024-11-22 오후 2 22 22" src="https://github.com/user-attachments/assets/6c4e0bbd-e255-4ce7-98a2-742f4e1b83cf">

<br>

> ② Linear Combination

<br>

<img width="187" alt="스크린샷 2024-11-22 오후 2 22 44" src="https://github.com/user-attachments/assets/541e15cf-a9c0-4f66-9cf7-3716745e9802">

<br>

> ③ Linearly Dependent

<br>

<img width="361" alt="스크린샷 2024-11-22 오후 2 23 03" src="https://github.com/user-attachments/assets/bd7c05b2-4734-4a11-a0ad-e37ca112af74">

<br>

> ④ Linearly Independent

<br>

<img width="402" alt="스크린샷 2024-11-22 오후 2 23 18" src="https://github.com/user-attachments/assets/fa97253e-4fb6-49a8-8675-94312e9d8dd6">

<br>

> ⑤ Spanning Set: If any vector in vector space V can be expressed as a linear combination of elements in S, then S is a spanning set

<br>

<img width="511" alt="스크린샷 2024-11-22 오후 2 23 34" src="https://github.com/user-attachments/assets/a1d7dd16-3fd2-4bee-ae55-da9e0fd098cb">

<br>

> ⑥ Basis: A linearly independent subset of the spanning set

⑶ Inverse of T, T-1: If T-1 exists such that T-1: V → U, then T-1 is also a linear transformation

<br>

<img width="400" alt="스크린샷 2024-11-22 오후 2 23 51" src="https://github.com/user-attachments/assets/9a21d1a1-d04e-44a2-9ba7-88c3f98cf61e">

<br>

⑷ Inner Product Space

> ① Conditions for Inner Product

<br>

<img width="292" alt="스크린샷 2024-11-22 오후 2 24 09" src="https://github.com/user-attachments/assets/27bcde00-f9d7-424c-9956-dad16fb75d72">

<br>

> ② Standard Inner Product: Defined as follows for V = ℂn

<br>

<img width="288" alt="스크린샷 2024-11-22 오후 2 24 24" src="https://github.com/user-attachments/assets/91baa537-c6fc-48ce-a6d4-1aa75ef312b3">

<br>

> ③ Properties of Inner Product

<br>

<img width="251" alt="스크린샷 2024-11-22 오후 2 24 38" src="https://github.com/user-attachments/assets/4fc82472-0dc6-415d-90ac-ade3167563a2">

<br>

> ④ Inner Product Space: A vector space with a defined inner product

>> ○ Real Inner Product Space: When the scalar field is the set of real numbers

>> ○ Complex Inner Product Space: When the scalar field is the set of complex numbers

> ⑤ Norm

<br>

<img width="402" alt="스크린샷 2024-11-22 오후 2 24 51" src="https://github.com/user-attachments/assets/c40cc321-e270-45b6-b362-9d0ff5d464ea">

<br>

> ⑥ **Theorem 1.** Cauchy-Schwarz Inequality

<br>

<img width="360" alt="스크린샷 2024-11-22 오후 2 25 06" src="https://github.com/user-attachments/assets/6c141a04-f04f-43df-b755-37ada08c5b1b">

<br>

> ⑦ **Theorem 2.** Triangle Inequality

<br>

<img width="293" alt="스크린샷 2024-11-22 오후 2 25 20" src="https://github.com/user-attachments/assets/a305baa5-f900-49cc-a802-c2c0a42d2996">

<br>

⑷ Metric Space

> ① Distance Function

<br>

<img width="425" alt="스크린샷 2024-11-22 오후 2 25 40" src="https://github.com/user-attachments/assets/9a183d2a-f936-4c52-9293-7b3e34f7ccdc">

<br>

>> ○ [Types of Distance Functions](https://jb243.github.io/pages/879)

> ② Relation between Norm and Distance

>> ○ If norm is defined, distance d can be defined

<br>

<img width="147" alt="스크린샷 2024-11-22 오후 2 25 56" src="https://github.com/user-attachments/assets/67c25321-dc60-4c42-8458-8b07f8389466">

<br>

>> ○ Having a defined distance does not necessarily imply a corresponding norm exists

> ③ Kernel

>> ○ A non-linear map φ(**x**): X → H can be used to define distance d differently

<br>

<img width="598" alt="스크린샷 2024-11-22 오후 2 26 16" src="https://github.com/user-attachments/assets/57ee5d47-ff31-4201-955f-df29ecdc2a21">

<br>

>> ○ Definition of Kernel: k(**x i**, **y i**) ≡ φ(**x i**)Tφ(**x j**)

<br>

<img width="358" alt="스크린샷 2024-11-22 오후 2 26 31" src="https://github.com/user-attachments/assets/aceb63e0-58f2-4037-a02a-4d5c4d8a0652">

<br>

>> ○ Characteristics of Kernel

<br>

<img width="555" alt="스크린샷 2024-11-22 오후 2 26 49" src="https://github.com/user-attachments/assets/c4f6b9b9-c4d4-4d35-a1c9-262680829644">

<br>

>> ○ Examples of Kernels

>>> ○ φ(x, y) = (x, y, x2 + y2)T

>>> ○ k(**v**, **u**) = **u**T**v** (In this case, φ(·) is the identity function)

>>> ○ Gaussian Kernel: k(**v**, **u**) = exp(-<span>||</span>**v** - **u**<span>||</span><sup>2</sup> / 2σ<sup>2</sup>)

>>> ○ Polynomial Kernel: k(**v**, **u**) = (**u**T**v** + 1)<sup>d</sup>

>>> ○ Sigmoid Kernel: k(**v**, **u**) = tanh(α**u**T**v** + β)

>>> ○ RBF Kernel: k(**v**, **u**) = exp(-γ <span>||</span>**v** - **u**<span>||</span><sup>2</sup>)

⑸ Subspace: A spanning set spans a subspace

<br>

<img width="262" alt="스크린샷 2024-11-22 오후 2 27 04" src="https://github.com/user-attachments/assets/c3c7d986-a0af-4eed-baf4-5bdef4b3b89f">

<br>

---

_Input: 2020.04.07 21:36_

_Modified: 2024.10.10 08:12_
