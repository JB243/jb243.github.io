## **Chapter 3. Determinants and Inverses**

Recommended post: 【Linear Algebra】 [Linear Algebra Table of Contents](https://jb243.github.io/pages/1014)

---

**1.** [Determinant](#1-determinant)

**2.** [Inverse Matrix](#2-inverse-matrix)

**3.** [Cramer's Rule](#3-cramer-s-rule)

---

<br>

## **1. Determinant** 

⑴ Definition of a permutation

> ① **Permutation**: A permutation of S = {1, 2, ···, n} refers to a one-to-one correspondence function σ from S to S.

>> ○ This function is simply written as (f(1), ···, f(n)).

>> ○ Identity permutation: (1, 2, ···, n). That is, when f(i) = i.

> ② **Transposition**: A transformation that changes (f(1), ···, f(i), ···, f(j), ···, f(n)) to (f(1), ···, f(j), ···, f(i), ···, f(n))

>> ○ In other words, a transposition swaps the images of two elements in the domain of a permutation.

>> ○ Any permutation can be formed by multiplying finitely many transpositions from (1, ···, n).

> ③ Sign of a permutation

>> ○ Odd permutation: A permutation that can form the identity permutation by multiplying an odd number of transpositions.

>> ○ Even permutation: A permutation that can form the identity permutation by multiplying an even number of transpositions.

>> ○ If a permutation σ is odd, define sgn(σ) = -1; if even, sgn(σ) = +1.

> ④ Parity of the symmetric group: A permutation cannot be both even and odd.

>> ○ First assume f(0) = 0.

>> ○ Inversion

>>> ○ For α ≤ x ≤ β, define M(k)<sub>α, β</sub> as the number of x such that f(x) ＞ f(y), called an inversion.

>>> ○ Sum of inversions

<br>

<img width="93" height="52" alt="스크린샷 2025-12-05 오후 3 19 43" src="https://github.com/user-attachments/assets/5151da8e-7e84-4cfb-bf72-94a49eaf5e97" />

<br>

>> ○ Definitions

>>> ○ n<sub>1</sub>: Number of n such that f(n) > f(a) and 0 < n < i.

>>> ○ n<sub>2</sub>: Number of n such that f(a) > f(n) > f(b) and 0 < n < i.

>>> ○ n<sub>3</sub>: Number of n such that f(b) > f(n) and 0 < n < i.

>>> ○ n<sub>4</sub>: Number of n such that f(n) > f(a) and i < n < j.

>>> ○ n<sub>5</sub>: Number of n such that f(a) > f(n) > f(b) and i < n < j.

>>> ○ n<sub>6</sub>: Number of n such that f(b) > f(n) and 0 < n < i.

>> ○ **Case 1.** When f(i) = a and f(j) = b (assuming f(a) ＞ f(b))

<br>

<img width="579" height="59" alt="스크린샷 2025-12-05 오후 3 21 55" src="https://github.com/user-attachments/assets/37895e1d-dd4f-4b1e-9a67-ae242961de70" />

**Figure 1.** First case of permutation

<br>

<img width="772" height="319" alt="스크린샷 2025-12-05 오후 3 22 21" src="https://github.com/user-attachments/assets/495da65f-4444-4e4b-9847-7157a88b2dc7" />

<br>

>> ○ **Case 2.** When f(i) = b and f(j) = a (assuming f(a) ＞ f(b))

<br>

<img width="578" height="60" alt="스크린샷 2025-12-05 오후 3 23 09" src="https://github.com/user-attachments/assets/1ca57bd4-0a74-4651-a405-ec8f68e9a31d" />

**Figure 2.** Second case of permutation

<br>

<img width="703" height="320" alt="스크린샷 2025-12-05 오후 3 23 30" src="https://github.com/user-attachments/assets/6e47d932-0c7b-4c69-985e-e4c6901e1cfb" />

<br>

>> ○ Conclusion: Permutations have parity.

<br>

<img width="201" height="26" alt="스크린샷 2025-12-05 오후 3 23 53" src="https://github.com/user-attachments/assets/933833bf-d82e-4c02-b0a1-3bb3a5b3626a" />

<br>

⑵ Definition of determinant: When [A]<sup>j</sup> is the j-th column vector of matrix A,

> ① **Property 1.** det[I] = 1

> ② **Property 2.** Property related to the sign of permutations

<br>

<img width="358" height="66" alt="스크린샷 2025-12-05 오후 3 24 21" src="https://github.com/user-attachments/assets/720a70f7-2354-4da2-aaa0-9f238c67e25b" />

<br>

>> ○ **2-1.** If in A = ([A]<sup>1</sup>, ···, [A]<sup>n</sup>), [A]<sup>h</sup> = [A]<sup>k</sup> (1 ≤ h ≠ k ≤ n), then det(A) = 0

> ③ **Property 3.** det(A) = det([A]<sup>1</sup>, ···, [A]<sup>n</sup>) is a multilinear function in the column vectors.

<br>

<img width="364" height="180" alt="스크린샷 2025-12-05 오후 3 26 27" src="https://github.com/user-attachments/assets/9f9e2bbf-771f-44ac-b1dc-999c98fb209b" />

<br>

>> ○ **3-1.** If [A]<sup>i</sup> = **0** in A = ([A]<sup>1</sup>, ···, [A]<sup>n</sup>), then det(A) = 0 (**∵** **0** + **0** = **0**)

>> ○ **3-2.** Useful operations on columns: Since the determinant remains the same for the transpose matrix, operations on rows are also allowed.

<br>

<img width="367" height="66" alt="스크린샷 2025-12-05 오후 3 27 23" src="https://github.com/user-attachments/assets/bbf37499-98e5-4855-9af6-4021a15159b5" />

<br>

> ④ The unique function satisfying **Property 1**, **Property 2**, and **Property 3** is as follows.

<br>

<img width="408" height="210" alt="스크린샷 2025-12-05 오후 3 27 42" src="https://github.com/user-attachments/assets/02ce7197-5d0d-4fca-9f78-9fe7b3edefc6" />

<br>

⑶ Computing determinants

> ① Determinant of a 2 × 2 matrix

<br>

<img width="281" height="142" alt="스크린샷 2025-12-05 오후 3 28 01" src="https://github.com/user-attachments/assets/07bb396d-268f-4fe5-a116-94f2a40b2f90" />

<br>

> ② Determinant of a 3 × 3 matrix

<br>

<img width="452" height="187" alt="스크린샷 2025-12-05 오후 3 28 20" src="https://github.com/user-attachments/assets/2f3b0822-0192-4e1c-8415-7f681da6b6f3" />

<br>

> ③ Cofactor expansion: Computing determinants using minors

<br>

<img width="618" height="157" alt="스크린샷 2025-12-05 오후 3 28 39" src="https://github.com/user-attachments/assets/1fe2222d-59b3-4261-83ed-8857b4754be2" />

<br>

⑷ Applications of determinants

> ① **Theorem 1.** If the rank of an n × n matrix A is less than n, then det(A) = 0.

>> ○ Reason: The determinant implies the existence of a unique solution via the inverse matrix.

> ② **Theorem 2.** Determinant of the transpose: If A is an n × n matrix, det(A<sup>t</sup>) = det(A)

> ③ **Theorem 3.** If A and B are n × n matrices, det(AB) = det(A)det(B)

<br>

<img width="473" height="256" alt="스크린샷 2025-12-05 오후 3 29 12" src="https://github.com/user-attachments/assets/e6654bf6-305a-43d8-8d83-98d71c6e5d73" />

<br>

> ④ **Theorem 4.** For X ∈ ℳ<sub>n</sub>, A ∈ ℳ<sub>r</sub>, D ∈ ℳ<sub>n-r</sub>, B ∈ ℳ<sub>r, n-r</sub>, the following holds:

<br>

<img width="310" height="42" alt="스크린샷 2025-12-05 오후 3 29 50" src="https://github.com/user-attachments/assets/5bb06156-431b-4215-b92d-8e3c5631107b" />

<br>

>> ○ **Theorem 4-1.**

<br>

<img width="576" height="44" alt="스크린샷 2025-12-05 오후 3 30 10" src="https://github.com/user-attachments/assets/45b91081-3069-49e1-bc99-94da74475229" />

<br>

>> ○ **Theorem 4-2.** For n × n matrices A, B, C, D, if ㅣDㅣ ≠ 0 and CD = DC

<br>

<img width="369" height="233" alt="스크린샷 2025-12-05 오후 3 30 45" src="https://github.com/user-attachments/assets/045e3f6a-0c4e-43b4-bb30-e50fcf244cbc" />

<br>

>> ○ **Theorem 4-3.** For A ∈ ℳ<sub>r</sub>, B ∈ ℳ<sub>r, n-r</sub>, C ∈ ℳ<sub>n-r, r</sub>, D ∈ ℳ<sub>n-r</sub>, the following identity holds.

<br>

<img width="537" height="162" alt="스크린샷 2025-12-05 오후 3 31 30" src="https://github.com/user-attachments/assets/ecd4d8ab-04d7-4a45-960e-acd48388597f" />

<br>

> ⑤ **Theorem 5.** When **x** and **y** are both n-dimensional column vectors, the following identity holds.

<br>

<img width="405" height="89" alt="스크린샷 2025-12-05 오후 3 31 54" src="https://github.com/user-attachments/assets/e5125928-8e50-4c7c-b71b-a52708a4dbfe" />

<br>

> ⑥ **Theorem 6.** Vandermonde matrix

>> ○ Definition: A matrix whose columns consist of powers of certain numbers.

>> ○ Determinant

<br>

<img width="500" height="227" alt="스크린샷 2025-12-05 오후 3 32 21" src="https://github.com/user-attachments/assets/3f723de7-2874-4216-8d02-7601d8023d64" />

<br>

>>> ○ The given determinant can be expressed as a polynomial: For example, regarding x<sub>n</sub>, the polynomial is of degree ≤ n-1 in x<sub>n</sub>.

>>> ○ Note the fact that subtracting one row vector from another does not change the determinant.

>>> ○ From the difference between the nth row and the 1st row, the determinant has (x<sub>n</sub> - x<sub>1</sub>) as a factor; similarly (x<sub>n</sub> - x<sub>2</sub>), ···, (x<sub>n</sub> - x<sub>n-1</sub>).

>>> ○ Thus, the polynomial is expressed as (x<sub>n</sub> - x<sub>1</sub>) ··· (x<sub>n</sub> - x<sub>n-1</sub>): Confirm the coefficient of x<sub>n</sub><sup>n-1</sup> is 1.

>>> ○ Without loss of generality, the same pattern holds for x<sub>n-1</sub>, x<sub>n-2</sub>, ···, x<sub>1</sub>, proving the formula.

> ⑦ **Theorem 7.** Gramian (Gram) matrix

>> ○ Definition: A symmetric matrix formed by inner products of vectors.

> ⑧ **Theorem 8.** Hankel matrix

>> ○ Definition: A matrix in which all values along the anti-diagonal (bottom-left ↗ top-right) are equal.

⑸ Uses of determinants

> ① **Use 1.** Determinants represent area, volume, etc., transformed by a linear transformation.

<br>

<img width="398" height="399" alt="스크린샷 2025-12-05 오후 3 36 20" src="https://github.com/user-attachments/assets/f118e937-5c65-44b5-9593-2db6ca67be59" />

**Figure 3.** Determinant and area of a 2-dimensional linear transformation

<br>

> ② **Use 2.** If given row vectors or column vectors are dependent, the determinant is 0; if independent, the determinant is non-zero (and the converse is also true).

>> ○ **Case 1.** Dependent: By **Property 2**, the determinant becomes 0.

>> ○ **Case 2.** Independent

>>> ○ Using Gaussian elimination to form an upper triangular matrix, none of the diagonal elements become 0.

>>> ○ Such an upper triangular matrix clearly has a non-zero determinant.

>>> ○ The determinant does not change during Gaussian elimination.

>>> ○ Therefore, a matrix with independent column or row vectors has a non-zero determinant.

> ③ **Use 3.** Existence of inverse matrices: A determinant of 0 is a necessary and sufficient condition for a matrix to have no inverse.

>> ○ Because Gaussian elimination, which preserves the determinant, can automatically find the inverse.

> ④ **Use 4.** Equation of a line passing through (x<sub>1</sub>, y<sub>1</sub>)', (x<sub>2</sub>, y<sub>2</sub>)' in the x-y plane

<br>

<img width="104" height="72" alt="스크린샷 2025-12-05 오후 3 37 54" src="https://github.com/user-attachments/assets/b58d7aca-1d63-4810-af48-71f4589f1fb4" />

<br>

> ⑤ **Use 5.** Cross product of **v** = (v<sub>1</sub>, v<sub>2</sub>, v<sub>3</sub>) and **w** = (w<sub>1</sub>, w<sub>2</sub>, w<sub>3</sub>)

<br>

<img width="116" height="72" alt="스크린샷 2025-12-05 오후 3 38 46" src="https://github.com/user-attachments/assets/9e6e6cae-07a5-4433-bf29-33d6c0308e77" />

<br>

> ⑥ **Use 6.** Wronskian matrix

<br>

<img width="498" height="95" alt="스크린샷 2025-12-05 오후 3 39 10" src="https://github.com/user-attachments/assets/cd14e457-4488-45ba-ac3a-b372e36cdbea" />

<br>

> ⑦ **Use 7.** Jacobian matrix

<br>

<img width="610" height="155" alt="스크린샷 2025-12-05 오후 3 39 31" src="https://github.com/user-attachments/assets/2498231c-f6a8-49e0-ad97-305d7a76cf6d" />

<br>

> ⑧ **Use 8.** Hessian matrix

>> ○ Hessian for a 2 × 2 matrix

<br>

<img width="695" height="317" alt="스크린샷 2025-12-05 오후 3 39 56" src="https://github.com/user-attachments/assets/3fe039d0-7502-4db7-85fa-644a3ad5530a" />

<br>

>> ○ Hessian for a 3 × 3 matrix

<br>

<img width="856" height="339" alt="스크린샷 2025-12-05 오후 3 40 17" src="https://github.com/user-attachments/assets/3768b23d-59f0-4078-8a81-5acf9149089d" />

<br>

>> ○ Hessian for an n × n matrix

<br>

<img width="195" height="98" alt="스크린샷 2025-12-05 오후 3 40 49" src="https://github.com/user-attachments/assets/4f73b04b-6db5-4c08-8334-367aa7408838" />

<br>

> ⑨ **Use 9.** <span style="background-color: #ee2323; color: #ffffff; font-family: Times New Roman;">►</span> [Hückel approximation and Hamiltonian](https://www.youtube.com/watch?v=oT71KYCPSJE) ([ref](https://jb243.github.io/pages/1334)))

> ⑩ **Use 10.** Rotation and reflection transformations

>> ○ Rotation transformation: For a matrix **R** representing T**:** **x** → **y**, if **R**<sup>T</sup>**R** = **RR**<sup>T</sup> = **I** (isometric), det(**R**) = 1

>> ○ Reflection transformation: For a matrix **R** representing T**:** **x** → **y**, if **R**<sup>T</sup>**R** = **RR**<sup>T</sup> = **I** (isometric), det(**R**) = -1

>> ○ [Example applied to an object's collision]([https://jb243.github.io/pages/1987#:D%](https://jb243.github.io/pages/1987#:D%) %2)

<br>

<br>

## **2. Inverse Matrix** 

⑴ Definition

<br>

<img width="116" height="64" alt="스크린샷 2025-12-05 오후 3 42 10" src="https://github.com/user-attachments/assets/339933b5-d1f8-436e-8ffa-8040322dcb30" />

<br>

⑵ Invertible matrix: A matrix with an existing inverse.

> ① **Theorem 1.** If A has an inverse, it is unique.

> ② **Theorem 2.** If A is invertible, A<sup>-1</sup> is also invertible.

<br>

<img width="97" height="28" alt="스크린샷 2025-12-05 오후 3 42 36" src="https://github.com/user-attachments/assets/72a72df5-7341-4945-8601-69ee780317d3" />

<br>

> ③ **Theorem 3.** If A and B are invertible, AB is also invertible.

<br>

<img width="367" height="65" alt="스크린샷 2025-12-05 오후 3 42 56" src="https://github.com/user-attachments/assets/2cd2eba7-ce93-489c-a3d7-a9a25067226d" />

<br>

> ④ **Theorem 4.** If A is invertible, cA is also invertible.

<br>

<img width="125" height="48" alt="스크린샷 2025-12-05 오후 3 43 18" src="https://github.com/user-attachments/assets/bc25e7dc-d281-4039-9d29-416fc1de17dd" />

<br>

> ⑤ **Theorem 5.** Inverse matrix and transpose matrix

<br>

<img width="234" height="64" alt="스크린샷 2025-12-05 오후 3 43 37" src="https://github.com/user-attachments/assets/8690dd54-923c-4fa6-ad9c-f8b27061e620" />

<br>

> ⑥ **Theorem 6.** If there exists a natural number k such that det (A<sup>k</sup>) ≠ 0 (A is 3 × 3), then A is invertible.

> ⑦ **Theorem 7.** If there exists a natural number k such that (I - A<sup>k</sup>) = O (A is 3 × 3, I is the identity matrix), then A is invertible.

> ⑧ **Theorem 8.** If there exist <b>v<sub>1</sub></b>, <b>v<sub>2</sub></b>, ···, <b>v<sub>k</sub></b> such that A<b>v<sub>1</sub></b> ∪ A<b>v<sub>2</sub></b> ∪ ··· ∪ A<b>v<sub>k</sub></b> = ℝ<sup>3</sup>, then A is invertible.

>> ○ Reason: It means rank (A) = 3.

> ⑨ The existence of three orthogonal vectors <b>v<sub>1</sub></b>, <b>v<sub>2</sub></b>, <b>v<sub>3</sub></b> with A<b>v<sub>i</sub></b> ≠ O is not sufficient to regard A as invertible.

>> ○ Reason: Because A may map vectors to a single non-zero vector.

<br>

<img width="423" height="69" alt="스크린샷 2025-12-05 오후 3 45 48" src="https://github.com/user-attachments/assets/604b1dba-4b77-4b68-b935-fbd2ce8aa144" />

<br>

⑶ **Computing inverses 1.** Finding inverses by transforming to triangular matrices

> ① Elementary row operations: Provide an algorithm for finding inverse matrices.

<br>

<img width="72" height="28" alt="스크린샷 2025-12-05 오후 3 46 06" src="https://github.com/user-attachments/assets/cc91ac74-f3d1-43c0-9b61-3fb5db01098d" />

<br>

>> ○ ⓐ Swapping row i and row j of A is equivalent to swapping row i and row j of C.

>> ○ ⓑ Multiplying row i of A by c gives the same effect as multiplying row i of C by c.

>> ○ ⓒ Adding c times row j of A to row i is equivalent to performing the same operation on C.

> ② **Elementary matrix**: A matrix that has the same effect as applying a single elementary row operation.

>> ○ Type 1 elementary matrix: Represents the first elementary operation (ⓐ).

>> ○ Type 2 elementary matrix: Represents the second elementary operation (ⓑ).

>> ○ Type 3 elementary matrix: Represents the third elementary operation (ⓒ).

> ③ **Theorem 1.** All elementary matrices are invertible.

>> ○ The inverse of a type 1 elementary matrix is itself.

>> ○ Inverse of a type 2 elementary matrix

<br>

<img width="262" height="127" alt="스크린샷 2025-12-05 오후 3 46 41" src="https://github.com/user-attachments/assets/6d62e627-ef91-4109-b138-5c2ca03c76ea" />

<br>

>> ○ Inverse of a type 3 elementary matrix

<br>

<img width="182" height="30" alt="스크린샷 2025-12-05 오후 3 47 10" src="https://github.com/user-attachments/assets/52593062-5a40-43b2-affd-c78bc5169a3f" />

<br>

> ④ **Theorem 2.** Any invertible matrix can be expressed as a product of elementary matrices.

<br>

<img width="271" height="68" alt="스크린샷 2025-12-05 오후 3 47 27" src="https://github.com/user-attachments/assets/15c0228c-9a86-4523-8841-1051dee2abd0" />

<br>

> ⑤ **Theorem 3.** All triangular matrices are invertible.

>> ○ Triangular matrix: Either upper triangular or lower triangular.

>> ○ Any n × n triangular matrix A can be expressed as a product of elementary matrices.

>>> ○ First assume the given triangular matrix is upper triangular.

>>> ○ **Step 1.** From the identity matrix, multiply row 2 by a<sub>12</sub> and add it to row 1.

>>> ○ **Step 2.** After **Step 1**, multiply row 3 by a<sub>13</sub> and add to row 1, and multiply by a<sub>23</sub> and add to row 2.

>>> ○ **Step 3.** After **Step 2**, multiply row 4 by a<sub>14</sub> and add to row 1, multiply by a<sub>24</sub> and add to row 2, and multiply by a<sub>34</sub> and add to row 3.

>>> ○ **Step 4.** By repeating this method, the given upper triangular matrix can be expressed using only the identity matrix.

>>> ○ The same process works for lower triangular matrices.

>> ○ Therefore, triangular matrices have inverses and their forms can be determined.

⑷ **Computing inverses 2.** Adjoint matrix

> ① When A is an n × n matrix, removing row i and column j results in an (n-1) × (n-1) matrix.

<br>

<img width="30" height="35" alt="스크린샷 2025-12-05 오후 3 48 20" src="https://github.com/user-attachments/assets/6004356e-c6ea-4c84-b257-c78f9be3a293" />

<br>

> ② Cofactor a<sub>ij</sub>

<br>

<img width="167" height="33" alt="스크린샷 2025-12-05 오후 3 48 43" src="https://github.com/user-attachments/assets/8ca1b084-b1c5-4f27-be3e-6d345cdb14d4" />

<br>

> ③ Laplace expansion

<br>

<img width="271" height="56" alt="스크린샷 2025-12-05 오후 3 49 01" src="https://github.com/user-attachments/assets/fa0adf79-b433-4ae7-905c-eb4f634cf7e3" />

<br>

> ④ Adjoint matrix

<br>

<img width="337" height="77" alt="스크린샷 2025-12-05 오후 3 49 20" src="https://github.com/user-attachments/assets/793bfaea-e8ad-475f-8944-b299cf2a5e1c" />

<br>

> ⑤ Computing the inverse matrix

<br>

<img width="143" height="50" alt="스크린샷 2025-12-05 오후 3 49 37" src="https://github.com/user-attachments/assets/769250f7-aba8-41d9-83b8-c85c39a7e41a" />

<br>

⑸ **Computing inverses 3.** Programming code

> ① Using Python numpy

<br>

```python
import numpy as np

# Define an example matrix A
A = np.array([
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9]
])

# Obtain inverse matrix using numpy.linalg.inv function
try:
    A_inv = np.linalg.inv(A)
    print("A_inv (NumPy):")
    print(A_inv)
except np.linalg.LinAlgError:
    print("There is no inverse matrix.")
```

<br>

> ② Using Python sympy

<br>

```python
import sympy

# Define an example matrix A
A_sym = sympy.Matrix([
    [1, 2, 1],
    [0, 1, 2],
    [1, 2, 3]
])

# Obtain inverse matrix 
try:
    A_sym_inv = A_sym.inv()  # .inv() 메서드 사용
    print("A_inv (Sympy):")
    print(A_sym_inv)
except:
    print("There is no inverse matrix.")
```

<br>

<br>

## **3. Cramer's Rule** 

⑴ Let A be an n × n matrix, **x** = (x<sub>1</sub>, ···, x<sub>n</sub>)', b = (b<sub>1</sub>, ···, b<sub>n</sub>)'. The j-th element of the unique solution x<sub>0</sub> of **Ax** = **b** is:

<br>

<img width="422" height="51" alt="스크린샷 2025-12-05 오후 3 52 35" src="https://github.com/user-attachments/assets/8d16ced3-12f1-4844-940c-6b158bf797dc" />

<br>

⑵ Proof

<br>

<img width="520" height="143" alt="스크린샷 2025-12-05 오후 3 52 49" src="https://github.com/user-attachments/assets/e157df25-2c56-47db-b9c5-c31cebea4b24" />

<br>

---

_Input: 2020.04.22 09:51_

_Revised: 2024.01.01 18:37_
