## **Python Troubleshooting [21-40]**

Higher category **:** 【Python】 [Python Table of Contents](https://jb243.github.io/pages/1892)

---

<br>

#### **21. rpy2.rinterface\_lib.embedded.RRuntimeError: Error in library(ggplot2) : there is no package called 'ggplot2'**

⑴ (package) Solution: Connect to R and then `install.packages('ggplot2')`

<br>

<br>

#### **22. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behavior is the source of the following dependency conflicts.** **stlearn 0.4.5 requires scikit-image>=0.19.2, but you have scikit-image 0.18.3 which is incompatible.**

⑴ (package) Issue: Occurs when executing `pip install stlearn==0.4.5`

⑵ (package) Solution **:** `pip install stlearn==0.4.5 --no-deps`

⑶ **Reference:** [https://stackoverflow.com/questions/12759761/pip-force-install-ignoring-dependencies/12759996#12759996](https://stackoverflow.com/questions/12759761/pip-force-install-ignoring-dependencies/12759996#12759996)

⑷ **Reference:** Not to ignore dependency, refer to <https://turewind-flaseforest-inmoonlight.tistory.com/65>.

<br>

<br>

#### **23. ImportError: cannot import name '\_tsne\_fix' from 'scanpy.tools'**

⑴ (package) Solution: Downgrade `scanpy==1.9.1` to `scanpy==1.7.2`

<br>

<br>

#### **24. ValueError: m has more than 2 dimensions**

⑴ (grammar) Issue: Occurs when using `numpy.corrcoef` and the elements in the input vector arguments are `np.ndarray`

⑵ (grammar) Solution: Convert all elements in the input vector arguments to scalars. Use `~.item()`

<br>

<br>

#### **25. TypeError: Descriptors cannot not be created directly.** **If this call came from a \_pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0. If you cannot immediately regenerate your protos, some other possible workarounds are: 1. Downgrade the protobuf package to 3.20.x or lower. 2. Set PROTOCOL\_BUFFERS\_PYTHON\_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).**

⑴ (package) Solution: Downgrade `protobuf==3.19.1`, then turn off and on anaconda before running again

⑵ Additional information: [https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates%EF%BB%BF](https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates%EF%BB%BF)

<br>

<br>

#### **26. TypeError: only length-1 arrays can be converted to Python scalars**

⑴ (grammar) Issue: Function expects a specific value but an array is passed as an argument

⑵ (grammar) Solution: Use the function for each element in the array

⑶ Solution example

```python
for i in range(len(top)):
    top[i] = -math.log10(top[i])
```

<br>

<br>

#### **27. UnicodeDecodeError: 'cp949' codec can't decode bytes in position : illegal multibyte sequence**

⑴ (grammar) Issue **:** `f = open("example.txt", 'r')`

⑵ Cause: Starting from Python 3, only files encoded in ANSI can be read without specifying a separate encoding method for UTF-8

⑶ (grammar) Solution **:** `f = open("example.txt", 'r', encoding = 'utf-8')`

<br>

<br>

#### **28. TypeError: can only concatenate str (not "int") to str**

⑴ (grammar) Issue: Trying to concatenate an int variable to a str variable

⑵ Issue example **:** `a = 3; print('a = ' + a)`

⑶ (grammar) Solution: Convert the int variable to str using the str() function

⑷ Solution example **:** `a = 3; print('a = ' + str(a))`

<br>

<br>

#### **29. \_csv.Error: field larger than field limit (131072)**

⑴ (grammar) Solution

```python
import sys
import csv

csv.field_size_limit(sys.maxsize)
```

⑵ Reference: [https://stackoverflow.com/questions/15063936/csv-error-field-larger-than-field-limit-131072](https://stackoverflow.com/questions/15063936/csv-error-field-larger-than-field-limit-131072)

<br>

<br>

#### **30. AttributeError: type object 'scipy.spatial.transform.rotation.Rotation' has no attribute 'from\_dcm'**

⑴ (package) Solution: Downgrade to `scipy==1.5.2`

⑵ Reference: [https://github.com/benjiebob/SMALify/issues/22](https://github.com/benjiebob/SMALify/issues/22)

<br>

<br>

#### **31. ERROR: Could not install packages due to an OSError: \[WinError 225\] Operation did not complete successfully because the file contains a virus or potentially unwanted software ... ERROR: Could not install packages due to an OSError: \[WinError 225\] Operation did not complete successfully because the file contains a virus or potentially unwanted software**

⑴ (others) Cause: Package installation is blocked by security software

⑵ (others) Solution 1: Disable the problematic security program as shown in [this](https://softwarekeep.com/help-center/operation-did-not-complete-successfully-because-the-file-contains-a-virus) link

⑶ (others) Solution 2: Download the package on a different computer and transfer it directly to the computer where the package installation fails

<br>

<br>

#### **32. error: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !\_src.empty() in function 'cv::cvtColor'**

⑴ (grammar) Issue: Incorrectly entered directory, failing to properly input the image with `cv2.imread`

<br>

<br>

#### **33. ERROR: Could not find a version that satisfies the requirement git (from versions: none). ERROR: No matching distribution found for git**

⑴ (package) Issue: git is not installed

⑵ (package) Solution: conda install git

```python
conda install git
```

<br>

<br>

#### **34. AttributeError: 'dict' object has no attribute 'iteritems', 'iterkeys' or 'itervalues'**

⑴ (grammar) Issue: Starting from Python3, `.iteritems()`, `.iterkeys()`, and `.itervalues()` functions have been removed, causing this error

⑵ (grammar) Solution: Use the `.items()` function instead

<br>

<br>

#### **35. The current PyTorch install supports CUDA capabilities sm\_37 sm\_50 sm\_60 sm\_70. If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check the instruction.**

⑴ (package) Issue: Currently, RTX 3090 requires CUDA 11 or higher

⑵ (package) Solution: pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html

```python
pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html
```

<br>

<br>

#### **36. ImportError: DLL load failed while importing utilsextension: The specified module could not be found.**

⑴ (package) Issue: There is an issue with the pytables section connected to scanpy in Python 3.8

⑵ (package) Solution

```python
conda install -c conda-forge pytables
```

<br>

<br>

#### **37. AttributeError: module 'tensorflow.keras.layers' has no attribute 'RandomContrast'**

⑴ (grammar) Issue: [tensorflow version 2.11.0](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomContrast) uses `tf.keras.layers.RandomContrast`, while [tensorflow version 2.4](https://en.spec-zone.ru/tensorflow~2.4/keras/layers/experimental/preprocessing/randomcontrast) uses `tf.keras.layers.experimental.preprocessing.RandomContrast`

<br>

<br>

#### **38. NotImplementedError: Cannot convert a symbolic Tensor**

⑴ (package) Solution: Downgrade to `numpy==1.19.5`

<br>

<br>

#### **39. ModuleNotFoundError: No module named 'pydatset'**

⑴ (grammar) Issue: Error occurs when executing the following code:

```python
from pydatset.cifar10 import get_CIFAR10_data
```

⑵ (grammar) Solution: Instead, directly run the following code ([source](https://github.com/dnlcrl/PyDatSet/blob/master/pydatset/cifar10.py))

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import cPickle as pickle
import numpy as np
import os


def get_CIFAR10_data(cifar10_dir, num_training=49000, num_validation=1000, num_test=1000):
    '''
    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare
    it for the neural net classifier.
    '''
    # Load the raw CIFAR-10 data
    X_train, y_train, X_test, y_test = load(cifar10_dir)

    # Subsample the data
    mask = range(num_training, num_training + num_validation)
    X_val = X_train[mask]
    y_val = y_train[mask]
    mask = range(num_training)
    X_train = X_train[mask]
    y_train = y_train[mask]
    mask = range(num_test)
    X_test = X_test[mask]
    y_test = y_test[mask]

    X_train = X_train.astype(np.float64)
    X_val = X_val.astype(np.float64)
    X_test = X_test.astype(np.float64)

    # Transpose so that channels come first
    X_train = X_train.transpose(0, 3, 1, 2)
    X_val = X_val.transpose(0, 3, 1, 2)
    X_test = X_test.transpose(0, 3, 1, 2)

    mean_image = np.mean(X_train, axis=0)
    std = np.std(X_train)

    X_train -= mean_image
    X_val -= mean_image
    X_test -= mean_image

    X_train /= std
    X_val /= std
    X_test /= std

    return {
        'X_train': X_train, 'y_train': y_train,
        'X_val': X_val, 'y_val': y_val,
        'X_test': X_test, 'y_test': y_test,
        'mean': mean_image, 'std': std
    }


def load_CIFAR_batch(filename):
    ''' load single batch of cifar '''
    with open(filename, 'r') as f:
        datadict = pickle.load(f)
        X = datadict['data']
        Y = datadict['labels']
        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype("float")
        Y = np.array(Y)
        return X, Y


def load(ROOT):
    ''' load all of cifar '''
    xs = []
    ys = []
    for b in range(1, 6):
        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))
        X, Y = load_CIFAR_batch(f)
        xs.append(X)
        ys.append(Y)
    Xtr = np.concatenate(xs)
    Ytr = np.concatenate(ys)
    del X, Y
    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))
    return Xtr, Ytr, Xte, Yte
```

<br>

<br>

#### **40. ModuleNotFoundError: No module named 'cPickle'**

⑴ (grammar) Issue: In Python 3, it has been changed to 'pickle'

⑵ (grammar) Solution

```python
pip install pickle
```

<br>

---

*Input **:** 2022-05-09 22:23*
