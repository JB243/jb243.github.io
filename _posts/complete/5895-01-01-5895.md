## 第 9 章随机控制理论

推荐帖子：【控制理论】【控制理论目录】(https://jb243.github.io/pages/1909)

---

**1.** [西格玛代数](#1-西格玛代数)

**2.** [随机控制理论术语](#2-terminology-of-stochastic-control-theory)

**3.** [随机控制理论定律](#3-laws-of-stochastic-control-theory)

**4.** [高级主题](#4-高级主题)

---

**a.** [博弈论](https://jb243.github.io/pages/1914)

**b.** [强化学习](https://jb243.github.io/pages/2162)

**c.** [信仰的力量](https://jb243.github.io/pages/869)

---

<br>

## **1.西格玛代数**

⑴【概率空间】(https://jb243.github.io/pages/1623)

⑵ [Sigma-代数](https://jb243.github.io/pages/910)(σ-algebra)

<br>

<br>

## **2.随机控制理论术语**

⑴ 变量定义

> ① **State**（系统状态）x<sub>t</sub>：表示特定值或随机变量；下同

> ② **观察** y<sub>t</sub>：在完美观察情况下，y<sub>t</sub> = x<sub>t</sub>

> ③ **噪声**（系统噪声）、**干扰**、**误差**、**原始随机变量** w<sub>t</sub>、v<sub>t</sub>

> ④ **系统状态噪声** w<sub>t</sub>

> ⑤ **观察噪声** v<sub>t</sub>

> ⑥ 原始随机种子产生随机不确定性 x<sub>0</sub>

> ⑦ **控制** u<sub>t</sub>

> ⑧ **控制策略/法律/政策** g<sub>t</sub>

<br>

<img width="298" height="231" alt="스크린샷 2025-10-15 10 06 54" src="https://github.com/user-attachments/assets/8b0ca3a5-17d6-451e-8338-dff0aabc9759" />

<br>

> ⑨ **系统状态序列** x<sub>t+1</sub> := f<sub>t</sub>(x<sub>t</sub>, u<sub>t</sub>, w<sub>t</sub>)

> ⑩ **观察序列** y<sub>t</sub> := h<sub>t</sub>(x<sub>t</sub>, v<sub>t</sub>)

> ⑪ **控制输入**，**动作** u<sub>t</sub> := g<sub>t</sub>(y<sub>0:t</sub>, u<sub>0:t-1</sub>)。使用所有过去的信息称为**完美回忆**。

⑵ 按系统顺序分类

> ① **DDS**（确定性系统）：x<sub>t+1</sub> := f<sub>t</sub>(x<sub>t</sub>, u<sub>t</sub>, w<sub>t</sub>) = f<sub>t</sub>(x<sub>t</sub>, u<sub>t</sub>)。 y<sub>t</sub> := h<sub>t</sub>(x<sub>t</sub>, v<sub>t</sub>) = h<sub>t</sub>(x<sub>t</sub>)。在任何时间 t，状态变量 x<sub>t</sub> 和输出变量 y<sub>t</sub> 都是已知的情况。

> ② **SDS**（随机动力学模型）：x<sub>t+1</sub> := f<sub>t</sub>(x<sub>t</sub>, u<sub>t</sub>, w<sub>t</sub>), y<sub>t+1</sub> := h<sub>t</sub>(x<sub>t</sub>, v<sub>t</sub>), w<sub>t</sub>, v<sub>t</sub> ≢ 0。

⑶ 按控制输入分类

> ① **开环控制**：u<sub>t</sub> := g<sub>t</sub>(y<sub>0:t</sub>, u<sub>0:t-1</sub>) = g<sub>t</sub>(u<sub>0:t-1</sub>)。

> ② **反馈控制**：过去的输出 y<sub>0:t</sub> 影响控制动作 u 的情况。

> ③ **集中随机控制：** **(1)** 随机动力系统 + **(2)** 一个控制器 + **(3)** 具有完美召回率的控制器

> ④ **多控制器问题**：团队问题、竞技游戏等。

⑷ 按政策分类

> ① **决策过程**：处理决策问题的一般框架，其中状态、行动和奖励遵循一个过程。

> ② **马尔可夫过程**：（无论是否是决策过程）未来仅取决于当前状态

<br>

<img width="577" height="29" alt="image" src="https://github.com/user-attachments/assets/5ce57777-d8e9-4464-ad03-14c48e2c9e82" />

<br>

>> ○ **马尔可夫链**：马尔可夫过程中，指具有有限或可数无限状态空间的过程。

>> ○ **受控马尔可夫链**：马尔可夫链+决策过程

<br><img width="330" height="26" alt="스크린샷 2025-10-05 오전 2 11 59" src="https://github.com/user-attachments/assets/4433ae56-3122-497e-b289-8897944f23b9" />

<br>

> ③ **MDP**（马尔可夫决策过程）：决策过程中，指未来仅取决于当前状态的情况。

>> ○ **动态规划**：递推关系（打破时间依赖性）。如果说MDP指的是系统框架，那么【动态编程】(https://jb243.github.io/pages/721)指的是方法论。

>> ○ **POMDP**（部分观察马尔可夫决策过程）：只能使用部分信息而不是完整状态信息的 MDP 系统。

>> ○ **受约束的 MDP**、**受约束的 POMDP** 也存在。

>> ○ 【相关算法】(https://jb243.github.io/pages/2162)

> ④ **高斯过程**：状态过程{X<sub>t</sub>}使得任何有限子集服从联合高斯分布。

> ⑤ **高斯-马尔可夫过程**

>> ○ **条件 1.** {X<sub>t</sub>} 是高斯过程。

>> ○ **条件2.** 马尔可夫性质： P(X<sub>n+1</sub> ∈ A ㅣ X<sub>0</sub>,…, X<sub>n</sub>) = P(X<sub>n+1</sub> ∈ A ㅣ X<sub>n</sub>)

<br>

<br>

## **3。随机控制理论定律**

⑴ **引理1.** 在开环控制中，x<sub>t</sub>是x<sub>0</sub>、u<sub>0:t-1</sub>、w<sub>0:t-1</sub>的函数，y<sub>t</sub>是x<sub>0</sub>、u<sub>0:t-1</sub>、w<sub>0:t-1</sub>的函数， v<sub>t</sub>。

<br>

<img width="599" height="207" alt="스크린샷 2025-10-05 2 13 47" src="https://github.com/user-attachments/assets/ac28b4fd-761c-4b26-948d-c19f489626d5" />

<br>

⑵ **引理2.** 开环系统与反馈系统

> ① **开环控制**：u<sub>t</sub> := g<sub>t</sub>(y<sub>0:t</sub>, u<sub>0:t-1</sub>) = g<sub>t</sub>(u<sub>0:t-1</sub>)。

> ② **反馈控制**：过去的输出 y<sub>0:t</sub> 影响控制动作 u 的情况。

> ③ 在DDS 下，开环系统和反馈系统是等效的。

>> ○ 开环 → 反馈的证明：给定一个开环控制输入序列 **u**，定义一个忽略状态的反馈控制（即，在每个时间 t 返回预定 u<sub>t</sub> 的映射）。然后，从初始状态 x<sub>0</sub> 开始，它产生相同的轨迹和成本。因此，无论 DDS/SDS，对于任何开环都存在与初始状态等效的反馈策略。也就是说，开环 ⊂ 反馈始终成立。

>> ○ 反馈证明 → 开环：在 DDS 中，所有控制输入都是唯一确定的（确定性）。因此，如果您预先指定相同的输入序列 **u** 作为开环策略，则结果的状态演化是相同的，成本也是相同的。

> ④ 在 SDS 下，开环系统和反馈系统并不等效。

>> ○ **反例1.**

<br>

<img width="298" height="368" alt="스크린샷 2025-10-05 2 14 49" src="https://github.com/user-attachments/assets/fcac0b86-524a-4099-bcad-0cfe27647da7" />

<br>

>> ○ 在上面的反例中，反馈系统优于开环系统（即，它产生较低的成本）。

<br>

<img width="504" height="237" alt="스크린샷 2025-10-11 오후 5 44 43" src="https://github.com/user-attachments/assets/5c6f4c5d-5fb9-4301-9010-7de04bdf1641" />

<br>

⑶ **引理 3.** **策略独立性**：如果 W<sub>t</sub> 独立于 X<sub>0:t-1</sub>、U<sub>0:t-1</sub>，则 ℙ(x<sub>t+1</sub><sup>g</sup> ∈ A ㅣ x<sub>0:t</sub>, u<sub>0:t</sub>) = ℙ(x<sub>t+1</sub><sup>g</sup> ∈ A ㅣ x<sub>t</sub>, u<sub>t</sub>) = ℙ(f<sub>t</sub>(x<sub>t</sub>, u<sub>t</sub>, w<sub>t</sub>) ∈ A ㅣ x<sub>t</sub>, u<sub>t</sub>) （**马尔可夫性质**），因此对策略 g 的依赖消失了。

<br><img width="300" height="285" alt="스크린샷 2025-10-05 2 16 25" src="https://github.com/user-attachments/assets/a841d6d1-4d9a-46f9-9f78-b5753b49c126" />

<br>

> ① 在DDS中，如果知道当前状态，就可以立即知道下一个状态，但在SDS中，过去的状态很重要，因此历史的条件概率很重要。

> ② 即当w<sub>t</sub>独立时，系统演化遵循自然规律+纯噪声，因此策略无关；但如果 w<sub>t</sub> 取决于策略，则策略会改变噪声分布，因此未来的状态分布取决于策略。

> ③ **哲学：** 从哲学上讲，“政策独立”意味着基于个人价值评估的多元化判断是不可能的，选择受到事实决定的限制。

⑷ **引理 4.** **高斯过程** (GP)

> ①定义：状态过程{X<sub>t</sub>}使得其任意有限子集服从联合高斯分布。

> ② **4-1.** 即使每个 X<sub>i</sub> 是高斯分布，也不意味着 {X<sub>i</sub>}<sub>i∈ℕ</sub> 是 GP。

>> ○ **示例：** X<sub>2</sub> = X<sub>1</sub> *I*{ㅣX<sub>1</sub>ㅣ ≤ k} + (-X<sub>1</sub>) *I*{ㅣX<sub>1</sub>ㅣ > k}，Y = (X<sub>1</sub> + X<sub>2</sub>) / 2 不是 GP。

> ③ **4-2.** 对于 X<sub>t+1</sub> = AX<sub>t</sub> + BU<sub>t</sub> + GW<sub>t</sub>，X<sub>0</sub> ~ 𝒩(0, Σ<sub>0</sub>), W<sub>t</sub> ~ 𝒩(0, Q)，{X<sub>t</sub>} 是 GP。

> ④ **4-3.** 根据反馈政策，{X<sub>t</sub>} 通常不是 GP。

>> ○ **示例：** 如果 U<sub>t</sub> := g<sub>t</sub>(Y<sub>t</sub>) = g<sub>t</sub>(X<sub>t</sub>) = X<sub>t</sub><sup>2</sup>，则 X<sub>1</sub> = AX<sub>0</sub> + BX<sub>0</sub><sup>2</sup> + GW<sub>0</sub>，不是高斯分布。

>> ○ 另一方面，在线性高斯 SDS 中，对于一般的开环策略，状态过程 {X<sub>t</sub>} 始终是高斯的。

> ⑤（注）**MMSE**（最小均方估计量）

<br>

<img width="449" height="38" alt="스크린샷 2025-10-05 9 49 29" src="https://github.com/user-attachments/assets/ef12dfc3-3813-4761-a9b8-33943b51ad30" />

<br>

> ⑥（注）**正交原理**

<br>

<img width="300" height="26" alt="스크린샷 2025-10-05 오전 9 50 20" src="https://github.com/user-attachments/assets/44661695-ddf0-4556-9130-5626fcf459fb" />

<br>

> ⑦（注）**LMMSE**（线性最小均方估计器）

<br>

<img width="161" height="34" alt="스크린샷 2025-10-05 9 50 46" src="https://github.com/user-attachments/assets/a9ec5dab-5b53-4ea7-b6de-e2257b21fdbe" />

<br>

> ⑧ 如果 X 和 Y 共同为高斯分布，则 LMMSE = MMSE 成立。

<br>

<img width="597" height="220" alt="스크린샷 2025-10-13 오후 7 55 13" src="https://github.com/user-attachments/assets/fe6205b8-97b7-4488-8394-83b5cbc8bfb2" />

<br>

⑸ **引理5.** **多步预测**

> ① 一般来说， ℙ(x<sub>t+2</sub><sup>g</sup> ∈ A ㅣ x<sub>t</sub>, u<sub>t</sub>, u<sub>t+1</sub>) ≠ ℙ(x<sub>t+2</sub><sup>g</sup> ∈ A ㅣ x<sub>0:t</sub>, u<sub>0:t+1</sub>)

<br>

<img width="502" height="273" alt="스크린샷 2025-10-05 오전 9 52 01" src="https://github.com/user-attachments/assets/2382de29-9682-47f6-ae97-f2148d18c4dc" />

<br>>> ○ **证明：** 让我们考虑 <span style="color: blue;">x<sub>t</sub></span> → y<sub>t</sub> → <span style="color: blue;">u<sub>t</sub></span> → <span style="color: green;">x<sub>t+1</sub></span> → y<sub>t+1</sub> → <span style="color:绿色;">u<sub>t+1</sub></span> → <span style="color: Orange;">x<sub>t+2</sub></span>。由于与 u<sub>0:t-1</sub> 不独立的 u<sub>t+1</sub> = g<sub>t</sub>(y<sub>0:t+1</sub>, u<sub>0:t</sub>) 意味着通过 xt+1 = f(xt, ut, wt) 有关 w<sub>t</sub> 的信息，因此对 u<sub>t+1</sub> 的条件作用打破了过去的独立性w<sub>t</sub>：这里的“过去”表示x<sub>0:t-1</sub>，u<sub>0:t-1</sub>。

>> ○ **反例1.** 在开环控制中，u<sub>t+1</sub> = g<sub>t</sub>(u<sub>0:t</sub>)成立，因此它不能隐含有关w<sub>t</sub>的信息，因此等式成立。

>> ○ **反例2.** 当w<sub>t</sub>为常数时

>> ○ **反例3.** 当u<sub>t</sub>被定义为具有马尔可夫性质和无记忆反馈时，例如u<sub>t</sub> = μ<sub>t</sub>(x<sub>t</sub>)：则情况如下 y<sub>t</sub> = x<sub>t</sub> = u<sub>t</sub>

<br>

<img width="246" height="333" alt="스크린샷 2025-10-05 9 54 51" src="https://github.com/user-attachments/assets/375d7041-6970-49e6-9623-19563f95ce8d" />

<br>

> ② 开环控制多步预测

<br>

<img width="466" height="35" alt="스크린샷 2025-10-05 오전 9 55 21" src="https://github.com/user-attachments/assets/c10995c6-98a2-44bd-94b7-2036f2485582" />

<br>

> ③ **查普曼-柯尔莫哥洛夫分解**

<br>

<img width="546" height="294" alt="스크린샷 2025-10-05 9 55 47" src="https://github.com/user-attachments/assets/0f52ce9e-6c8f-41a9-9717-2a7e6d5f0218" />

<br>

⑹ **引理 6.** **线性高斯状态空间模型**

> ①（注）**高斯-马尔可夫过程**

>> ○ **条件 1.** {X<sub>t</sub>} 是高斯过程。

>> ○ **条件2.** 马尔可夫性质： P(X<sub>n+1</sub> ∈ A ㅣ X<sub>0</sub>,…, X<sub>n</sub>) = P(X<sub>n+1</sub> ∈ A ㅣ X<sub>n</sub>)

> ② 系统定义

<br>

<img width="198" height="208" alt="스크린샷 2025-10-05 오전 9 57 08" src="https://github.com/user-attachments/assets/1c825a4f-25ea-46b2-b9a4-a7291b845b5f" />

<br>

>> ○ 马尔可夫性质：即使有反馈策略也适用。

<br>

<img width="278" height="27" alt="스크린샷 2025-10-05 9 57 35" src="https://github.com/user-attachments/assets/b0448876-e3a5-4e74-a0c1-546142625455" />

<br>

>> ○ 多步马尔可夫性质

<br>

<img width="446" height="248" alt="스크린샷 2025-10-05 오전 9 58 08" src="https://github.com/user-attachments/assets/dd51a25b-5405-4bc8-a71d-9e3ce6b354f7" />

<br>

>> ○ 平均传播

<br>

<img width="403" height="33" alt="스크린샷 2025-10-05 9 58 34" src="https://github.com/user-attachments/assets/3931106d-6da3-4e15-a25b-00ab4675831c" />

<br>

>> ○ 互协方差 Cov(**X**<sub>t+m</sub>, **X**<sub>t</sub>)

<br>

<img width="498" height="202" alt="스크린샷 2025-10-05 9 59 18" src="https://github.com/user-attachments/assets/eabaf28e-9f85-4074-a97d-a04e47017cfb" />

<br>

>> ○ 协方差传播

<br>

<img width="450" height="191" alt="스크린샷 2025-10-05 9 59 48" src="https://github.com/user-attachments/assets/ece67a8f-b4bb-4e1d-9258-691b8a6ba055" />

<br>

> ③ **DALE**（离散时间代数李亚普诺夫方程）

>> ○ 如果方阵 A 的所有特征值（包括复数）的绝对值都小于 1，则该矩阵定义为稳定：因为 A<sup>∞</sup> = 0。

>> ○ 若 A 稳定，则 Σ<sub>∞</sub> = lim<sub>t→∞</sub> Σ<sub>t</sub> = lim<sub>t→∞</sub> 𝔼[(X<sub>t</sub> - 𝔼[X<sub>t</sub>])(X<sub>t</sub> - 𝔼[X<sub>t</sub>])ᵀ] 唯一存在。

<br><img width="636" height="72" alt="스크린샷 2025-10-05 10 01 17" src="https://github.com/user-attachments/assets/380b05a6-c4db-44e3-a17d-9b8bc1a09f0f" />

<br>

>> ○ Σ<sub>∞</sub>唯一性证明

<br>

<img width="330" height="182" alt="스크린샷 2025-10-11 오후 11 40 32" src="https://github.com/user-attachments/assets/b4715e3b-71ca-47c4-a2e5-ced52ca8fe7c" />

<br>

>> ○ **备注1.** A 的稳定性是**充分**，但**非必要**条件。

>>> ○ 即使 A 不稳定，Σ<sub>∞</sub> 仍可能唯一存在。 

>>> ○ 给出了一个简单的例子 Σ<sub>0</sub> = 0, Q = 0，在这种情况下 Σ<sub>k</sub> ≡ 0 独立于 A。（首先没有噪声。）

>> ○ **备注 2.** Σ<sub>∞</sub> 可能不是严格正定的。

>>> ○ 一个简单的例子是 A = O，rank(GQG<sup>T</sup>) < n。 （噪音并未触及该州的所有方向。）

>> ○ **备注 3.** 如果输入扰动 w<sub>k</sub> 影响状态向量的所有分量，则 A 的稳定性对于 Σ<sub>k</sub> 的收敛是必要的，并且极限协方差 Σ<sub>∞</sub> 将是正定的 → 与可重复性的概念相关。

> ④ **可达性**

>> ○ 定义：在有限时间内能否达到。与可控性和可观测性相关。

<br>

<img width="700" height="115" alt="스크린샷 2025-10-05 10 02 24" src="https://github.com/user-attachments/assets/e8a36fb8-de6d-4914-9044-449c77f95397" />

<br>

>> ○ **定理 1.** 以下都是等价的：假设 w ∈ ℝ<sup>s</sup>

<br>

<img width="700" height="147" alt="스크린샷 2025-10-05 10 02 54" src="https://github.com/user-attachments/assets/1c335335-ac4f-464a-bb0f-65990d3c6cce" />

<br>

>>> ○ 在条件 3 中，噪声序列 w 应解释为应用于系统的控制输入；由于它们，系统可以在 n 个时间步长内从 0 转向给定状态 x。

>> ○ **定理2.** **李亚普诺夫稳定性检验**

<br>

<img width="700" height="131" alt="스크린샷 2025-10-05 10 03 34" src="https://github.com/user-attachments/assets/aeb1568e-edf9-4db7-b5d5-854602df1dd3" />

<br>

>>> ○ 请注意，在条件 2 中，它是 PD（正定），而不是 PSD（正半定）。

⑺ **引理7.** [图论](https://jb243.github.io/pages/616)

> ① 强关联（= 不可约、可传播）

>> ○ 从图中任意节点 i 可以到达任意其他节点 j 的条件。

>> ○ 如果 j 从 j ∀i, j 可达，则马尔可夫链是不可约的。

<br>

<img width="181" height="280" alt="스크린샷 2025-10-05 10 04 05" src="https://github.com/user-attachments/assets/f8a6de25-c6b1-42bf-a3a5-c78649d56a6d" />

**图 1.** “不可约”的示例

<br>

<img width="206" height="311" alt="스크린샷 2025-10-05 10 04 55" src="https://github.com/user-attachments/assets/051ce217-a9e3-4ad8-9689-86c916ec4473" />

**图 2.** “可简化”示例（状态 3 是接收器）

<br>

> ② 周期：特定节点i的周期是从i返回i的所有路径长度的最大公约数

>> ○ 示例：有两个节点 A、B，通过两条边 A=B 连接，每个节点的周期为 2。

>> ○ 在给定适当的置换矩阵 Q 的情况下，当允许状态重排（例如 Q<sup>T</sup>PQ）时，周期为 m 的转移矩阵应具有以下形式。 

<br>

<img width="859" height="170" alt="스크린샷 2025-10-05 10 05 44" src="https://github.com/user-attachments/assets/d92111d7-767e-4d2d-969a-e689714632ba" />

**图 3.** 周期为 m 的转移矩阵示例

S<sub>1</sub>→S<sub>2</sub>→···→S<sub>m</sub>→S<sub>1</sub>→···有这样一个循环。

<br>

> ③ 非周期：所有节点的周期为1。>> ○ 对于不可约马尔可夫链，如果一个状态是非周期的，则所有状态都是非周期的。

>> ○ 示例：如果每个节点都有一条到自身的路径，则它是非周期的。

> ④ 平稳状态：如果 Pr(x<sub>n</sub> ㅣ x<sub>n-1</sub>) 与 n 无关，则马尔可夫过程是平稳的（时不变的）。

> ⑤ 常规

>> ○ 常规 ⊂ 不可缩减

>> ○ 对于某个自然数 k，转移矩阵 M 的幂 M<sup>k</sup> 的每个条目都是正数（即非零）。

> ⑥ 转移矩阵

<br>

<img width="456" height="177" alt="스크린샷 2025-10-05 10 06 49" src="https://github.com/user-attachments/assets/faff3d86-9ccb-4cbd-9c57-76adc359f6a9" />

<br>

> ⑦ 马尔可夫策略：u<sub>t</sub> = g<sub>t</sub>(x<sub>t</sub>)

> ⑧ 利用马尔可夫过程可以证明热力学第二定律（熵增定律）。

>> ○ 因为可以模拟扩散定律：假设有均匀平稳分布。

>> ○ 相关概念：随机游走

> ⑨ **Perron-Frobenius 定理**

>> ○ **定理1.** 如果具有转移矩阵P的**有限**马尔可夫链是强连通的，则恰好存在一个平稳分布**q**。

>>> ○ 平稳分布满足 P**q** = **q**。

>>> ○ 示例：如果 P = I（单位矩阵） ε ℝ<sup>2×2</sup>，则它是可约的，因此对于所有 x ε [0, 1]，存在无限多个 (x, 1-x) 形式的平稳分布。

<br>

<img width="352" height="83" alt="스크린샷 2026-01-17 오후 2 27 57" src="https://github.com/user-attachments/assets/b55296a1-836c-4285-8ab1-ae2068dbaf0a" />

<br>

>> ○ **定理 2.** 如果具有转移矩阵 P 的 **有限** 马尔可夫链是强连通且非周期的，则称为 **遍历马尔可夫链** 并满足：

>>> ○ P<sub>ij</sub>：从节点 j 转移到节点 i 的概率。 Σ<sub>i</sub> P<sub>ij</sub> = 1。注意，P<sub>ij</sub> 表示下面其他**引理**中从节点 i 转移到节点 j 的概率。

>>> ○ **2-1.** 当 k → ∞ 时，P<sup>k</sup> 的 (i,j) 项 P<sub>ij</sub>(k) 收敛到 **q**<sub>i</sub>：请注意，对于固定 i，无论 j 如何，它都会收敛到相同的值。

>>> ○ **2-2.** 无论初始状态 **x**<sub>0</sub> 为何，第 k 状态 **x**<sub>k</sub> 都会随着 k → ∞ 收敛到 **q**。

<br>

<img width="319" height="88" alt="스크린샷 2025-10-12 오후 1 24 03" src="https://github.com/user-attachments/assets/299e8127-0ef5-41b5-a5a0-201769a91b93" />

<br>

>>> ○ 示例：如果 P=((0,1),(1,0))，则它是周期性的（周期=2）。因此，存在唯一的平稳分布 π=(0.5,0.5)，但 $\lim_{k\to\infty} p(k)$ 不会收敛到单一极限，而是分裂成两个子序列（例如，$p^{\text{even }k}=(1,0)$ 和 $p^{\text{odd }k}=(0,1)$）。

<br>

<img width="208" height="122" alt="스크린샷 2026-01-17 오후 2 43 28" src="https://github.com/user-attachments/assets/58c906e9-b054-482d-9889-7f0a32e14483" />

<br>

⑻ **引理 8.** 遵循确定性马尔可夫性质的值函数

> ① 预期成本和转移概率

<br>

<img width="406" height="244" alt="스크린샷 2025-10-12 오후 1 52 21" src="https://github.com/user-attachments/assets/5911d1ab-e6b4-4981-8dc3-33abd34e05ce" />

<br>

> ② **递归和向后迭代**：动态规划 

<br>

<img width="569" height="652" alt="스크린샷 2025-10-05 11 12 32" src="https://github.com/user-attachments/assets/71c9a2a9-e5b2-422e-8b0b-fb0f06a48a29" />

<br>

>> ○ J<sub>T</sub><sup>g</sup> ∈ ℝ<sup>1×1</sup>

>> ○ π<sub>0</sub> ε ℝ<sup>1×n</sup>：马尔可夫链的初始分布

>> ○ V<sub>0</sub><sup>g</sup> ε ℝ<sup>n×1</sup>：收集政策 g 下每个状态的预期累积成本的状态价值函数向量>> ○ 当 T = ∞ 时，J<sup>g</sup> 变为无穷大，无法找到最优策略 g；由此，引入了贝尔曼方程、切萨罗极限概念。

> ③ **贝尔曼方程****：** 下面主要描述贴现成本问题。

>> ○ （注）时间齐次：{x<sub>t</sub><sup>g</sup>}<sub>t≥0</sub> 和 {x<sub>t</sub><sup>g</sup>}<sub>t≥τ,∀τεℤ<sub>+</sub></sub> 遵循相同的分布。也意味着严格静止。

<br>

<img width="841" height="280" alt="스크린샷 2025-10-07 1 34 29" src="https://github.com/user-attachments/assets/279f5a7f-dd38-43c8-985a-6ea3fcd7f6fa" />

<br>

>> ○ **条件 1.** 时间齐次转变： P<sub>t</sub>(j ㅣ i, u) = P(j ㅣ i, u) ∀t

>> ○ **条件 2.** 时间同质成本：C<sub>t</sub>(x, y) = C(x, y) ∀t

>> ○ **条件 3.** 平稳策略：g<sub>t</sub> = g ∀t

>> ○ 如果以上都成立，则可以得到下面的定点方程。

<br>

<img width="398" height="245" alt="스크린샷 2025-10-05 10 10 36" src="https://github.com/user-attachments/assets/2b7ba5cf-3dcb-428a-a5ef-c764e7e6e193" />

<br>

>>> ○ J<sup>g</sup>：成本的现值；一般用于经济领域。

>>> ○ 由于 P<sup>g</sup> 稳定，所有特征值的绝对值均小于 1，因此 det(I - βP<sup>g</sup>) = β det((1/β)I - P<sup>g</sup>) ≠ 0

<br>

<img width="201" height="195" alt="스크린샷 2025-10-05 10 12 01" src="https://github.com/user-attachments/assets/710ac80e-c439-4a5c-b687-ced04c799a26" />

<br>

>>> ○ V<sup>g</sup> ε ℝ<sup>n×1</sup>：状态价值函数向量，收集政策 g 下每个状态的预期贴现累积成本

<br>

<img width="500" height="65" alt="스크린샷 2025-10-05 10 12 57" src="https://github.com/user-attachments/assets/bb1d01b0-e238-4732-96cf-e5ad211e37d1" />

<br>

>>> ○ P<sup>g</sup> ∈ ℝ<sup>n×n</sup>：转移矩阵； (i,j) 条目是从 i 转移到 j 的概率。

> ④ **塞萨罗极限**：与长期平均成本问题有关。

<br>

<img width="553" height="136" alt="스크린샷 2025-10-05 10 13 39" src="https://github.com/user-attachments/assets/e1f7e8d8-a5df-4c59-a8a8-f7ec5ac58903" />

<br>

> ⑤ **泊松方程**：与平均成本有关。

<br>

<img width="503" height="264" alt="스크린샷 2025-10-05 10 14 13" src="https://github.com/user-attachments/assets/bb71851f-1c70-4979-8655-dd0002b9c4b1" />

<br>

>> ○ J<sup>g</sup> 是独一无二的。

<br>

<img width="350" height="253" alt="스크린샷 2025-10-05 10 14 45" src="https://github.com/user-attachments/assets/9f6ccc83-4392-475d-acc0-552829a2c658" />

<br>

>> ○ L<sup>g</sup>：相对值函数。 L<sup>g</sup> 不是唯一的（**∵** L<sup>g</sup> + α**1** ∀α ε ℝ 也是泊松方程的一个解）

>> ○ 解的存在性

<br>

<img width="599" height="273" alt="스크린샷 2025-10-05 10 15 31" src="https://github.com/user-attachments/assets/dc4df273-2ffb-48f3-868b-babcc5be93fa" />

<br>

⑼ **引理 9.** 当不是不可约时

> ① 如果 P<sup>g</sup> 不是不可约的，则状态空间 S 分裂为瞬态 T 和一个或多个循环通信类 C<sub>1</sub>，…

> ② 瞬态：仅访问有限次。最终该过程离开瞬态并进入循环状态。

>> ○ **定理：** 有限状态马尔可夫链的平稳分布 π<sup>g</sup> 将概率 0 分配给所有瞬态。

<br>

<img width="752" height="278" alt="스크린샷 2025-10-07 오후 11 27 58" src="https://github.com/user-attachments/assets/1279e4e6-bb1b-4359-a3c9-8b89164e3686" />

<br>

>> ○ (i) 证明：鸽巢原理。有限性至关重要（并且需要使用）。>>> ○ _假设某个暂态i满足Q<sub>i</sub>=0。由于循环通信类是一个闭集，因此一旦进程进入循环类，就不会与外部节点发生通信。因此，该假设意味着瞬态 i 对于所有 K 个转换仅转变为瞬态。因此，根据鸽巢原理，K+1 个鸽巢中至少有一个瞬态被访问两次（从开始算起），这会产生完全包含在瞬态集中的有向循环。这个循环是封闭的（在这 K 个步骤中没有边将其留给循环类），因此它形成了一个与给定循环类不相交的封闭通信类。在有限马尔可夫链中，每个封闭的通信类都是循环的；因此，我们产生了第二个循环类，这与唯一性假设相矛盾。因此，假设 Q<sub>i</sub> 为假，因此对于每个瞬态 i._ Q<sub>i</sub>>0

>> ○ (ii) 证明

<br>

<img width="439" height="247" alt="스크린샷 2025-10-07 오후 11 28 44" src="https://github.com/user-attachments/assets/04025777-b0c7-491f-916b-830831f83486" />

<br>

> ③循环状态：由于循环通信类是闭集，因此不会与外部节点发生通信。

>> ○ i → j：表示从 i 到 j 存在一条概率为正的路径。

>> ○ i ↔︎ j：表示i → j 且j → i； i 和 j 进行交流。

>> ○ 正循环：返回该状态的平均时间是有限的。

>>> ○ 以正循环状态开始的链具有独特的平稳分布。

>> ○ 零循环：返回该状态的平均时间是无限的。不存在平稳分布。

>>> ○ **示例：** X<sub>n+1</sub> = X<sub>n</sub> + ψ<sub>n</sub>, X<sub>0</sub> = 0, ℙ(ψ<sub>n</sub> = +1) = ℙ(ψ<sub>n</sub> = −1) = 0.5 → 返回原点的概率为 1，但期望时间为 Infini。

>> ○ 吸收状态：一旦进入，就永远处于这种状态

> ④ **例1.** 静止状态集F 

<br>

<img width="300" height="270" alt="스크린샷 2025-10-12 오후 3 34 50" src="https://github.com/user-attachments/assets/1911891b-ac5c-48c9-b212-1d32ae1ef337" />

<br>

> ⑤ **示例2.** 有限状态空间

>> 令 S = {0, 1, ···, I}。由于 V<sup>g</sup>(0) = 0 且 C(0, g(0)) = 0，我们只能关注 Ś = S \ {0} = {1, ···, I}，即非吸收态。令 Ṽ<sup>g</sup> 为 Ś 中状态的值向量，并令 R<sup>g</sup> 为 P<sup>g</sup> 的子矩阵，用于 Ś 内状态之间的转换。 （即，描述链在达到 0 之前如何仅在非吸收状态之间移动的矩阵。）那么这些状态的方程组为 Ṽ<sup>g</sup> = c̃ + R<sup>g</sup>Ṽ<sup>g</sup>。为了显示Ṽ<sup>g</sup>的唯一性，假设有两个解Ṽ<sub>1</sub><sup>g</sup>，Ṽ<sub>2</sub><sup>g</sup>。设它们的差为 U<sup>g</sup> = Ṽ<sub>1</sub><sup>g</sup> - Ṽ<sub>2</sub><sup>g</sup>；两个方程相减得到 U<sup>g</sup> = R<sup>g</sup>U<sup>g</sup> = ⋯ = (R<sup>g</sup>)<sup>n</sup>U<sup>g</sup> = ⋯ = **0** (∵ lim<sub>n→Infini</sub> (R<sup>g</sup>)<sup>n</sup> = 0，无限下降法）⇔ Ṽ<sub>1</sub><sup>g</sup> = Ṽ<sub>2</sub><sup>g</sup>。因此，在状态 0 为吸收且所有其他状态都可以达到 0 的有限状态空间中，首次通过时间成本方程具有唯一的非负解。

> ⑥ **例3.** 可数无限状态空间

<br>

<img width="593" height="164" alt="스크린샷 2025-10-05 10 40 17" src="https://github.com/user-attachments/assets/51e73f3c-8fae-41e3-bc3e-e677123ea938" />

**图4.** 可数无限状态空间图

<br><img width="304" height="176" alt="스크린샷 2025-10-14 오후 9 04 27" src="https://github.com/user-attachments/assets/5e685188-771a-40ac-a097-e9f3623c760a" />

<br>

>> 独特性并非微不足道。假设解是有界的通常可以显示出唯一性。考虑两个解之差的方程 U<sup>g</sup> = R<sup>g</sup>U<sup>g</sup>。将其连接到图上可得出 U<sup>g</sup>(ℓ+1) - U<sup>g</sup>(ℓ) = (λ - 1)(U<sup>g</sup>(ℓ) - U<sup>g</sup>(ℓ-1))。连续差值 Δ(ℓ) = U<sup>g</sup>(ℓ+1) - U<sup>g</sup>(ℓ) 形成比率为 (λ - 1) 的几何序列。如果 <span>|</span>λ - 1<span>|</span> < 1，这些差异收敛于 0，表明有界解。如果 <span>|</span>λ - 1<span>|</span> ≥ 1，差异可能会发散，这意味着唯一性可能会失败。

⑽ **引理 10.** [Martingale](https://jb243.github.io/pages/910)

> ① **杜布定理**

>> ○ σ(X<sub>1</sub>, X<sub>2</sub>, ···, X<sub>n</sub>)：使 X<sub>1</sub>, X<sub>2</sub>, ···, X<sub>n</sub> 可测量的最小 σ 代数。

>> ○ Doob 定理：σ(X<sub>1</sub>, X<sub>2</sub>, ···, X<sub>n</sub>) 等价于 g(X<sub>1</sub>, X<sub>2</sub>, ···, X<sub>n</sub>) 形式的所有函数的集合。

>> ○ σ 代数越大，可测量的函数就越多；即它包含的信息越多。

> ② 过滤

>> ○ 按包含顺序递增的 σ 代数集合。

>> ○ 按 ⊆ 排序；如果 ℱ<sub>1</sub> ⊆ ℱ<sub>2</sub>，则 ℱ<sub>2</sub> 之后是相对于 ℱ<sub>1</sub> 的。

>> ○ 为了方便起见，令时间索引 t = 0, 1, 2, ⋯；则过滤为 {ℱ<sub>t</sub>}<sub>t∈ℤ<sub>+</sub></sub> 并且对于所有 s ≤ t 满足 ℱ<sub>s</sub> ⊆ ℱ<sub>t</sub>。

>> ○ 直觉：代表信息随着观察的积累而增加的情况。

> ③ **鞅**

>> ○ 条件期望的性质

>>> ○ 对于任意随机变量 Y，𝔼[Y ㅣ X<sub>1</sub>, ···, X<sub>n</sub>] = 𝔼[Y ㅣ σ(X<sub>1</sub>, ···, X<sub>n</sub>)] 成立。

>>> ○ 原因：因为 σ(X<sub>1</sub>, ···, X<sub>n</sub>) 等价于 X<sub>1</sub>, ···, X<sub>n</sub> 生成的所有函数的集合。

>>> ○ 另外，当 σ(Y) ⊂ σ(Z) 时，𝔼[𝔼[X ㅣ Z] ㅣ Y] = 𝔼[𝔼[X ㅣ Y] ㅣ Z] = 𝔼[X ㅣ Y]成立。

>> ○ Martingale：随机过程 {X<sub>t</sub>}<sub>t∈ℤ<sub>+</sub></sub> 适应过滤 {ℱ<sub>t</sub>}<sub>t∈ℤ<sub>+</sub></sub> 满足以下所有条件

>>> ○ **条件 1.** X<sub>t</sub> 对于所有 t ∈ ℤ<sup>+</sup> 是 ℱ<sub>t</sub> 可测量的。

>>>> ○ 如果 s ≤ t ≤ s′ 且 ℱ<sub>s</sub>​ ⊆ ℱ<sub>t</sub> ⊆ ℱ<sub>s′</sub>，则 X<sub>t</sub> ∈ ℱ<sub>t</sub> 不是 ℱ<sub>s</sub> 可测（由于信息不足），而是ℱ<sub>s′</sub>-可测量。

>>> ○ **条件 2.** 𝔼[ㅣX<sub>t</sub>ㅣ] 对于所有 t ∈ ℤ<sub>+</sub> 都是有限的。

>>> ○ **条件 3.** 𝔼[X<sub>t</sub> ㅣ ℱ<sub>s</sub>] = X<sub>s</sub>，几乎可以肯定，对于所有 s ≤ t 且所有 t ∈ ℤ<sub>+</sub>

>>>> ○ **解释：** 仅给定时间 s (ℱ<sub>s</sub>) 之前的信息，X<sub>t</sub> 的最优预测等于 X<sub>s</sub>（即，预测被限制为 X<sub>s</sub>；𝔼[X<sub>t</sub> ㅣ ℱ<sub>s</sub>] 是X<sub>t</sub> 进入 ℱ<sub>s</sub> 可测量随机变量空间（“最佳预测”））。

>>>> ○ **备注：** 仅当根据过去预测未来时才需要鞅性质。特别是，对于 s > t，无论 X<sub>t</sub> 是否是鞅（假设可积），我们都有 𝔼[X<sub>t</sub> ㅣ ℱ<sub>s</sub>] = X<sub>t</sub>。>>>> ○ 对于 s < t，𝔼[X<sub>s</sub> ㅣ ℱ<sub>t</sub>] = X<sub>s</sub> 也成立，因为 X<sub>s</sub> 是 ℱ<sub>s</sub> 可测的，但由于 ℱ<sub>s</sub> ⊆ ℱ<sub>t</sub> 信息不足。

>> ○ 注意：i.i.d.过程通常不是鞅（常数过程除外）。

>> ○ 应用：𝔼[U<sup>g</sup>(X<sub>t</sub><sup>g</sup>) ㅣ X<sub>t-1</sub><sup>g</sup>] = U<sup>g</sup>(X<sub>t-1</sub><sup>g</sup>)

> ④ 鞅与随机控制理论

<br>

<img width="605" height="95" alt="스크린샷 2025-10-15 11 58 24" src="https://github.com/user-attachments/assets/0ddcf3f7-d599-4469-96d6-615f0f8356e0" />

<br>

⑾ **引理 11.** (`Fully observed`) ― 最优策略

> ① 问题定义：**完美观察**下的cost-to-go函数。由于控制输入 {U<sub>t</sub>, ..., U<sub>1</sub>} 可以通过 {X<sub>t</sub>, ..., X<sub>0</sub>} 测量，因此以下公式成立：

<br>

<img width="495" height="223" alt="스크린샷 2025-10-07 오후 1 59 08" src="https://github.com/user-attachments/assets/a6f57e3f-04a6-465a-abd4-b063fe9d0eeb" />

<br>

> ② 遵循马尔可夫性质，贝尔曼方程成立。这里，J<sub>t</sub><sup>g</sup>，V<sub>t</sub><sup>g<sup>M</sup></sup>(X<sub>t</sub>)是从t到未来的成本。

<br>

<img width="602" height="96" alt="스크린샷 2025-10-07 오후 2 01 58" src="https://github.com/user-attachments/assets/b7a3e947-d8db-4c15-b0e0-c67e0416eb97" />

<br>
 
> ③ **马尔可夫化定理**（马尔可夫政策充分性，还原为马尔可夫政策）

>> ○ **定理：** 在有限范围 MDP 中，对于任何一般（可能依赖历史和随机）策略 g，都存在一个行为马尔可夫策略 g<sup>M</sup>，使得在相同的初始分布 μ 下，所有 t = 0, ..., T−1 和 X<sub>T</sub> 的 (X<sub>t</sub>, U<sub>t</sub>) 联合分布是相同的。因此，性能（成本）J<sup>g</sup> = 𝔼<sup>g</sup>[Σ<sub>t=0 to T−1</sub> C<sub>t</sub>(X<sub>t</sub>, U<sub>t</sub>) + C<sub>T</sub>(X<sub>T</sub>)] 等于 J<sup>g<sup>M</sup></sup>。因此，在不损失最优性的情况下，人们可以将注意力限制在随机马尔可夫策略上。

<br>

<img width="501" height="80" alt="스크린샷 2025-11-21 오후 4 11 38" src="https://github.com/user-attachments/assets/8688ece9-0b11-4d99-bd5c-84205faf2b4f" />

<br>

>> ○ **证明**

<br>

<img width="497" height="354" alt="스크린샷 2025-10-10 1 54 36" src="https://github.com/user-attachments/assets/8922b0d2-330c-49ad-82f7-071bd5085b60" />

<br>

> ④ **比较原理** 

>> ○ **定理：** 通过从目标向后推导并确保贝尔曼不等式在每一步都成立，初始值 V<sub>0</sub> 作为所有可能政策性能的下界。在每个阶段实现平等的一系列行动共同构成了最优政策。因此，可以通过组合局部最优（阶段式）选择来验证或构造最优性。

<br>

<img width="602" height="232" alt="스크린샷 2025-10-07 오후 2 03 17" src="https://github.com/user-attachments/assets/58b38ece-1ccf-4909-8180-10abdbb725d7" />

<br>

>> ○ 证明：使用【数学归纳法】(https://www.youtube.com/watch?v=t9RBuyBmFdQ) 向后推导

>>> ○ **情况 1.** t = T: 由于 J<sub>T</sub><sup>g</sup> = 𝔼<sup>g</sup>[C<sub>T</sub>(X<sub>T</sub><sup>g</sup>) ㅣ X<sub>T</sub><sup>g</sup>, ..., X<sub>1</sub><sup>g</sup>, X<sub>0</sub>] = C<sub>T</sub>(X<sub>T</sub><sup>g</sup>) ≥ V<sub>T</sub>(X<sub>T</sub><sup>g</sup>) (∵ (V1)) 成立，归纳假设仍然成立。

>>> ○ **情况 2.** 如果归纳假设建立在 ℓ = t+1, ..., T 上，则该假设对于 ℓ = t 仍然成立，可以验证如下：

<br><img width="621" height="551" alt="스크린샷 2025-10-07 오후 2 06 19" src="https://github.com/user-attachments/assets/550f9ab6-e2b5-48bb-b822-51757d4f3b37" />

<br>

>> ○ 推论

<br>

<img width="651" height="77" alt="스크린샷 2025-10-07 오후 2 06 44" src="https://github.com/user-attachments/assets/e83a46bd-c749-4dbf-931a-b6ba3746aa93" />

<br>
 
> ⑤ **哈密尔顿-雅可比-贝尔曼 (HJB) 方程** 

>> ○ 定理：HJB 适用于有限/可数无限、状态/动作空间。贝尔曼方程的连续时间版本。

<br>

<img width="723" height="308" alt="스크린샷 2025-10-07 오후 2 07 21" src="https://github.com/user-attachments/assets/4e828a43-294b-4596-9f0d-7eacd0d6fd2b" />

<br>
 
>> ○ **定理1**的证明已在比较原理中给出，因此以下解释仅与**定理2**相关。

>> ○ p：某个马尔可夫策略 g<sup>M</sup> = {g<sub>t</sub>} 是最优的。

>> ○ q: 给定 ∀x, t, g<sub>t</sub>(x) ∈ arg inf<sub>uε𝒰</sub> {c<sub>t</sub>(x, u) + 𝔼<sub>W<sub>t</sub></sub>[V<sub>t+1</sub>(f<sub>t</sub>(x, u, W<sub>t</sub>))]} （即实现逐步贝尔曼最小化）

>> ○ **定理 2** (q ⇒ p) 的充分性证明：当每个阶段给出 x<sub>t</sub> 时，任何满足下确界的策略都是最优的（∵推论）。那么，u<sub>t</sub>应该是当前状态x<sub>t</sub>的可测函数，最优策略应该是马尔可夫策略。

<br>

<img width="405" height="241" alt="스크린샷 2025-10-12 오후 5 29 43" src="https://github.com/user-attachments/assets/96663f5b-3b96-4958-8291-fb480085cc69" />

<br>

>> ○ **定理 2** 的必要性证明 (p ⇒ q)：如果一个策略是最优马尔可夫策略，它应该在每个阶段实现下确界 (w.p.1)；否则，我们可以构造一个具有正概率集的更好的策略 g'，这意味着 J(g') < J(g)。

<br>

<img width="598" height="718" alt="스크린샷 2025-10-14 오후 6 28 01" src="https://github.com/user-attachments/assets/f45a458e-ba26-419b-8569-c61dd2c6a4ab" />

<img width="598" height="721" alt="스크린샷 2025-10-14 오후 6 28 52" src="https://github.com/user-attachments/assets/ff2e96f0-59e8-4977-926e-998cd5eae7c0" />

<br>

>> ○ 推论 

<br>

<img width="504" height="182" alt="스크린샷 2025-11-09 오전 1 18 06" src="https://github.com/user-attachments/assets/fa51e0ea-6345-435f-b0aa-5d17b8d11152" />

<br>

>> ○ **应用1.** 如果1→6的最优路径为1→2→3→6，则根据HJB方程，2→6的最优路径应为2→3→6。

>> ○ **应用 2.** 政策评估：下面讨论。

>> ○ **应用3.** 由HJB方程得到的V<sub>t</sub>(x)称为价值函数。它有效地减少了搜索空间的大小。

>> ○ **应用 4.** Q 值（状态-动作值函数）： Q<sub>t</sub>(x, u) = C<sub>t</sub>(x, u) + 𝔼<sub>W<sub>t</sub></sub>[V<sub>t+1</sub>(f<sub>t</sub>(x, u, W<sub>t</sub>))], V<sub>t</sub>(x) = inf<sub>uε𝒰</sub> Q<sub>t</sub>(x, u)

>> ○ **应用5.** 对于给定的有限状态/动作空间，inf = min，最优策略是确定性马尔可夫策略。

<br>

<img width="353" height="129" alt="스크린샷 2025-10-14 오후 6 32 30" src="https://github.com/user-attachments/assets/77ec14cb-d146-4d9e-b0d7-f01c80036b04" />

<br>

>> ○ **应用 6.** 随机马尔可夫策略下的价值函数：对于 u ~ μ<sub>t</sub>(u ㅣ i)，

<br>

<img width="451" height="127" alt="스크린샷 2025-10-14 오후 6 32 46" src="https://github.com/user-attachments/assets/6c0d35bf-3d52-4c1a-ab60-4ac0b4d26610" />

<br>

> ⑥（注）【布莱克威尔无关信息原则】(https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-35/issue-2/Memoryless-Strategies-in-Finite-Stage-Dynamic-Programming/10.1214/aoms/1177703586.full)>> ○ 如果 Y 独立于状态并且不直接出现在奖励中，则 Y 与决策无关：忽略 y 的决策规则总是至少一样好。换句话说，拥有更多信息并不总是更好。

<br>

<img width="333" height="40" alt="스크린샷 2025-11-21 오후 3 41 29" src="https://github.com/user-attachments/assets/31a584cc-d912-4962-bfa9-c60b67493be1" />

<br>

>> ○ **示例：** 假设医生必须决定患者的治疗方案。每天早上，医生可以观察患者的健康状况X，此外还知道今天是星期几Y。可用的操作是“治疗”和“不治疗”。如果一周中的某一天与预期奖励（生存概率）和健康状况无关，则仅根据 X 做出决策会产生与同时使用 X 和 Y 相同的预期生存概率。

>> ○ 然而，根据动作空间和可测性等技术假设，该陈述可能需要用ε-最优策略来制定，并且当涉及可数/不可数和可测性陷阱时（例如Borel集的投影可以是非Borel），存在全局近似优势失败的反例。

>> ○ **结论：** 在动态规划问题中，可以从数学上证明无记忆策略足以优化预期奖励。

>> ○ **应用：** 在有限视野马尔可夫决策问题中，可以轻松证明马尔可夫策略是最优的。 （[参考]（https://infostructuralist.wordpress.com/2010/11/08/deadly-ninja-weapons-blackwells-principle-of-irrelevant-information/））

⑿ **引理 12.** (`Partially observed`) ― 信息状态

> ① {z<sub>t</sub>}<sub>t={0,…,T}</sub> 满足以下给定的部分观察上下文

>> ○ 背景：历史 H<sub>t</sub> := {y<sub>0</sub>, ..., y<sub>t</sub>, u<sub>0</sub>, ..., u<sub>t-1</sub>} 随着时间的推移而增加，其域呈指数增长。 （维度的诅咒）

>> ○ **条件 1.** 压缩： z<sub>t</sub> = ℓ<sub>t</sub>(H<sub>t</sub>) ∀t 

>> ○ **条件 2.** 政策/策略独立：z<sub>t+1</sub> = 𝒯<sub>t</sub>(<span style="color: Orange;">z<sub>t</sub></span>, <span style="color: Purple;">y<sub>t+1</sub></span>, <span style="color: Purple;">u<sub>t</sub></span>) (<span style="color: Orange;">■</span>当前状态，<span style="color: Purple;">■</span>新信息）也就是说，z<sub>t</sub>可以使用当前状态和新信息递归更新，而不需要直接引用整个过去的历史。

>> ○ **条件 3.** 相对于 g<sub>0:t-1</sub> 的独立性：∀t = 0, ..., T-1 

<br>

<img width="344" height="124" alt="스크린샷 2025-10-23 오후 8 10 21" src="https://github.com/user-attachments/assets/1203d2c7-fbca-45f1-8b26-2c6dad46b484" />

<br>

> ② **条件 1.** z<sub>t</sub> = H<sub>t</sub> := {y<sub>0</sub>, ..., y<sub>t</sub>, u<sub>0</sub>, ..., u<sub>t-1</sub>}

>> ○ π<sub>0</sub>(i) 如下：

<br>

<img width="257" height="176" alt="스크린샷 2025-10-23 오후 8 11 24" src="https://github.com/user-attachments/assets/8211c709-c647-4fd6-b4e6-1c2542683c72" />

<br>

> ③ **候选人 2.** 信念状态：z<sub>t</sub> = π<sub>t</sub> s.t. π<sub>t</sub>(i) := ℙ(X<sub>t</sub> = i ㅣ H<sub>t</sub>) = ℙ(X<sub>t</sub> = i ㅣ y<sub>0:t</sub>, u<sub>0:t-1</sub>) ∀i ∈ S

>> ○ **满足条件 1**：时间上的 z<sub>t</sub> = ℓ<sub>t</sub>(H<sub>t</sub>)（压缩） 

>> ○ **满足条件2**：直接利用贝叶斯法则可以得到满足 π<sub>t+1</sub> = 𝒯<sub>t</sub>(π<sub>t</sub>, y<sub>t+1</sub>, u<sub>t</sub>) 的𝒯<sub>t</sub>。这是置信状态的更新方程，通常称为非线性滤波器。

<br><img width="857" height="474" alt="스크린샷 2025-10-23 오후 8 15 21" src="https://github.com/user-attachments/assets/c5c00e7f-a564-44ca-b7c4-331af9769031" />

<br>
 
>> ○ **满足条件3**：使用逆向[数学归纳法](https://www.youtube.com/watch?v=t9RBuyBmFdQ)。

>>> ○ **情况 1.** t = T-1：所有项都不依赖于 g<sub>0:T-1</sub>。

<br>

<img width="717" height="467" alt="스크린샷 2025-10-24 오전 9 58 09" src="https://github.com/user-attachments/assets/c28941d6-0a1d-4960-9ec8-c9817ae624c0" />

<br>

>>> ○ **情况 2.** 后向归纳法可以建立如下： 

<br>

<img width="645" height="448" alt="스크린샷 2025-10-24 10 22 35" src="https://github.com/user-attachments/assets/52c0171f-2992-4094-8a14-4fb4d5b4f484" />

<br>

>> ○ **贝尔曼信念方程-MDP：** 该定理的关键信息是，尽管 MDP 的整体策略空间 𝒢 包含从历史到行动的所有映射，因此非常大，但信念 Π<sub>t</sub> 是足够的，因此我们通过将注意力限制在“信念 → 行动”形式的分离策略上，不会失去最优性。

<br>

<img width="725" height="341" alt="스크린샷 2025-10-24 10 31 26" src="https://github.com/user-attachments/assets/87e90a0b-d8d9-48b8-ab37-62ab7658e6f5" />

<br>

>> ○ 证明

<br>

<img width="599" height="460" alt="스크린샷 2025-10-29 10 21 30" src="https://github.com/user-attachments/assets/d0620de5-6974-48b8-8109-b8ed969951f5" />

<br>

>> ○ **应用1.**（单向）分离定理 

<br>

<img width="704" height="148" alt="스크린샷 2025-10-24 오전 11 10 57" src="https://github.com/user-attachments/assets/e97dc972-96ba-41be-9f75-f99b0de5b9d8" />

<br>

>> ○ **应用2.** 置信空间中的成本函数

<br>

<img width="552" height="64" alt="스크린샷 2025-10-24 11 11 17" src="https://github.com/user-attachments/assets/52df06ce-70ff-402b-99be-071c42d34581" />

<br>

>> ○ **应用 3.** 与信念状态不同，以下内容依赖于策略，因为它依赖于 g<sub>t-1</sub>。

<br>

<img width="255" height="33" alt="스크린샷 2025-10-24 11 11 34" src="https://github.com/user-attachments/assets/8543fe60-3f83-4cc4-9ab1-86f31129111d" />

<br>

>> ○ **应用 4.** 与信念状态不同，以下是依赖于策略的：因为如果不包括 u<sub>t</sub> 作为条件 π<sub>t+1</sub> = 𝔼<sub>u<sub>t</sub> ~ p(· ㅣ Y<sub>0:t</sub>) [𝒯<sub>t</sub>(π<sub>t</sub>, y<sub>t+1</sub>, u<sub>t</sub>)] 成立，因此信息状态转换受策略影响。

<br>

<img width="192" height="33" alt="스크린샷 2025-10-24 11 11 51" src="https://github.com/user-attachments/assets/16b92058-3428-4443-abb1-d1cbd2285bc5" />

<br>

>> ○ **应用 5.** 一般来说，P<sup>g</sup>(X<sub>t+1</sub> ∈ A ㅣ H<sub>t</sub>, u<sub>t</sub>) ≠ P<sup>g</sup>(X<sub>t+1</sub> ∈ A ㅣ y<sub>t</sub>, u<sub>t</sub>), H<sub>t</sub> = （Y<sub>0:t</sub>、U<sub>0:t-1</sub>）>>> ○ **证明：** 假设 t = 1。我们考虑 x<sub>0</sub> → y<sub>0</sub> → u<sub>0</sub> → x<sub>1</sub> → y<sub>1</sub> → u<sub>1</sub> → x<sub>2</sub> → ⋯。给定 H<sub>1</sub> = (y<sub>0:1</sub>, u<sub>0</sub>)，我们可以通过 y<sub>0</sub> → x<sub>0</sub> 确定 x<sub>0</sub> 的分布。因此，我们可以通过 y<sub>1</sub> → x<sub>1</sub> 和 (x<sub>0</sub>, u<sub>0</sub>) → x<sub>1</sub> **更准确地**确定 x<sub>1</sub> 的分布。之后，我们可以通过x<sub>1</sub>、u<sub>1</sub>、w<sub>1</sub>确定x<sub>2</sub>的分布。然而，在右侧，我们只能使用 y<sub>1</sub> → x<sub>1</sub> 以及 u<sub>1</sub> 的有限信息来确定 x<sub>1</sub> 的分布，导致 x<sub>2</sub> 的分布不太准确。因此，双方意见不一。

>> ○ **应用 6.** P<sup>g</sup>(X<sub>t+1</sub> A ㅣ H<sub>t</sub>, u<sub>t</sub>) = P<sup>g</sup>(X<sub>t+1</sub> A ㅣ y<sub>0:t</sub>, u<sub>t</sub>)

>>> ○ **证明：** 让我们考虑 x<sub>0</sub> → y<sub>0</sub> → u<sub>0</sub> → x<sub>1</sub> → y<sub>1</sub> → u<sub>1</sub> → x<sub>2</sub> → ⋯。给定策略 g，在右侧，我们可以分别通过 y<sub>0</sub> → u<sub>0</sub> 和 y<sub>0</sub> → x<sub>0</sub> 确定 u<sub>0</sub> 和 x<sub>0</sub> 的分布。因此，我们可以通过 (x<sub>0</sub>, u<sub>0</sub>) → x<sub>1</sub> 来确定 x<sub>1</sub> 的分布。现在利用 u<sub>t</sub> = g<sub>t</sub>(y0:t, u<sub>0:t-1</sub>) 和 x<sub>t+1</sub> = f<sub>t</sub>(x<sub>t</sub>, u<sub>t</sub>, w<sub>t</sub>) ，我们可以确定所有变量的分布，从而彻底得到 x<sub>t+1</sub> 的分布。从左侧看是一样的。

>>> ○ **结论：** 信息状态 Z<sub>t</sub><sup>g</sup> := (Y<sub>0:t</sub><sup>g</sup>, U<sub>0:t-1</sub><sup>g</sup>) 是 Y<sub>0:t</sub><sup>g</sup> 的函数。

>> ○ **应用 7.** P(X<sub>t+1</sub> ∈ A ㅣ H<sub>t</sub>, u<sub>t</sub>) ≠ P(X<sub>t+1</sub> ∈ A ㅣ y<sub>0:t</sub>, u<sub>t</sub>)

>>> ○ **证明：** 让我们考虑 x<sub>0</sub> → y<sub>0</sub> → u<sub>0</sub> → x<sub>1</sub> → y<sub>1</sub> → u<sub>1</sub> → x<sub>2</sub> → ⋯。在右侧，我们可以通过 y<sub>0</sub> → x<sub>0</sub> 确定 x<sub>0</sub> 的分布，但只能在策略集的概率上通过 y0 → u0 确定 u<sub>0</sub> 的分布。然而，u<sub>0</sub> 恰好在左侧给出。因此，双方意见不一。我们可以得出结论，P<sup>g</sup>(X<sub>t+1</sub> ∈ A ㅣ H<sub>t</sub>, u<sub>t</sub>) 是策略无关的，而 P<sup>g</sup>(X<sub>t+1</sub> ∈ A ㅣ y<sub>0:t</sub>, u<sub>t</sub>) 是策略依赖的。

⒀ **引理 13.** 动态规划

> ① 如果 V<sub>t</sub>(i) = max{r(i), a + bΣ<sub>j∈S</sub> ℙ(j ㅣ i) V<sub>t+1</sub>(j)} = max{r(i), a + b𝔼[V<sub>t+1</sub>(j) ㅣ i]}, V<sub>t</sub>(i) ≥ V<sub>t+1</sub>(i)成立。

> ② 如果 V<sub>t</sub>(x) = max{-c + p(x)(1 + V<sub>t+1</sub>(x-1)) + (1 - p(x))V<sub>t+1</sub>(x), V<sub>t+1</sub>(x)}, V<sub>N+1</sub>(x) = 0，则成立：

>> ○ **时间上的单调性：** V<sub>t</sub>(x) ≥ V<sub>t+1</sub>(x) （[证明](https://jb243.github.io/pages/1802))

>> ○ **x 上的单调性：** V<sub>t</sub>(x) ≥ V<sub>t</sub>(x-1) ([证明](https://jb243.github.io/pages/1802))

>> ○ **边际值的上限值：** 1 ≥ V<sub>t</sub>(x) - V<sub>t</sub>(x-1) （[证明](https://jb243.github.io/pages/1802))

>> ○ <span style="color: red">x 上的凹性不成立</span>： V<sub>t</sub>(x) - V<sub>t</sub>(x-1) ≤ V<sub>t</sub>(x-1) - V<sub>t</sub>(x-2) （存在反例）>> ○ **边际价值与时间的关系：** V<sub>t</sub>(x) - V<sub>t</sub>(x-1) ≥ V<sub>t+1</sub>(x) - V<sub>t+1</sub>(x-1) ([证明](https://jb243.github.io/pages/1802))

>> ○ **阈值的存在：** G<sub>t</sub>(x) = p(x)(1 - Δ<sub>t+1</sub>(x)) 在 x 上是非递减的（[证明](https://jb243.github.io/pages/1802)）

> ③ 凸面

>> ○ **引理 1.** 给定两个凸函数 f<sub>1</sub> 和 f<sub>2</sub>，max{f<sub>1</sub>, f<sub>2</sub>} 也是凸函数。

<br>

<img width="284" height="177" alt="image" src="https://github.com/user-attachments/assets/ed125d32-36b4-4e4c-b6f1-7a22ec5062ce" />

**图 5.** 两个凸函数的最大值是凸函数。

<br>

>> ○ **引理 2.** 两个凸函数之和是凸函数。

<br>

<img width="504" height="219" alt="스크린샷 2025-11-03 12 41 32" src="https://github.com/user-attachments/assets/fefd8bd4-6627-4539-9334-a0ac44bd9168" />

<br>

>> ○ **引理 3.** 如果 V(x) 是非减凸函数，则 V(max{x, a}), ∀a 也是凸凸函数：在几何上很容易理解。

>> ○ **引理 4.** 若 L(π) 为凸函数，则 L(π)=sup<sub>i∈I</sub> {α<sub>i</sub> π + β<sub>i</sub>}, α<sub>i</sub>, β<sub>i</sub> ε ℝ 成立。 

>>> ○ 以上来自不等式 f(x) ≥ f(x<sub>0</sub>) + f'(x<sub>0</sub>)(x - x<sub>0</sub>);这并不是说该公式适用于任意选择 α<sub>i</sub> 和 β<sub>i</sub>。

>>> ○ 示例：如果 L(π) = π<sup>2</sup>，则 π<sup>2</sup> = super<sub>x<sub>0</sub>εℝ</sub> {2x<sub>0</sub>π - x<sub>0</sub><sup>2</sup>}。

>>> ○ 实用点：使用在线性（仿射）表示中保留凸性的变换，可以表明对原始凸函数应用相同的变换也可以保留凸性。示例如下。

<br>

<img width="592" height="400" alt="스크린샷 2025-11-08 오후 3 02 29" src="https://github.com/user-attachments/assets/b706e04b-6c32-4d43-a5b9-3a612a3d3df6" />

<br>

⒁ **引理14.** (`Stochastic policy`) DCOE（贴现成本最优方程，无限范围贴现成本贝尔曼方程）

> ①【Banach不动点定理】(https://jb243.github.io/pages/1827) 

>> ○ **定理**

>>> ○ 设 F 为 Banach 空间。这里，Banach空间是指完全赋范空间，集合“完备”意味着集合中的每个柯西序列都收敛于集合中的某个元素。令 T: F → F 为满足以下关系的变换：ㅣㅣTx - Tyㅣㅣ ≤ βㅣㅣx - yㅣㅣ，∃β ∈ (0,1)，∀x, y ∈ F。则有：

>>>> ○ 存在唯一不动点 w ∈ F 满足 Tw = w。

>>>> ○ 对于任意 x ∈ X，lim<sub>n→∞</sub> T<sup>n</sup>x = w。

>>> ○ 这本质上意味着以下内容： 

>>>> ○ 满足上述条件的变换称为收缩。严格来说，它要求sup β(x, y) < 1。

>>>> ○ T 是连续的，具体来说是 Lipschitz 连续的。 

>> ○ **证明**

>>> ○ 令 x ∈ F, α = ㅣㅣx - Txㅣㅣ。那么，我们有ㅣㅣT<sup>n</sup>x - T<sup>n+1</sup>xㅣㅣ ≤ β<sup>n</sup>α。如果我们设置 {x, Tx, T<sup>2</sup>x, ···} 的柯西序列，我们可以得到： ∀ϵ > 0, ∃N<sub>ϵ</sub> s.t。 ∀n, m ≥ N<sub>ϵ</sub>, ㅣㅣT<sup>n</sup>x - T<sup>m</sup>xㅣㅣ < ϵ。不失一般性，我们可以设置n>m。那么，我们有 

<br>

<img width="301" height="316" alt="스크린샷 2025-11-02 8 23 50" src="https://github.com/user-attachments/assets/81a98477-742e-48a5-8585-1f5350369220" />

<br>>>> ○ 因此，我们有 N 服从 αβ<sup>N</sup> / (1 - β) < ϵ。由于 F 是 Banach 空间，因此 w 服从 lim<sub>n→∞</sub> T<sup>n</sup>x = w。由于 T(lim<sub>n→∞</sub> T<sup>n</sup>x) = Tx = lim<sub>n→∞</sub> T<sup>n+1</sup>x = w，所以 w 是一个不动点。如果我们将 w<sub>1</sub>、w<sub>2</sub> 设置为 T 的不动点，则有 ㅣㅣw<sub>1</sub> - w<sub>2</sub>ㅣㅣ = ㅣㅣTw<sub>1</sub> - Tw<sub>2</sub>ㅣㅣ = ⋯ = ㅣㅣT<sup>n</sup>w<sub>1</sub> - Tnw<sub>2</sub>ㅣㅣ = ⋯ = 0，因此 w<sub>1</sub> 和 w<sub>2</sub> 相同。

>> ○ **直觉**

<br>

<img src="https://github.com/user-attachments/assets/cd14d51f-adf9-495f-8f65-f99cd25aa826" width="500" style="max-width:100%; height:auto;" />

<br>

> ②贝尔曼算子和收缩定理

>> ○ **定理**

>>> ○ 令 F 为一组函数，例如 F = {z: S → ℝ}。这里，S = {1, 2, ···, I} 且 z := (z(1), ···, z(I))<sup>T</sup>。让我们定义以下范数： ㅣㅣzㅣㅣ = max<sub>i</sub> ㅣz(i)ㅣ（即ㅣㅣ·ㅣㅣ<sub>∞</sub>） 让我们为每个分量定义运算符 T: F → F。然后，对于所有 i ∈ S，我们有 Tz(i) = min<sub>uε𝒰</sub> [C(i, u) + βΣ<sub>jεS</sub> ℙ(j ㅣ i, u) z(j)]。那么，T就是收缩映射。

>> ○ **证明**

>>> ○ 令 ℝ<sup>I</sup> 为范数为ㅣㅣ·ㅣㅣ<sub>∞</sub> 的 Banach 空间。若z,y ∈ F，则可证明定理如下：

<br>

<img width="606" height="487" alt="스크린샷 2025-11-04 오후 5 30 19" src="https://github.com/user-attachments/assets/12aaf12c-d0c4-4dd1-a708-635e18ef0ddc" />

<br>

>>> ○ 即使我们用成本最大化的特殊定义替换它，收缩定理在相同的证明结构下仍然成立。

> ③ 推论 

>> ○ ∀i ∈ S, W<sub>∞</sub>(i) = min<sub>uε𝒰</sub> C(i, u) + βΣ<sub>jεS</sub> ℙ(j ㅣ i, u) W<sub>∞</sub>(i) 有 w<sub>∞</sub> 的唯一解。

>> ○ DCOE与几何分布的关系

<br>

<img width="497" height="226" alt="스크린샷 2025-11-21 오후 5 20 09" src="https://github.com/user-attachments/assets/d5185470-34f0-417d-99c3-2b4faa9baaa8" />

<br>

>> ○ W<sub>∞</sub>(i) = inf<sub>gε𝒢</sub> J<sup>g</sup>(i) = inf<sub>gε𝒢</sub> 𝔼<sup>g</sup>[Σ<sub>t=0 到 ∞</sub> β<sup>t</sup>c(x<sub>t</sub>, u<sub>t</sub>) ㅣ X<sub>0</sub> = i], ∀i ∈ S

>>> ○ J<sup>g</sup>(i) 和有界的定义 

<br>

<img width="298" height="91" alt="스크린샷 2025-11-09 오후 5 28 13" src="https://github.com/user-attachments/assets/5f1a91e4-8ad7-474d-aa86-d227083b5838" />

<br>

>>> ○ W<sub>∞</sub>的定义：根据收缩映射的性质，递减序列{W<sub>n</sub>}收敛于W<sub>∞</sub>。

<br>

<img width="333" height="100" alt="스크린샷 2025-11-09 오후 5 28 41" src="https://github.com/user-attachments/assets/612c73f4-836a-47fc-a18f-576d482f0d55" />

<br>

>>> ○ J<sup>g</sup>(i) ≥ W<sub>∞</sub>（下界）

<br>

<img width="501" height="97" alt="스크린샷 2025-11-09 오후 5 29 15" src="https://github.com/user-attachments/assets/5a661967-caa6-4ca2-80e1-7d776684df7c" />

<br>

>>> ○ W<sub>∞</sub>(i) ≥ inf<sub>g</sub> J<sup>g</sup>(i)（上界）：可表示为 J(X<sub>0</sub>, π*) ≤ Σ<sub>τ=0 to t-1</sub> β<sup>τ</sup> C<sub>τ</sub>(X<sub>τ</sub>, π<sub>τ</sub>\*) + β<sup>t</sup>𝔼[V<sub>t</sub>(X<sub>t</sub>, π<sub>t</sub>)]。

<br>

<img width="503" height="177" alt="스크린샷 2025-11-09 오후 5 29 56" src="https://github.com/user-attachments/assets/e878167a-af89-40bf-9aa2-e09b59bf6a7d" />

<br>

>>> ○ **结论：** W<sub>∞</sub>(i) = inf<sub>g</sub> J<sup>g</sup>(i) 

>> ○ 最优平稳马尔可夫策略 g*(i) ε argmin<sub>uε𝒢</sub> c(i, u) + βΣ<sub>jεS</sub> ℙ(j ㅣ i, u)V<sub>∞</sub>(j) 

>> <span style="color: White;">○</span> ⇔ W<sub>∞</sub> = c<sup>g\*</sup> + βP<sup>g\*</sup>w<sub>∞</sub>>> <span style="color: White;">○</span> ⇔ W<sub>∞</sub> = (I - βP<sup>g\*</sup>)<sup>-1</sup> c<sup>g\*</sup>

>> ○ 最优算子T定义如下：

<br>

<img width="502" height="72" alt="스크린샷 2025-11-21 오후 5 24 14" src="https://github.com/user-attachments/assets/153d29a0-d827-4360-9938-154be5077b7b" />

<br>

>>> ○ 根据定义，TZ ≤ T<sup>g</sup>Z 

>>> ○ T<sup>g</sup> 和 T 都是 ℓ<sub>∞</sub> 范数上的收缩映射。

>>> ○ T<sup>g</sup> 和 T 都满足单调性：如果 z ≤ y，则 T<sup>g</sup>z ≤ T<sup>g</sup>y 且 Tz ≤ Ty

>>>> ○ 证明1

<br>

<img width="600" height="114" alt="스크린샷 2025-11-21 오후 9 02 06" src="https://github.com/user-attachments/assets/38e68738-71ec-49e2-ae0e-9f29fcca06cc" />

<br>

>>>> ○ 证明2

<br>

<img width="184" height="154" alt="스크린샷 2025-11-21 오후 5 26 27" src="https://github.com/user-attachments/assets/2c6a0a1f-3840-4702-a918-d1a0f88cd57d" />

<br>

>> ○ 若 h, g ∈ 𝒢<sub>SMP</sub>，且 T<sub>h</sub>W<sub>∞</sub><sup>g</sup> ≤ W<sub>∞</sub><sup>g</sup>，W<sub>∞</sub><sup>h</sup> ≤ W<sub>∞</sub><sup>g</sup> 成立： T<sub>h</sub><sup>n</sup>W<sub>∞</sub><sup>g</sup> ≤ ⋯ ≤ T<sub>h</sub>W<sub>∞</sub><sup>g</sup> ≤ W<sub>∞</sub><sup>g</sup>；然后，我们可以将n设为无穷大来得到结论。

> ④ **算法1.** 值迭代

>> ○ 通过重复应用贝尔曼最优算子 T 来更新价值函数的方法，即 V<sub>k+1</sub> = TV<sub>k</sub>。

>> ○ 由于收缩映射性质，如果 β < 1，则 V<sub>k</sub> → V<sup>\*</sup> 收敛到唯一不动点，并且相对于 V<sup>\*</sup> 的贪心策略是最优的。

>> ○ 典型的停止标准是ㅣㅣV<sub>k+1</sub> - V<sub>k</sub>ㅣㅣ<sub>∞</sub> < ε 等。

>> ○ **特点：** 优点是计算简单，缺点是需要多次迭代。

> ⑤ **算法2.** 策略迭代

>> ○ **步骤 1.** 选择任意平稳马尔可夫策略 g<sub>n</sub> ∈ 𝒢<sub>SMP</sub>。

>> ○ **步骤 2.** **策略评估：** 计算 W<sub>∞</sub><sup>g<sub>n</sub></sup> = (I - βP<sup>g<sub>n</sub></sup>)<sup>-1</sup>C<sup>g<sub>n</sub></sup>。

>> ○ **步骤3.** **停止准则：**如果TW<sub>∞</sub><sup>g<sub>n</sub></sup> = W<sub>∞</sub><sup>g<sub>n</sub></sup>，停止并以g<sub>n</sub>为最优策略；否则请转至**步骤 4**。

>> ○ **步骤4.** **策略改进：**定义g<sub>n+1</sub>如下。

<br>

<img width="499" height="123" alt="스크린샷 2025-11-21 오후 5 40 20" src="https://github.com/user-attachments/assets/2446a9c6-11b7-45fa-987a-c71076b97fd1" />

<br>

>> ○ **定理：** 序列 ({g<sub>0</sub>, g<sub>1</sub>, g<sub>2</sub>, …}) 经过有限多次迭代后达到最优策略。

>> ○ **证明：** 当停止条件 W<sub>∞</sub><sup>g<sub>n</sub></sup> = TW<sub>∞</sub><sup>g<sub>n</sub></sup> 成立时，g<sub>n</sub> 已经是最优策略。否则，在**步骤 4** 中，我们有 T<sub>g<sub>n+1</sub></sub> W<sub>∞</sub><sup>g<sub>n</sub></sup> ≤ W<sub>∞</sub><sup>g<sub>n</sub></sup>，并且至少有一个状态是严格不等式的。由于可能的策略数量是有限的（ㅣUㅣ<sup>ㅣSㅣ</sup>），并且每一步的成本都会严格改善（至少在一个状态下），因此无法重新审视相同的策略。因此，该算法通过有限多个步骤达到停止条件并产生最优策略。

>> ○ **特点：** 它的优点是需要迭代次数少得多，但每次迭代时必须在两个算子之间交替（策略评估（由于逆矩阵计算更昂贵）和策略改进）。

> ⑥ **算法3.** 线性规划

>> ○ **定理**

<br><img width="448" height="202" alt="스크린샷 2025-11-21 오후 5 45 43" src="https://github.com/user-attachments/assets/9e07e6b0-5312-4b17-b760-ca81558303c2" />

<br>

>> ○ **证明**

<br>

<img width="561" height="699" alt="스크린샷 2025-11-21 오후 5 46 25" src="https://github.com/user-attachments/assets/982082c8-85d8-42f5-a2c9-0574dc55f9af" />

>> ○ **实现：** [拉格朗日乘子法](https://jb243.github.io/pages/1813)，双最优变量。

<br>

<img width="564" height="728" alt="스크린샷 2025-11-21 오후 5 47 24" src="https://github.com/user-attachments/assets/8a34fc47-040a-4f01-bb4b-aebdc8df282a" />

<br>

⒂ **引理15.** (`Stochastic policy`) ACOE（平均成本最优方程，无限范围平均成本贝尔曼方程）

> ① 概述

>> ○ 对于有限状态空间、有限动作空间和有界成本函数，定义 J<sup>g</sup> 如下：

<br>

<img width="304" height="66" alt="스크린샷 2025-11-21 오후 5 50 30" src="https://github.com/user-attachments/assets/ff545fcc-5a6b-4415-b3f3-3859a2c71111" />

<br>

>> ○ 在不可约马尔可夫链中，考虑泊松方程 J<sup>g</sup>**1** + W<sup>g</sup> = C<sup>g</sup> + P<sup>g</sup>W<sup>g</sup>。

>> ○ 如果 W<sup>g</sup> 是解，则 W<sup>g</sup> + α**1** 也是任意常数 α 的解，但 W<sup>g</sup> 是唯一确定的，直到该可加常数。

>> ○ **ACOE 的推导：**相对值函数 W<sub>N</sub>(i) - W<sub>N</sub>(j) 收敛，N → ∞，对应 W(i) - W(j)。

<br>

<img width="498" height="318" alt="스크린샷 2025-11-21 오후 5 52 51" src="https://github.com/user-attachments/assets/04e19dea-8f7c-4442-81eb-e0ca4eb0f0e9" />

<br>

>> ○ **意义1.** J\* 是最优成本。

>> ○ **意义2.** 最优SMP g\* 必须满足ACOE。

>>> ○ 假设最优策略 g\* 给出如下，并假设该等式对于某些状态 i 不成立。

<br>

<img width="642" height="66" alt="스크린샷 2025-11-21 오후 5 56 46" src="https://github.com/user-attachments/assets/20ad9d71-21fe-40ad-a1af-c075aff355ca" />

<br>

>>> ○ 那么矛盾就出现了，因为g\*失去了最优性，因此最优的g\*必须满足ACOE。

<br>

<img width="350" height="174" alt="스크린샷 2025-11-21 오후 5 57 32" src="https://github.com/user-attachments/assets/03c7334a-4123-4c9e-926c-cc4feeefbfd3" />

<br>

>> ○ **意义3.** 我们可以使用策略迭代。

> ② **算法1.** 策略迭代算法

>> ○ **步骤 1.** 选择任意策略 g<sub>0</sub> ∈ 𝒢<sub>SMP</sub>。

>> ○ **步骤2.** **策略评估：** 给定g<sub>n</sub>，求解以下泊松方程得到(J<sup>g<sub>n</sub></sup>, W<sup>g<sub>n</sub></sup>)。由于我们有 I 个方程，但有 (I+1) 个未知数（J<sup>g<sub>n</sub></sup>、W<sup>g<sub>n</sub></sup>(1)、…、W<sup>g<sub>n</sub></sup>(I)），我们固定一个分量，例如设 W<sup>g<sub>n</sub></sup>(I) = 0)，唯一确定 J<sup>gn</sup>**1** + W<sup>g<sub>n</sub></sup> = C<sup>g<sub>n</sub></sup> + 的解P<sup>g<sub>n</sub></sup>W<sup>g<sub>n</sub></sup>

>> ○ **步骤3.** **停止标准：** 如果g<sub>n</sub> 满足ACOE，则g<sub>n</sub> 是最优SMP。否则，请转到**步骤 4**。 ACOE: J<sup>g<sub>n</sub></sup> + W<sup>g<sub>n</sub></sup>(i) = min<sub>uε𝒰</sub> {C(i, u) + Σ<sub>jεS</sub> P(j ㅣ i, u)W<sup>g<sub>n</sub></sup>(j)}, ∀i

>> ○ **步骤4.** **策略改进**：通过 g<sub>n+1</sub> ε arg min<sub>uε𝒰</sub> {C(i, u) + Σ<sub>jεS</sub> P(j ㅣ i, u)W<sup>g<sub>n</sub></sup>(j)} 定义新策略 g<sub>n+1</sub> 并返回**步骤2**。

>> ○ 如果 g<sub>n</sub> 不满足停止准则，则 J<sup>g<sub>n+1</sub></sup> < J<sup>g<sub>n</sub></sup> 成立。

<br><img width="403" height="198" alt="스크린샷 2025-11-21 오후 6 05 31" src="https://github.com/user-attachments/assets/d6183813-26a0-4c04-bd7f-9f05fa61eb85" />

<br>

> ③ **算法2.** ACOE和相对值迭代

>> ○ 假设：对于每个 g ∈ 𝒢<sub>SMP</sub>，转移矩阵 P<sup>g</sup> 是不可约且非周期的。

>> ○ **步骤 1.** 选择任意 h<sub>0</sub> ∈ ℝ<sup>I</sup>。

>> ○ **步骤 2.** 对于任意 k ≥ 1，

>>> ○ ∀i ∈ S, λ<sup>k</sup>(i) = min<sub>uε𝒰<sub> {C(i, u) + Σ<sub>jεS</sub> P(j ㅣ i, u)h<sup>k-1</sup>(j)}

>>> ○ μ<sup>k</sup> = λ<sup>k</sup>(I) 对于某些固定参考状态 I

>>> ○ ∀i ∈ S, h<sup>k</sup>(i) = λ<sup>k</sup>(i) - μ<sup>k</sup>

>> ○ **步骤3.** 检查收敛性；如果不收敛，则返回**步骤2**。

>> ○ 那么μ<sup>k</sup>收敛到J\*，h<sup>k</sup>收敛到W（相对值函数）。

> ④其他算法

>> ○ 线性规划：如果没有最大值条件，由于 ≤ 不等式（这是比取最小值更强的条件），J* 可以下降到 −∞。

<br>

<img width="458" height="761" alt="스크린샷 2025-11-22 오후 12 08 56" src="https://github.com/user-attachments/assets/aed80b8b-c7c2-433b-a5ef-b46700568255" />

<br>

>> ○ 逐次逼近

<br>

<img width="561" height="691" alt="스크린샷 2025-11-21 오후 6 10 32" src="https://github.com/user-attachments/assets/ec24ca2c-0769-43a7-8daa-739b44f30f22" />

<br>

>> ○ Bertsekas 算法

>> ○ Puterman 算法

> ⑤ MDS（鞅差分序列）

>> ○ **概述：** 对于具体样本路径（随机变量），我们要证明 lim inf<sub>N→∞</sub> Ĵ<sub>N</sub><sup>g</sup>(ω) 对于每个 g 几乎肯定 (a.s.) 如下，并且 lim<sub>N→∞</sub> Ĵ<sub>N</sub><sup>g\*</sup>(ω) = J\*如（假设 g\* 是最优的）

<br>

<img width="254" height="58" alt="스크린샷 2025-11-21 오후 6 13 35" src="https://github.com/user-attachments/assets/d59404d1-d179-4496-8080-403e102a3d3d" />

<br>

>> ○ **定理 1.** 让 {X<sub>k</sub>}<sub>kεℕ</sub> 适应过滤 {ℱ<sub>k</sub>}<sub>kεℕ</sub> 并几乎肯定满足 𝔼[X<sub>k+1</sub> ㅣ ℱ<sub>k</sub>] = 0。那么 X<sub>k</sub> 和 Y<sub>k</sub> = Σ<sub>j=1 到 k</sub> X<sub>j</sub> 是 ℱ<sub>k</sub> 可测的。

>> ○ **定理2.** 鞅稳定性定理（LLN）

<br>

<img width="554" height="127" alt="스크린샷 2025-11-21 오후 6 16 05" src="https://github.com/user-attachments/assets/d4cb53b9-e7e4-4798-ba58-1dceb9f711de" />

<br>

>> ○ **定理 3.** 对于任意 g ε 𝒢，lim<sub>N→∞</sub> inf (1/N) Σ<sub>t=0 到 N-1</sub> C(X<sub>t</sub><sup>g</sup>, U<sub>t</sub><sup>g</sup>) ≥ J\* a.s.成立，如果等式成立，则 g\* 满足 ACOE。

>>> ○ 令 (J\*, W) 为 ACOE 的解。定义 Z<sub>k+1</sub> = C(X<sub>k</sub>, U<sub>k</sub>) - J\* + W(X<sub>k+1</sub>) - W(X<sub>k</sub>) - h(X<sub>k</sub>, U<sub>k</sub>) 和 h(i, u) = C(i, u) + Σ<sub>j∈S</sub> P(j ㅣ i, u)W(j) - J\* - W(i) ≥ 0。设 ℱ<sub>k</sub> = σ(X<sub>0</sub>, X<sub>1</sub><sup>g</sup>, ···, X<sub>k</sub><sup>g</sup>)。然后，给定 U<sub>k</sub><sup>g</sup> = g<sub>k</sub>(X<sub>0</sub>, X<sub>1</sub><sup>g</sup>, ···, X<sub>k</sub><sup>g</sup>)，我们得到 𝔼[Z<sub>k+1</sub> ㅣ ℱ<sub>k</sub>] = 0如下：

<br>

<img width="600" height="307" alt="스크린샷 2025-11-21 오후 6 21 44" src="https://github.com/user-attachments/assets/6fba18d9-3f50-471d-81f2-81f1f8727516" />

<br>

>>> ○ 因此 {Z<sub>k</sub>}<sub>k∈ℕ</sub> 是一个 MDS，并且 Z<sub>k+1</sub> 的每一项都是有界的，因此 Z<sub>k+1</sub> 相对于 M̃ 有界。因此，

<br>

<img width="461" height="68" alt="스크린샷 2025-11-21 오후 6 22 51" src="https://github.com/user-attachments/assets/62b938d4-8088-4d38-a779-beba2bb3ce27" /><br>
  
>>> ○ 成立，根据 LLN，我们有 lim<sub>N→∞</sub> (1/N)Σ<sub>k=1 to N</sub> Z<sub>k</sub> = 0 a.s.但是

<br>

<img width="596" height="118" alt="스크린샷 2025-11-21 오후 6 23 51" src="https://github.com/user-attachments/assets/4e674640-8235-4e5f-a9d3-2ba385de22b1" />

<br>

>>> ○ 成立且 h(·,·) ≥ 0，因此我们有 lim<sub>N→∞</sub> inf (1/N) Σ<sub>t=0 到 N-1</sub> C(X<sub>t</sub><sup>g</sup>, U<sub>t</sub><sup>g</sup>) ≥ J\* a.s.

> ⑥ **定理：** 当 β → 1 时，DCOE 问题与 ACOE 问题等价。

<br>

<img width="601" height="474" alt="스크린샷 2025-11-21 오후 6 25 12" src="https://github.com/user-attachments/assets/5e137370-8b7a-4e72-956b-989b5a73733f" />

<br>

>> ○ 上述证明中ㅣW<sub>β</sub>(i) - W<sub>β</sub>(j)ㅣ < ∞ 的原因。

>>> ○ 定理

<br>

<img width="700" height="152" alt="스크린샷 2025-11-21 오후 6 26 04" src="https://github.com/user-attachments/assets/f5bc8fb2-f89e-410a-b122-8b49144e06a5" />

<br>

>>> ○ 上限

<br>

<img width="639" height="577" alt="스크린샷 2025-11-21 오후 6 26 28" src="https://github.com/user-attachments/assets/3b470b09-1147-428e-9d61-093b9cc3a59f" />

<br>

>>> ○ 下限

<br>

<img width="450" height="375" alt="스크린샷 2025-11-21 오후 6 26 55" src="https://github.com/user-attachments/assets/f28b6d8e-b14e-4f36-8dc5-4d17706bb453" />

<br>

>>> ○ 一般证明

<br>

<img width="646" height="534" alt="스크린샷 2025-11-24 10 37 23" src="https://github.com/user-attachments/assets/ed27ac5f-517e-42e3-bbc7-c6eef2f6f9e8" />

<br>

>> ○ **意义 1.** 最优策略 g<sub>β</sub>\* 不一定收敛于最优 ACOE 策略 g\*。

>> ○ **显着性 2.** Blackwell 最优性：如果相同的策略 g<sub>β</sub>* 对于所有 β̂ < β < 1 的 β 都是最优的，那么 g<sub>β</sub>\* 对于 ACOE 也是最优的。那么，J<sub>β</sub>* = ACOE 最优 J* 也成立。

>>> ○ **证明1.**

<br>

<img width="502" height="157" alt="스크린샷 2025-11-22 오후 12 40 24" src="https://github.com/user-attachments/assets/ac067165-d9f6-4c09-81de-4e72d6c6c6a2" />

<br>

>>> ○ **证明 2.** 在经典的 Blackwell 论证中，您可以通过将两个固定策略 π 和 ν 作为贴现因子函数 f<sub>π,ν</sub>(γ) = V<sub>γ</sub><sup>π</sup> − V<sub>γ</sub><sup>ν</sup> 的函数来比较两个固定策略 π 和 ν。在标准有限 MDP 中，这种差异是 γ 的有理函数，非零有理函数只能有有限多个零。这意味着只有有限多个贴现因子 γ 可以使这两种策略相互关联；超出这些点，它们的排名不能像 γ → 1 那样无限频繁地翻转。因此，对于所有足够接近 1 的 γ，相同的策略仍然是最优的，并且该策略对于平均奖励标准也是最优的；这就是布莱克威尔最优策略。

⒃ **引理 16.** 卡尔曼滤波器

> ① 概述

>> ○ **情况 1.** 纯预测问题 (U<sub>t</sub> ≡ 0)：卡尔曼滤波器。给定 Y<sub>0</sub>,...,Y<sub>t</sub>，问题是预测 X<sub>0</sub>,...,X<sub>t</sub>。

>> ○ **情况 2.** 纯控制问题 (Y<sub>t</sub> = X<sub>t</sub>)：LQR（线性二次调节器）

>> ○ **情况 3.** 具有二次成本的部分观测：LQG（线性二次高斯）。

> ② 回顾：线性高斯过程

<br>

<img width="428" height="532" alt="스크린샷 2025-11-21 오후 6 30 06" src="https://github.com/user-attachments/assets/fc9ff37b-1131-4026-8e3d-51482a28b7e2" />

<br>

> ③ **情况 1.** u<sub>t</sub> ≡ 0 或 B<sub>t</sub> = 0

>> ○ **步骤 1.** 预测

<br>

<img width="650" height="313" alt="스크린샷 2025-11-21 오후 6 30 32" src="https://github.com/user-attachments/assets/b3c106db-0895-4cbe-89d6-5e7dec56bc39" />

<br>

>> ○ **步骤2.** 观测预测

<br><img width="650" height="530" alt="스크린샷 2025-11-21 오후 6 30 56" src="https://github.com/user-attachments/assets/40e0ffda-6532-42c4-9ece-80035ffd86ac" />

<br>

>> ○ **步骤3.** 数据更新

<br>

<img width="651" height="623" alt="스크린샷 2025-11-21 오후 6 31 29" src="https://github.com/user-attachments/assets/d3497d68-d732-4c9b-a61f-ece713590c63" />

<br>

>> ○ **意义：** 从L<sub>t</sub>的形式来看，滤波器是确定性的、非线性的。

>> ○ **应用：** 卡尔曼滤波器的渐近行为

>>> ○ **定义：** 在时不变情况下 A<sub>t</sub> ≡ A, G<sub>t</sub> ≡ G, C<sub>t</sub> ≡ C, H<sub>t</sub> ≡ H。

>>> ○ **背景理论：** _在讨论卡尔曼滤波器的渐近行为时出现可观性的原因是，为了构造一个长期稳定的观测器，系统必须至少是可观的，或者更一般地说，满足可观性。如果存在不可观测模式，则无法使用测量来校正该方向的状态分量。特别是，如果这样的模式不稳定（即，其特征值位于单位圆之外），则无法从输出推断其贡献，并且该方向上的估计误差随着时间的推移而无限制地增长。因此，误差协方差 P<sub>k</sub> 也沿着该方向发散，因此 Riccati 递归不会收敛到有限极限 P<sub>∞</sub>，并且观测器误差无法稳定。因此，为了保证卡尔曼滤波器良好的渐近行为（例如误差协方差的收敛、恒定的稳态卡尔曼增益和稳定的估计），所有不稳定模式都是可观测的，即 (A,C) 对是可观测的，这一点至关重要。_

>>> ○ “Observable”、“Detectabile”和“reachable”具有相同的含义。

<br>

<img width="600" height="227" alt="스크린샷 2025-11-21 오후 6 33 18" src="https://github.com/user-attachments/assets/c253bccc-a926-4bc3-95dc-74b4ddb7dc05" />

<br>

>>> ○ ARE(代数 Riccati 方程) 

<br>

<img width="651" height="289" alt="스크린샷 2025-11-21 오후 6 33 43" src="https://github.com/user-attachments/assets/7d108251-10db-4642-a640-f39a016c2612" />

<br>

>>> ○ 如果 (A,S) 可达，则以下等价： A 稳定。 ⇔ 方程 Σ = AΣA\* + SS\* 有正定解 Σ。 ⇔ 推论

<br>

<img width="651" height="45" alt="스크린샷 2025-11-21 오후 6 34 29" src="https://github.com/user-attachments/assets/69358896-9ae2-46fd-bb12-424179f3e57d" />

<br>

> ④ **情况 2.** 任意 u<sub>t</sub> = g<sub>t</sub>(H<sub>t</sub>) = g<sub>t</sub>(y<sub>0:t</sub>, u<sub>0:t-1</sub>) 和任意 C<sub>t</sub>(x<sub>t</sub>, u<sub>t</sub>)

<br>

<img width="301" height="216" alt="스크린샷 2025-11-27 오후 4 12 13" src="https://github.com/user-attachments/assets/8bf9d5f8-c51c-4228-8ce2-4bde37645c59" />

<br>

>> ○ **结果 1.** (y<sub>0:t</sub><sup>g</sup>, u<sub>0:t-1</sub><sup>g</sup>) 和 y<sub>0:t</sub> 是相同的 σ 代数：每个都是彼此的函数

>>> ○ <b>(y<sub>0:t</sub><sup>g</sup>, u<sub>0:t-1</sub><sup>g</sup>) → y<sub>0:t</sub> 证明：</b> u<sub>0</sub><sup>g</sup> = g<sub>0</sub>(y<sub>0</sub><sup>g</sup>) = g<sub>0</sub>(y<sub>0</sub> + ş<sub>0</sub><sup>g</sup>) 和 y<sub>0</sub> = y<sub>0</sub><sup>g</sup> - c<sub>0</sub>x̄<sub>0</sub><sup>g</sup> = y<sub>0</sub><sup>g</sup> - C<sub>0</sub>𝔼[x<sub>0</sub>]。 x̄<sub>1</sub><sup>g</sup> = A<sub>0</sub>x̄<sub>0</sub><sup>g</sup> + B<sub>0</sub>u<sub>0</sub><sup>g</sup>，所以 ş<sub>1</sub><sup>g</sup> = C<sub>1</sub>x̄<sub>1</sub><sup>g</sup>，导致 y<sub>1</sub> = y<sub>1</sub><sup>g</sup> - ş<sub>1</sub><sup>g</sup>。所以，我们可以这样构造 y<sub>0:t</sub> 。>>> ○ <b>y<sub>0:t</sub> → (y<sub>0:t</sub><sup>g</sup>, u<sub>0:t-1</sub><sup>g</sup>) 证明：</b> 让我们考虑 x<sub>0</sub> → y<sub>0</sub> → u<sub>0</sub> → x<sub>1</sub> → y<sub>1</sub> → u<sub>1</sub> → x<sub>2</sub> → ⋯。 ų<sub>0</sub><sup>g</sup> = c<sub>0</sub>x̄<sub>0</sub><sup>g</sup> 已知。 y<sub>0</sub><sup>g</sup> = y<sub>0</sub> + ş<sub>0</sub><sup>g</sup> 是已知的，u<sub>0</sub><sup>g</sup> = g<sub>0</sub>(y<sub>0</sub><sup>g</sup>) 也是已知的。那么， x̄<sub>1</sub><sup>g</sup> = A<sub>0</sub>x̄<sub>0</sub><sup>g</sup> + B<sub>0</sub>u<sub>0</sub><sup>g</sup> 是已知的，我们也知道 ş<sub>1</sub><sup>g</sup> = c<sub>1</sub>x̄<sub>1</sub><sup>g</sup> 和 y<sub>1</sub><sup>g</sup> = y<sub>1</sub> + ş<sub>1</sub><sup>g</sup>。因此，u<sub>1</sub><sup>g</sup> = g<sub>1</sub>(y<sub>0:1</sub><sup>g</sup>, y<sub>0</sub><sup>g</sup>) 是已知的。因此，命题可以这样证明。

>>> ○ 这与前一个命题相关：P<sup>g</sup>(X<sub>t+1</sub> ∈ A ㅣ H<sub>t</sub>, u<sub>t</sub>) = P<sup>g</sup>(X<sub>t+1</sub> ∈ A ㅣ y<sub>0:t</sub>, u<sub>t</sub>)。

>> ○ **结果 2.** π<sub>t</sub> = ℙ(x<sub>t</sub><sup>g</sup> ㅣ y<sub>0:t</sub><sup>g</sup>, u<sub>0:t-1</sub><sup>g</sup>) = ℙ(x<sub>t</sub><sup>g</sup> ㅣ y<sub>0:t</sub>) 

>> ○ **结果 3.** ℙ(x<sub>t</sub> ㅣ y<sub>0:t</sub>) (= 卡尔曼滤波器) 足以理解系统。

>> ○ **备注 1.** 控制仅影响 x̄<sub>t</sub><sup>g</sup>（均值），而不影响 Σ<sub>tㅣt</sub>（方差）。

>> ○ **备注 2.** 与一般 POMDP 不同，它不需要学习（主动探索）来减少方差。

>> ○ **备注3.** 分离原理：卡尔曼滤波器和控制可以分开。

> ⑤ 动态规划

<br>

<img width="600" height="599" alt="스크린샷 2025-11-27 오후 4 24 42" src="https://github.com/user-attachments/assets/f8840160-ee66-4ed9-99e9-3c3b56142666" />

<br>

> ⑥ 二次成本

>> ○ 假设： C<sub>t</sub>(x<sub>t</sub>, u<sub>t</sub>) = x<sub>t</sub>\*P<sub>t</sub>x<sub>t</sub> + u<sub>t</sub>\*T<sub>t</sub>u<sub>t</sub>, C<sub>T</sub>(x<sub>T</sub>) = x<sub>T</sub>\*P<sub>T</sub>x<sub>T</sub> 

>> ○ 令 X ~ 𝒩(X̄, Σ) 和 S 为对称矩阵，则有 𝔼[X\*SX] = X̄\*SX̄ + Tr(SΣ)。

<br>

<img width="300" height="319" alt="스크린샷 2025-11-27 오후 4 26 42" src="https://github.com/user-attachments/assets/b5437823-a881-41db-9ae6-0463a6ad2a64" />

<br>

>> ○ LQG问题的解决方案

<br>

<img width="655" height="300" alt="스크린샷 2025-11-27 오후 4 27 21" src="https://github.com/user-attachments/assets/93a3f049-c427-48e0-bb3b-4a7f312fd443" />

<br>

>> ○ 证明

<br>

<img width="553" height="445" alt="스크린샷 2025-11-27 오후 4 27 41" src="https://github.com/user-attachments/assets/b790e530-bb4f-47da-9ef9-bf0515b6be9c" />

<br>

>> ○ **备注1.** 确定性等价控制：最优控制策略中不出现噪声项{w<sub>t</sub>}和{v<sub>t</sub>}。

>> ○ **备注2.** 分离原理：通过卡尔曼滤波器进行前向估计，通过求解LQR问题进行控制动作的后向计算。

>> ○ **备注 3.** 如果 Σ<sub>tㅣt</sub> ≡ 0，则 s<sub>t</sub> ≡ 0。

> ⑦ 二次成本和ACOE

<br>

<img width="656" height="227" alt="스크린샷 2025-11-27 오후 4 29 19" src="https://github.com/user-attachments/assets/67ed8e49-13db-42fc-9752-75da2d3169c2" />

<br>

<br>

⒄ **引理 17.** **MAB**（多臂老虎机）

<br>

<img width="493" height="99" alt="스크린샷 2025-12-30 오후 9 33 05" src="https://github.com/user-attachments/assets/9a9e85a7-944a-4875-8345-5abf86e04069" />

**图 6.** MAB

<br>

> ① 公式

>> ○ 前提：N 个随机过程 (X<sub>k</sub><sup>n</sup>)<sub>k=0,1,…； n=1,2,……</sub>

>> ○ 状态集：S = {1, 2, ···, I} 或可数无限集>> ○ 动作集：u<sub>k</sub> ∈ {1, 2, ···, N}

>> ○ 转换规则

<br>

<img width="471" height="144" alt="스크린샷 2025-12-26 오후 5 12 59" src="https://github.com/user-attachments/assets/a6e0e76a-24ce-490e-a3b8-65266b15a0a7" />

<br>

>> ○ **目标：** 我们想要一个最优策略，使得sup<sub>g∈𝒢</sub> 𝔼<sup>g</sup>[Σ<sub>k=0 to ∞</sub> β<sup>k</sup>R(x<sub>k</sub><sup>u<sub>k</sub></sup>)]。

>> ○ **动态规划：** W(x<sup>1</sup>, x<sup>2</sup>, ···, x<sup>N</sup>), x<sup>i</sup> ∈ S(s<sup>N</sup>) = max<sub>u∈{1, 2, ···, N}</sub> R(x<sup>u</sup>) + βΣ<sub>j=1至 I</sub> P(j ㅣ x<sup>u</sup>)W(x<sup>1</sup>, x<sup>2</sup>, ···, x<sup>u-1</sup>, j, x<sup>u+1</sup>, ···, x<sup>N</sup>) 

> ② 理念

>> ○ 要使用动态规划求解多臂老虎机 (MAB)，您必须将所有臂的状态视为一个巨大的状态向量 (x<sub>1</sub>, x<sub>2</sub>, ⋯, x<sub>N</sub>)。

>> ○ 随着臂数（N）的增加，状态空间呈指数级增长，使得计算变得不可行。

>> ○ **关键思想：** 不要共同考虑所有臂，而是单独分析每个臂，为其分配一个分数（指数），然后选择得分最高的臂。 → 这将复杂的 N 臂问题简化为单臂问题：随机臂与静态臂（“1.5 臂”问题）。

>> ○ **设置：** 在您面前，有一台老虎机（随机臂）。在任何时候，您都可以放弃这台机器并退休，以在每个周期（静态臂）永远获得固定奖励（M）（或R*）。

<br>

<img width="349" height="71" alt="스크린샷 2025-12-26 오후 5 01 04" src="https://github.com/user-attachments/assets/83c82a22-bba0-44c1-965a-5ca66900d62f" />

<br>

>> ○ **问题：** 当随机机处于状态 i 时，退休奖励 M 的多少值使您在“继续赌博”和“立即退休”之间完全无差别？ → 该退休奖励水平是状态 (i) 的 **Gittins 指数**。

> ③ **数学定义**

>> ○ 最佳停止时间（τ）：你继续玩机器，当状态变得非常不利以至于你认为“最好退休并选择M”时，你就停止。

<br>

<img width="445" height="57" alt="스크린샷 2025-12-26 오후 4 51 26" src="https://github.com/user-attachments/assets/41fad9af-2cb7-46ac-9e19-e38ad2bdf7a3" />

<br>

>> ○ 直觉：它是你在停止之前（退休前）可以获得的总奖励除以所花费的（折扣后）时间。换句话说，它是你在退休前可以提取的**单位时间平均折扣的最大奖励**。

> ④ **最优性证明：** 交换论证

>> ○ 令 i 为当前 Gittins 指数 (γ) 最高的臂，j 为第二高的臂。

>> ○ 假设（矛盾）策略 g̃ 首先扮演 j。

>> ○ 通过交换顺序（交换参数），我们可以将策略更改为先玩 i，后玩 j，这是最优策略 g，并且总奖励变得大于或等于。这是因为arm i具有较高的“平均奖励率（指数）”，因此在折扣（β）下，当奖励折扣较小时，最好早点做更好的选择。

>> ○ 定义适当的时间间隔（例如 τ<sub>i</sub>、τ<sub>j</sub>）需要一些额外的代数推导。

<br>

<img width="599" height="330" alt="스크린샷 2025-12-26 오후 5 28 38" src="https://github.com/user-attachments/assets/7a083d9f-15dd-4ff2-b277-f7342ce819a8" />

<br>> ⑤ **示例1.** 假设有N台老虎机，记为M<sub>1</sub>, ..., M<sub>N</sub>。每台老虎机 M<sub>i</sub> 的成功概率为 θ<sub>i</sub>，失败概率为 1 − θ<sub>i</sub>。当我们玩一次时，成功时我们会收到 1 的奖励，失败时会收到 0 的奖励。成功概率 θ<sub>1</sub>, ..., θ<sub>N</sub> 是相互独立的随机变量，取值在 [0, 1] 中，它们的先验分布用 P<sub>1</sub>(dθ<sub>1</sub>), ..., P<sub>N</sub>(dθ<sub>N</sub>) 表示（我们假设这些分布允许密度）。在每个时间步，我们只能选择并玩 N 台老虎机中的一台。找到最大化的最优策略
E<sup>g</sup>[Σ<sub>t=0 到 ∞</sub> β<sup>t</sup> r<sub>t</sub>]。

<br>

<img width="360" height="350" alt="스크린샷 2025-11-28 오후 12 40 47" src="https://github.com/user-attachments/assets/c8255892-ae8a-44ee-90f7-15b606ed9016" />

<br>

> ⑥ **示例 2.** 我们考虑一个具有 J 个队列（节点）的小型网络。在每个节点 j ∈ {1, ..., J}，最初有 n<sub>j</sub> 个工作（客户）在排队等待。节点 j 服务单个顾客所需的时间是随机的，其分布具有累积分布函数（CDF）F<sub>j</sub>。当客户在节点 j 完成服务时，会发生以下两种情况之一。以概率 q<sub>jℓ</sub>，客户移动到另一个节点 ℓ 并加入那里的队列；剩余概率为 1 − Σ<sub>ℓ=1 到 J</sub> q<sub>jℓ</sub>，客户完全离开系统。我们假设每当客户在节点 j 完成服务时，我们获得的奖励 r<sub>j</sub> > 0（例如，r<sub>j</sub> 可以解释为公司在节点 j 完成一项工作所获得的收入）。系统中只有一台服务器（worker）。因此，每时每刻我们都必须决定“接下来我们应该服务哪个节点的队列？”我们假设没有新客户从外部到达，我们的目标是随着时间的推移最大化总折扣奖励（总折扣收入）。将这种情况视为多臂老虎机（MAB）问题，每个节点 j 对应一个臂。在每个时间步，我们从集合 {1, 2, ..., J} 中选择一个操作，并为相应节点队列中的一个客户提供服务。客户接下来去哪里是由该节点的概率 q<sub>jℓ</sub> 决定的，因此整体排队状态（每个节点上还有多少客户等）演变为下一个状态。所有节点的联合状态就是强盗问题中的“系统状态”。为了使系统看起来更像一个标准的强盗模型，我们可以添加一个虚构的第（J+1）个节点，代表离开系统的客户的目的地，从而使网络“封闭”。没有实际的服务器分配给这个虚构的节点，因此永远不会选择它作为操作；它只是一个代表离开系统的客户流量的设备。通过这种方式，单个服务器在多个队列中选择在哪里花费时间，每当服务完成时接收奖励，并相应地看到队列状态变化的结构是 MAB 的典型示例。如果根本没有到达，每个队列仅在我们选择提供服务时才会缩小，因此问题是一个相对简单的“休息”强盗（参见 Gittins 策略是最优的）。然而，如果顾客不断从外部到达，那么即使他们没有被选择，队列也会改变状态，这个问题就成为“不安分强盗”的一个例子（参见Gittins索引策略不再是最优的，必须诉诸Whittle索引等概念）。

<br>

<br>

## **4。高级主题**⑴ 去中心化团队（[ref](https://arxiv.org/abs/1002.4172)、[ref](https://arxiv.org/abs/1209.1695)、[ref](https://web.eecs.umich.edu/~teneket/pubs/ASHUTOSH%2CASITYA%2CBOOK.pdf))

⑵ [鲁棒MDP](https://jb243.github.io/pages/1131) ([参考](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa2x1SXJnO TAxMXM5Tnl3bTY2d3lub2Z2UE5EQXxBQ3Jtc0trSnhiLTJab3V2ZENRcnJEaG1JMm9pOHlqeWhIN0tvb1Z1blF0MTJnWl9 pWDNLSmxhSk4tWUtOWDBvT2VLZ2JHdTJQRWxYM1JPdWIxc3lab1lpemswdWQ1bmVTbmlQU3BsNGhvR2pPWU41OTJaUHB0Y w&q=https%3A%2F%2Fcdn.aaai.org%2FWorkshops%2F2004%2FWS-04-08%2FWS04-08-013.pdf&v=u5iEl2nlD2U), [参考](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnlOc0Jkd0VZ S1hLdVpzVE1WLWFyal9nYXRUUXxBQ3Jtc0ttU3VNLUpXWEYzQlNxTjZ3OTV5RnZiR0dmR2ZHZVc0UE13emZiY1ZoWTJFODN RV1Z4RGx6Wm9XbFJQcndXU1hjaXdWSnRCaDlNNU8yZ0hDMDAyV01UMjkzVXJHLVVOM3g4a1RMVkZsNnROU1A4TVRVaw&q=h ttp%3A%2F%2Fwww.corc.ieor.columbia.edu%2Freports%2Ftechreports%2Ftr-2002-07.pdf&v=u5iEl2nlD2U))

⑶ 约束 MDP ([ref](https://scispace.com/papers/denumerable-constrained-markov-decision-processes-and-finite-2jeu04xlpx), [ref](https://link.springer.com/article/10.1007/BF00353877))

⑷强盗（[参考]（https://www.semanticscholar.org/paper/A-dynamic-allocation-index-for-the-discounted-Gittins-Jones/d0c564e32058cd8e5d0bf9455538b64d8a0e2df8）， [参考]（https://people.eecs.berkeley.edu/~russell/classes/cs294/s11/readings/Gittins:1979.pdf），[参考]（https://academic.oup.com/jrsssb/article/42/2/143/7027598）， [参考](https://www.sciencedirect.com/science/article/pii/0196885885900028)，[参考](https://www.jstor.org/stable/2332286))

⑸ 不安分的强盗（[参考]（https://www.semanticscholar.org/paper/Restless-bandits%3A-activity-allocation-in-a-changing-Whittle/45196e90c3b265cbcd008af6e1aac97128e525dc），[参考]（https://arxiv.org/abs/2306.00196））

⑹ 强盗和自适应控制（[参考]（https://ui.adsabs.harvard.edu/abs/1987ITAC...32..968A/abstract），[参考]（https://people.eecs.berkeley.edu/~ananth/1987-1989/Pravin/MarkovMultiarmedbandit.pdf）， [参考](https://people.eecs.berkeley.edu/~ananth/1987-1989/Agrawal/AgrawalIID89.pdf))

⑺ 自适应控制（[参考]（https://www.semanticscholar.org/paper/Asymptotically-Efficient-Adaptive-Choice-of-Control-Graves-Lai/59ef34c2ecca183b7d0ff1788b49f2d5ca3e5ab9）， [参考](https://www.semanticscholar.org/paper/Machine-learning-and-nonparametric-bandit-theory-Lai-Yakowitz/fe611ab14edf4c19fa90e03da42589b0e9c5d5ec))

⑻ 系统识别（线性）（[ref](https://par.nsf.gov/servlets/purl/10312038), [参考](https://www.semanticscholar.org/paper/Finite-Time-Identification-of-Linear-Systems%3A-and-Jedra-Prouti%C3%A8re/9826799d60be5539495bf6df29fcaa928313d94d))

⑼ 系统识别（受控马尔可夫链）（[ref](https://arxiv.org/abs/2509.05193), [ref](https://arxiv.org/abs/2208.08480))

⑽ 线性 SDS 中的策略梯度 ([ref](https://arxiv.org/abs/1801.05039), [ref](https://arxiv.org/abs/2505.01348))

<br>
 
---

_输入：2025.08.26 23:34_