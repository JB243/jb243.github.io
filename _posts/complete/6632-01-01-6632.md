## **第 16 章。线性回归分析**

高级类别：【统计】【统计概述】(https://jb243.github.io/pages/1641)

---

**1.** [回归分析](#1-回归分析)

**2.** [简单线性回归模型](#2-简单线性回归模型)

**3.** [多元线性回归模型](#3-多元线性回归模型)

---

**a.** [R 中的回归分析](https://jb243.github.io/pages/1754) 

--

<br>

## **1. regression analysis** 

⑴回归分析**：**将某一特定变量表示为一个或多个其他变量的依赖关系

> ① 更准确地说，y ~ X（假设 y ∈ ℝ） 

>> ○ 包含在监督算法中

>> ○ (注) 分类: y ~ X (assyming ㅣ { y } | ＜ ∞ ) 

>> ○（注）[Engression](https://arxiv.org/pdf/2307.00835)：虽然一般回归假设 Y = g(X) ± ε，但 engression 模型却是 Y = g(X + ε)，这使得外推成为可能（其中 ε 是噪声）。

> ② 特定变量：名称因变量具有代表性，但有多个名称

>> ○ Response variable 

>> ○ Outcome variable

>> ○ 目标变量

>> ○ Output variable

>> ○ 预测变量

> ③其他变量：名称自变量具有代表性，但有多种名称

>> ○ 实验变量

>> ○ 解释变量

>> ○ 预测变量
 
>> ○ 回归器

>> ○ Covariate

>> ○ 控制变量

>> ○ 调节变量

>> ○ Exposure variable

>> ○ Risk factor

>> ○ Input variable

>> ○ Feature

⑵（比较）交叉分析和方差分析 

> ①回归分析**：**自变量是可测量变量。因变量是可测量变量

>> ○ 回归分析显示自变量与因变量的因果关系

>> ○ 不需要实际因果关系的证明，因为目的就是预测本身 

>> ○ 示例 **:** 6 岁儿童未钙化骨骼的长度可以预测身高的额外增长，但不是因果关系

> ②交叉分析**：**自变量是分类（分类）变量。因变量是分类（分类）变量

>> ○ 交叉分析简单来说就是变量之间相关性的表示

> ③方差分析**：**自变量是分类（分类）变量。因变量是可测量变量

⑶一元回归分析和多元回归分析

> ①简单回归分析**：**具有一个自变量的回归

> ② 多元回归分析**：** 具有多个自变量的回归

⑷ 变量选择方法

> ① 正向选择

>> ○ **步骤 1.** 从仅包含截距的常量模型开始

>> ○ **步骤 2.** 依次添加对模型重要的自变量

> ② 后向淘汰法

>> ○ **步骤 1.** 从包含所有候选自变量的模型开始

>> ○ **步骤 2.** 从基于平方和影响最小的变量开始，一一删除变量

>> ○ **步骤 3.** 继续删除自变量，直到不再有统计上不显着的变量

>> ○ **步骤4.** 此阶段选择型号

> ③ 逐步法

>> ○ 逐步添加：如果现有变量的重要性因添加新变量而减弱，则删除受影响的变量

>> ○ 逐步消除：检查哪些变量被删除，当没有更多变量可以删除时停止

⑸ 选型标准

> ① 概述

>> ○ 模型复杂度惩罚方法

>> ○ 计算所有候选模型的AIC和BIC，选择值最小的模型

> ② AIC（赤池信息准则）>> ○ AIC = -2 ln(L) + 2p（其中ln(L)是模型拟合，L是似然函数，p是参数数量）

<br>

<img width="268" alt="스크린샷 2025-06-07 오후 1 48 18" src="https://github.com/user-attachments/assets/590aeb3d-685d-499f-b43e-8fd21d3e1e50" />

<br>

>> ○ 目的：由于参数多的模型容易过拟合，因此按参数数量的比例进行惩罚。

>> ○ 显示实际数据分布与模型预测分布之间差异的指标

>> ○ 值越低表示模型拟合越好

>> ○ 随着样本量的增加，准确性会降低

> ③ BIC（贝叶斯信息准则）

>> ○ BIC = -2 ln(L) + p ln n（其中ln(L)是模型拟合，L是似然函数，p是参数个数，n是数据点个数）

>> ○ 随着样本量的增加，补偿 AIC 的不准确性

>> ○ 随着样本量的增加，对更复杂的模型进行更严厉的惩罚

> ④ AIC<sub>c</sub> 

>> ○ AIC<sub>c</sub> = AIC + 2K(K+1) / (N-K-1)，其中 N 是样本数 

>> ○ 目的：解决随着样本量增大，AIC 准确度降低的问题。

<br>

<br>

## **2.简单线性回归模型** 

⑴ 定义**：**简单回归分析的情况，其中依赖性显示为线性函数 

⑵ 数据的表示

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/sZKZB/btruiQPFzBX/qyTEL1NQhe15R2fP8ICOs1/img.jpg" alt="绘图" />

<b>图 1.</b> 简单线性回归模型

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/cijkyq/btruiQhRJoS/OmH44OLyVoN1hf8WkQZ4p0/img.png" alt="绘图" />

<br>

> ① β<sub>0</sub> **:** y 截距 

> ② β<sub>1</sub> **:** X 上的斜率或系数 

>> ○ 也称为参数、回归系数、权重等 

>> ○ 直观上来说，弹性就是斜率绝对值大的程度

>> ○ 在微观经济学中，弹性是指斜率乘以(-1)。

> ③回归线的类型

>> ○ 总体回归线**：**根据总体特征得到的回归线

>> ○拟合回归线**：**根据样本特征得到的回归线

> ④ u<sub>i</sub> **:** 残差

> ⑤残差与误差的区别

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/Tk79h/btruyNcrapj/rCn8ERjyjozHJ2sf5Tc6a0/img.png" alt="绘图" />

<br>

>> ○ 后面提到的误差其实就是残差

> ⑥ 方差特征 

>> ○ **同方差****:** <span>VAR(u<sub>i</sub> | X<sub>i</sub>) 和 Xi 是独立的。一个不切实际的假设。许多统计程序的默认设置</span>

>> ○ **异方差性 **:** <span>VAR(u<sub>i</sub> | X<sub>i</sub>) 取决于 X<sub>i</sub></span>

>> ○（注意）具有同方差性的模型是一个好模型 

⑶ 假设 

> ① **假设** **1\.** X<sub>i</sub> 未提供有关错误的任何信息

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/c1sKBQ/btruqFUtWvo/kwnhIsfmKvZ3hRbKNI6emK/img.png" alt="绘图" />

<br>

>> ○ 如果残差图上有模式，则该模型不是好模型 

> ② **假设 2.** (X<sub>i</sub>, y<sub>i</sub>) 是 i.i.d. 

> ③ **假设3.** 4<sup>阶</sup>矩的存在

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/cgTx9Q/btrurx86IZI/diOuVnjYlxtoK80BSgdTF0/img.png" alt="绘图" />

<br>

⑷ 拟合回归线的归纳  > ① **方法1.** [矩](https://jb243.github.io/pages/1630)估计器(MOM)或样本模拟估计的方法 

>> ○ 计算过程

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/dgmehi/btruhvSyyvu/Z88P2NfW3kbOXpjaRGmND1/img.png" alt="绘图" />

<br>

> ② **方法** **2.**最小二乘法或普通最小二乘法（OLS）

>> ○ 定义**：**计算误差平方和的最小值（SSE）

>> ○ 所有统计软件均提供 

>> ○ 计算过程 **:** 如果 X<sub>i</sub> 是一维 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/cynYnX/btruoK2bqqB/TaR0SHeoqqlZSM4hMNPn01/img.png" alt="绘图" />

<br>

>> ○ 最小二乘法基于[最大似然估计](https://jb243.github.io/pages/1630)（假设残差具有同方差性和正态性）

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/YluVP/btruxjbBa01/YtLh6dmTvD6go9KjKJMwsK/img.jpg" alt="绘图" />

<br>

>> ○ X到Y的回归和Y到X的回归一般不一样

>>> ○ E(X<sub>2</sub>), E(XY), E(X)等参与X到Y的回归

>>> ○ E(Y<sub>2</sub>)、E(XY)、E(Y)等参与Y到X的回归

>>> ○ E(X<sub>2</sub>), E(Y<sub>2</sub>), 等造成不对称

> ③ **方法3.** 【交叉熵】(https://jb243.github.io/pages/2145) 

>> ○ 一般定义 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/cd8zj0/btruvtS8yXW/dJLzSxR8kX1qww0X38Xilk/img.png" alt="绘图" />

<br>

>> ○ 二元分类

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/bQXDyL/btrukfhuLA9/isB6TM156Clmbq3pxgUZ71/img.png" alt="绘图" />

<br>

>> ○ 如果 y 表示为 one-hot 向量 \[0, ···, 1, ···, 0\]，则以下成立 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/cvIT9l/btruyMLmmaX/c9Kd54kuIjstZWHKSaPjm0/img.png" alt="绘图" />

<br>

⑸ 回归线的【特点】(https://jb243.github.io/pages/1630) 

> ① 概述

<br>

![图片](https://github.com/user-attachments/assets/f097999c-65c8-4b0e-a1d2-7ae6ca63bd1e)

<br>

> ② 公正性

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/boCSdb/btruwHXFQgG/SKj7yGvQtDqVV8fYbr3Jbk/img.png" alt="绘图" />

<br>

> ③ 效率

>> ○ 高斯-马尔可夫定理**：** OLS 在满足同方差性时有效  

> ④ 一致性

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/bb3UA4/btrusNYQdme/dzsahz21F4tGqTTQjne700/img.png" alt="绘图" />

<br>

> ⑤ 渐近正态性

>> ○ 坡度

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/bWn9P7/btrup8IvvHc/mLpVbL9mRsLE8CZwA7rMd0/img.png" alt="绘图" />

<br>

>> ○ y 截距 - 异方差性 - 稳健标准误

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/3QBdc/btrutlN5E0O/SbyAV8GfYvLlaNwPpnGtI0/img.png" alt="绘图" />

<br>

>> ○ y 截距 - 同方差性-稳健标准误

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/okdsC/btruoKHThbc/v42FgCjckaB7NxNskSNN0k/img.png" alt="绘图" />

<br>

⑹ 回归线的评估

> ① **标准 1.** 线性 

> ② **标准 2.** 同方差性 **：** 具有相等方差的残差项> ③ **标准 3.** 正态性 **:** 遵循正态分布的残差项

>> ○ Box-Cox **：** 在线性回归模型中难以假设正态性的情况下，此方法会将因变量转换为更接近正态分布。

⑺ 决定系数**：**也称为R平方

> ①决定系数R2

>> ○ 定义

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/ACb4x/btrusOKbHXb/H8LZyavZaMPrS6Ip70KkzK/img.jpg" alt="绘图" />

<br>

>>> ○ SST **:** 总变化

>>> ○ SSR **:** 回归方程的变化

>>> ○ SSE **:** 由于错误而发生变化

>>> ○ SSE也称为残差平方和（RSS）、残差平方和（SSR）

>>> ○ 术语 <span style="color=purple">■</span> 为 0** 的原因：** 因为偏差和机会误差的协方差直观上为 0

>> ○ 含义

>>> ○ **含义 1.** X可以描述的Y的方差比例（无单位）

>>> ○ **含义 2.** 回归线描述的平方和 ÷ 总平方和

> ②决定系数与**相关系数的平方**相同

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/bz5sFZ/btruiQCbsu8/NyVU33vYXocMdR0MA5lwO1/img.png" alt="绘图" />

<br>

> ③ 无法解释的方差分数（FVU）

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/cJxPjI/btruomgRtgm/JpHYHPheUpJuZZGWYl8C3k/img.png" alt="绘图" />

<br>

> ④ 特点 

>> ○ 0 ≤ R<sup>2</sup> ≤ 1

>> ○ R<sup>2</sup>越接近1，回归线的拟合优度越好

>> ○ β<sub>1</sub> = 0 的估计量 ⇒ R<sup>2</sup> = 0

>> ○ R<sup>2</sup> = 0 ⇒ β<sub>1</sub> = 0 或 X<sub>i</sub> = 常数的估计量

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/cxNYEg/btrukgHm3yR/Hhb8H1b1CNvO0hlkBr2JZ1/img.png" alt="绘图" />

<br>

⑻平均误差回归

> ① 上证所公式 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/l6oEv/btruiQCbsAP/foXthIxhuPg0ndDr8ryKhK/img.png" alt="绘图" />

<br>

> ②上证所预期值

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/b9DQad/btruxjWWPAn/kTU4ty0G0RZ9CrnmwH78OK/img.png" alt="绘图" />

<br>

>> ○ 总自由度 = 残差自由度 + 回归线自由度

>> ○ 总自由度 = n-1

>> ○ 回归线自由度 = 1 (**∵** 只有一个回归变量)

>> ○ 残差自由度 = n-2 

> ③ 均方误差（MSE）

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/wgFGy/btrutlm10Cr/tgtKUEvQTD15upeZcsF561/img.png" alt="绘图" />

<br>

> ④ 标准误差回归（SER）

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/bOvs2Y/btruuhrPcIc/8k7U8eC7qwqKQRESH1dU10/img.png" alt="绘图" />

<br>

> ⑤ SSE 和无偏方差估计量

<br>

<img width="506" alt="스크린샷 2025-04-11 4 49 28" src="https://github.com/user-attachments/assets/01eac8d9-7eba-4d96-aeac-250a6c41bebd" />

<br>

⑼ **例1.** 回归的词源

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/czRTat/btruiRA0W4x/7hTyaqj5ksYA0hBH6iK41K/img.jpg" alt="绘图" />

<br>

<b>图 2.</b> 回归的词源

<br>

> ① X **:** 父亲的身高

> ② Y **：**儿子的身高> ③ E(X) = 67.7, E(Y) = 68.7, σ<sub>X</sub> = 2.7, σ<sub>Y</sub> = 2.7, ρ<sub>XY</sub> = 0.5 

> ④ <span>E(Y | X = 80) = 74.85</span>

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/ceGnse/btrupHZptl4/uaHcIGIXL7eLCgq8nPkdJ1/img.jpg" alt="绘图" />

<br>

> ⑤ <span>E(Y | X = 60) = 64.85</span>

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/85zQc/btrulR8qm9H/oi0DZnUhi88ZqgsvmWo9a1/img.jpg" alt="绘图" />

<br>

> ⑥结论

>> ○ 高父亲的儿子往往会变矮

>> ○ 父亲矮的儿子往往会长高

>> ○ 儿子身高终于趋于平均水平

>> ○ 然而，由于上述趋势仅基于期望值，因此儿子一代身高的方差不一定低于父亲一代身高的方差 

⑽ **示例 2.** 预测自变量范围之外的 Y 值：也称为外推法

> ①一般情况下不宜采用外推法 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/m6Vst/btruokQWyjX/oD2NnqfFQHdrIrOPxwOlH1/img.png" alt="绘图" />

<b>图 3.</b> 外推问题

<br>

> ② 外推法并不总是错误的

>> ○ 例子**：**生物进化研究

⑾【线性回归和二元正态分布的示例问题分布](https://blog.kakaocdn.net/dn/JMcdz/btsLJABUa7u/kWPry4j0RkcYiqBLKr2vM0/%E1%84%89%E1%85%A5%E1%86%AB% E1%84%92%E1%85%A7%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%2016%E1%84%8C%E1%85%A6.pdf?attach=1&knm=tfile.pdf)

⑿Python代码

<br>

<!-- 使用 hilite.me 生成的 HTML --><div style="background: #ffffff; Overflow:auto;width:auto;border:solid grey;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">来自</span> <span style=“color：#0e84b5; font-weight：bold”>sklearn</span> <span style=“color：#008800; font-weight：bold”>导入</span> Linear_model 
reg <span style="color: #333333">=</span> Linear_model<span style="color: #333333">.</span>LinearRegression() 
reg<span style="color: #333333">.</span>fit([[<span style="color: #0000DD; font-weight: bold">0</span>, <span style="color: #0000DD; font-weight: bold">0</span>], [<span style="color: #0000DD; font-weight: bold">1</span>, <span style="color: #0000DD; font-weight：bold">1</span>]，[<span style="color：#0000DD；font-weight：bold">2</span>，<span style="color：#0000DD；font-weight：bold">2</span>]]，[<span style="color：#0000DD；font-weight：bold">0</span>，<span style="color：#0000DD；字体粗细：粗体">1</span>，<span style="color: #0000DD；字体粗细：粗体">2</span>])
<span style="color: #888888"># 线性回归() </span>
reg<span style="color: #333333">.</span>coef_ 
<span style="color: #888888"># 数组([0.5, 0.5])</span>
</前></div>

<br>

<br>

## **3。多元线性回归模型**  

⑴定义**：**多元回归分析的情况，其中相关性显示为线性函数  

⑵ 省略变量偏差 

> ①定义**：**由于遗漏变量导致误差期望值不为零的现象

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/bBctTY/btruuiK3jMl/zXH1DzE8uFq8rJwuERzbp0/img.png" alt="绘图" />

<br>

>> ○内生变量**：**与ui相关的变量  

>> ○ 外生变量**：** 与 ui 不相关的变量  

> ② **条件1.**省略的变量和回归量（_例如_，X<sub>i</sub>）应该具有相关性

> ③ **条件** **2.**省略的变量应该是Y的决定因素> ④ 斜率的收敛值

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/SiVap/btruuiYxFfD/FHRKEqtrR7bJSkJTwRFLjK/img.png" alt="绘图" />

<br>

>> ○ ρ<sub>Xu</sub> ＞ 0 **:** 向上偏压

>> ○ ρ<sub>Xu</sub> ＜ 0 **:** downward bias

> ⑤ 如果增加新变量时系数值变化较大，则可以说存在遗漏变量基础

⑶ representation of data

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/ZrchP/btrusOXJbPy/AvQEhfc07dkWtuXXb1OL6k/img.png" alt="绘图" />

<br>

> ① 在上述估计量中观察到无偏性、一致性和渐近联合正态性 

> ② 鲁棒性**：** 添加新的回归量不会显着改变回归量的任何斜率值的特性 

> ③灵敏度**：**添加新的回归量会显着改变特定回归量的斜率值的特性 

⑷ 假设

> ① **假设** **1.** 错误不能由 X<sub>1i</sub> 解释，, ···, X<sub>ki</sub>

> ② **假设** 2.** (X<sub>1i</sub>, ···, X<sub>ki</sub>,Y<sub>i</sub>) 是 i.i.d.  

> ③ **假设3.** 存在四阶矩

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/3yOF5/btruuhZFdBj/oA3RnsKBuDd2ZuOjjfBDS0/img.png" alt="绘图" />

<br>

> ④ **假设 4.** 不存在完美多重共线性 

>> ○ 多重共线性 **：**一个自变量与另一个自变量的线性组合高度相关的特征

>>> ○（注）多元线性回归模型期望自变量真正独立 

>> ○ 完美多重共线性**：** 如果一个回归量与其他回归量具有完美线性。行列式值 = 0

>>> ○ 完美多重共线性不是变量的本质，而是数据集的本质

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/6qSEL/btruvtS8BtR/TTSE8dWjZYzdxdZWpRQn4K/img.png" alt="绘图" />

<br>

>>> ○ 当您尝试对完美多重共线性数据进行回归分析时，可能的系数数量是无限的**：** **不可能** 执行回归分析 

>> ○ 不完美多重共线性 **:** 两个或多个回归变量只是高度相关

>>> ○ 立刻不是问题

>>> ○ 斜率估计器的方差相当大 → 难以信任斜率估计器

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/chFfWK/btrupHLP76O/o8dD1PvS7hRcARONjFuoH0/img.png" alt="绘图" />

<b>图4.</b>多重共线性增加斜率估计量方差的原因

⒝ 显着性区间内可能存在多种平面

<br>

>>> ○ 一般来说，一对变量的相关性不应超过0.9

>> ○ 解决方案

>>> ○ 绘制所有组合的成对图并删除高度相关的变量

>>> ○ PCA、加权和等可以尝试，但各有各的缺点

>> ○（注）R Studio 在分析完美多重共线性数据时随机忽略最后一个有问题的项

⑸ OLS估计器**：**通过计算以下联立方程来确定系数 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/nIKy5/btruxkn3Btx/zky6kzyIRiKrhEY0Puekjk/img.png" alt="绘图" />

<br>

⑹ 回归线的特点

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/c8J2a5/btruxjbBkgI/eXKOiB63Kf7RVPGbITlfw0/img.png" alt="绘图" /><br>

> ① 公正性

> ②一致性 

> ③渐近联合正态性

> ④ 弗里希-沃定理 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/RR4jG/btruxkVQ5eU/8R4xFd02dQFB4vjbndrDLK/img.png" alt="绘图" />

<br>

⑺调整R<sup>2</sup>

> ①R<sup>2</sup>的缺点 **：**拟合程度在多元回归模型中没有得到很好的体现

>> ○ **缺点 1.** 每当添加新的回归量时，R<sup>2</sup> 总是会增加，因为 SSE 的最小值会减小

>> ○ **缺点 2.** 高 R<sup>2</sup> 无法验证是否存在遗漏变量偏差  

>> ○ **缺点 3****.** 高 R<sup>2</sup> 不能验证当前回归器是否最优 

>> ○ 为解决**缺点1**，引入调整后的R2

> ② 公式

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/nu9lX/btrupHrtUBG/e8JzC4Q1MKPW5Gg9zcehlk/img.png" alt="绘图" />

<br>

> ③特点 

>> ○ 调整后的 R<sup>2</sup> ≤ R<sup>2</sup>

>> ○ 调整后的 R<sup>2</sup> 可以为负值

>> ○ 添加不适当的变量后，值会减小

⑻ 标准误差回归（SER）**：** k 为回归方程中自变量的数量

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/nNrO6/btrupJv74dZ/nxSkMFzIp2d2q44KpKURfK/img.png" alt="绘图" />

<br>

⑼ 联合假设**：**当存在大于或等于2个约束条件时的假设

> ① **想法 1.** t1 和 t2 是独立的

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/b8TqH8/btruokDlbtu/EVJEOJutd409fRTJHBVQk0/img.png" alt="绘图" />

<br>

② **想法2.** t<sub>1</sub> 和 t<sub>2</sub> 存在多重共线性

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/PosAK/btrupIcQh5s/vanaA3w9fAd1Vxy30Pb5FK/img.png" alt="绘图" />

<br>

> ③一般情况

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/c31GQE/btrusPbgpS1/3UvyXatamtsMreKe5jybC0/img.png" alt="绘图" />

<br>

>> ○ 一般情况下，使用异方差稳健 F 统计量

>> ○ 许多统计程序都将同方差稳健 F 统计量作为默认设置

> ④原假设 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/btXHw7/btruok4pD21/HTJgHjUpJVZR4yFZjgxxU1/img.png" alt="绘图" />

<br>

⑽ 多元线性回归模型的重新定义 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/oULUo/btruolWxF5k/0lZgvKViebgkeqjPangrDk/img.png" alt="绘图" />

<br>

> ① H<sub>0</sub> **:** 如果要测试 β<sub>1</sub> = β<sub>2</sub>,  

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/bl3OeN/btruvt6BCUh/2TVTBePtmAPsCWBKmpA5C0/img.png" alt="绘图" />

<br>

> ② H<sub>0</sub> **:** 如果要测试 β<sub>1</sub> + β<sub>2</sub> = 1, 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/6pKSd/btruyOCqHsl/Fid7PrAZp0raeSZ4Xj5pV1/img.png" alt="绘图" />

<br>

⑾ 条件平均独立性

> ①定义

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/dWcbsF/btruuic9o6t/B7yySIothueoHTy43rT7d1/img.png" alt="绘图" />

<br>

> ② 对于给定的 X<sub>2i</sub>，X<sub>1i</sub> 与 ui 不相关 

> ③ β<sub>2</sub> 可能不具有一致性**：** 但这并不重要 

⑿ 矩阵表示法

> ①线性回归模型>> ○ 对于标量 Y、列向量 X 和 β， 

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/chIJYG/btruyOblLQS/KhkkJUMLg0OiBlYo5C2wk1/img.png" alt="绘图" />

<br>

>> ○ 概括

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/crQLrc/btrusN5CvIS/ravPQE4gCf7YXvYDaaJMIk/img.png" alt="绘图" />

<br>

> ②假设

>> ○ **假设 1.** E(u<sub>i</sub> | X<sub>i</sub>) = 0 

>> ○ **假设 2.** (X<sub>i</sub>, Y<sub>i</sub>), i = 1, ···, n 为 i.i.d. 

>> ○ **假设 3.** X<sub>i</sub> 和 u<sub>i</sub> 具有非零有限四阶矩 

>> ○ **假设** **4.** 0 ＜ E(X<sub>i</sub>X<sub>i</sub><sup>t</sup>) ＜ ∞，不存在完美多重共线性 

> ③ OLS建模-简单版

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/ciffIj/btrusPh1yPr/8TDkB6RWHzhLGBgMK2FABk/img.jpg" alt="绘图" />

<br>

> ④ OLS建模

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/di1fx6/btrusNEuzrH/p3ct8xHDmN7NcOd7H9BFa0/img.jpg" alt="绘图" />

<br>

> ⑤ 一致性

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/qlY2T/btrusNYQpz5/DJLqmTK8jEkYXWUscuwcRK/img.png" alt="绘图" />

<br>

> ⑥多元中心极限定理

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/yHscL/btruyNwJT03/b0wQKJPZCozRGnBAClwdSK/img.png" alt="绘图" />

<br>

> ⑦ 渐近正态性

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/PgJrN/btrupIYia6G/pKsF33ydYfSCbKzXsRemsk/img.png" alt="绘图" />

<br>

> ⑧ 鲁棒标准误（Eicker-Huber-White 标准误）

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/bQa8mM/btrusPbgtk0/pqXIwzWx9L52769DX9RgI1/img.png" alt="绘图" />

<br>

> ⑨ 稳健的F

<br>

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/b6cnEv/btruolPLQli/GJdHH19uK7KB8RePsRk3k0/img.png" alt="绘图" />

<br>

---

*输入：2019.06.20 23:26*