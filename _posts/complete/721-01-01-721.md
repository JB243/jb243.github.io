## Dynamic Programming Example Problems [01-10]

Higher category: „ÄêAlgorithm„Äë [Algorithm and Machine Learning Index](https://jb243.github.io/pages/1278)

---

<br>

## Q1. 

Consider a rooted binary tree network. Each internal node x has two children, denoted by x(lhs) and x(rhs). The cost of moving from x to its child x(a) is l<sub>a</sub>, where a ‚àà {lhs,rhs}. For each node x, let L<sub>x</sub> be the minimum cost of any path from x to a leaf node. For each leaf node y, define L<sub>y</sub> = 0. Show that for any internal node x the following holds: 

<br>

<center>L<sub>x</sub> ‚Äã= min<sub>a‚àà{lhs,rhs}</sub> ‚Äã {l<sub>a</sub> + L<sub>x</sub>(a)}.</center>

## S1.

See [this link](https://www.youtube.com/watch?v=yzZVRXJ0d80&list=PLGboZ4litMr_TOwUANH-s-uFnczzy2uuW).

<br>

<br>

## Q2. 

An investor has a fund. It is worth x pounds at time zero, and the principal cannot be withdrawn. The fund pays interest at rate r √ó 100% per year for T years. At time t, the investor consumes a proportion a<sub>t</sub> of the interest and reinvests the rest in the fund. What choice of {a<sub>t</sub>} should the investor make in order to maximize total consumption?

## S2. 

See [this link](https://www.youtube.com/watch?v=VMjrzLld9W0&list=PLGboZ4litMr_TOwUANH-s-uFnczzy2uuW&index=3). The optimal policy is to save all income at first and then, once a certain threshold is reached, switch to consuming all of it.

<br>

<br>

## Q3. 

You want to sell a car. At each time (t = 0, ..., T-1), you choose a price p<sub>t</sub>, and then a customer comes and looks at the car. The probability that the customer buys the car at price p is D(p). If the car has not been sold by time T, it is sold for a fixed price W<sub>T</sub>, where W<sub>T</sub> < 1. Maximize the expected reward from selling the car, and find the recursion (dynamic programming / Bellman equation) for the optimal reward when D(p) = max(1 - p, 0).

## S3. 

See [this link](https://www.youtube.com/watch?v=d1VkSkt0EbY&list=PLGboZ4litMr_TOwUANH-s-uFnczzy2uuW&index=7). The expected reward becomes larger as t gets closer to 0, and the price p<sub>t</sub> at time t should be set as: 

<br>

<center>p<sub>t</sub> = ((expected gain at t+1) + 1‚Äã) / 2.</center>

<br>

<br>

## Q4. 

You own an expensive fish. Each day you are offered a price X for the fish, where X has probability density function f(x). You may either accept or reject the offer. With probability 1‚àíp the fish dies on that day. Find the policy that maximizes the expected profit from selling the fish.

## S4. 

See this [link](https://www.youtube.com/watch?v=oGodjYGcy5A&list=PLGboZ4litMr_TOwUANH-s-uFnczzy2uuW&index=8&pp=iAQB). This system shows a time-invariant characteristics. Thus, the Bellman equation is as follows:

<br>

<center>V<sub>t</sub>(x) = max{x, pùîº[V<sub>t+1</sub>(X<sub>t+1</sub> „Ö£ x)]} = max{x, pùîº[V<sub>t+1</sub>(X<sub>t+1</sub>)]} = max{x, a},</center>

<br>

where a is a constant. Therefore, the optimal policy is as follows: if x ‚â• a, buy it; otherwise, reject it. Here, we can obtain the following fixed-point equation

<br>

<center>a = ‚à´<sub>-‚àû to a</sub> af(y)dy + ‚à´<sub>a to ‚àû</sub> yf(y) dy ‚áî 0 = ‚à´<sub>a to ‚àû</sub> (y - a)f(y) dy.</center>

<br>

The LHS is fixed to zero, but the RHS is nonincreasing on a, so the fixed-point is unique.

<br>

<br>

## Q5. 

A gambler has ùëñ i pounds and wants to reach N pounds. At each play, the gambler may stake any integer amount j with 1 ‚â§ j ‚â§ i. The gambler wins with probability p and loses with probability q = 1‚àíp; if they win, they gain j pounds, and if they lose, they lose j pounds. The game ends when the gambler‚Äôs fortune reaches either 0 or N. Assuming that p > 1/2, argue that it is always optimal for the gambler to gamble 1 pound at a time. 

## S5. 

See this [link](https://www.youtube.com/watch?v=MHPRlItuTyA&list=PLGboZ4litMr_TOwUANH-s-uFnczzy2uuW&index=11). 

<br>

<center>V<sub>t</sub>(x) = max<sub>j</sub> {pùîº[V<sub>t+1</sub>(x+j)] + qùîº[V<sub>t+1</sub>(x-j)]} ‚Üí V(x) = max<sub>j</sub> {pùîº[V(x+j)] + qùîº[V(x-j)]} (‚àµ time-invariant)</center>

Note that R(i) = (1 - (q/p)<sup>i</sup>) / (1 - (q/p)<sup>N</sup>) is the solution of R(i) = pR(i-1) + qR(i+1), R(0) = 0, R(N) = 1. The given problem is more complex, but in the end, we obtain V(x) = R(x). Intuitively, if infinite time is allowed, the optimal policy is to invest the minimum unit to decrease the risk.

The function form can be obtained by assuming the linear sum of exponential functions. Let's suppose R<sub>1</sub>, R<sub>2</sub> be the solutions of R(i) = pR(i-1) + qR(i+1). Then, the difference of two functions, R<sub>1</sub> - R<sub>2</sub>, also satisfy the equation. This equation is similar to the internally dividing point in geometry, so we know R<sub>1</sub> ‚àí R<sub>2</sub> is always zero in the integer grid points considering the number of variables and equations. If we increase the number of integer grid points, we know R<sub>1</sub> - R<sub>2</sub> is identical to 0 for all the points in the given interval.

<br>

---

_Input: 2025.11.21 00:36_
