## Dynamic Programming Example Problems [01-10]

Higher category: 【Algorithm】 [Algorithm and Machine Learning Index](https://jb243.github.io/pages/1278)

---

<br>

## Q1. 

Consider a rooted binary tree network. Each internal node x has two children, denoted by x(lhs) and x(rhs). The cost of moving from x to its child x(a) is l<sub>a</sub>, where a ∈ {lhs,rhs}. For each node x, let L<sub>x</sub> be the minimum cost of any path from x to a leaf node. For each leaf node y, define L<sub>y</sub> = 0. Show that for any internal node x the following holds: 

L<sub>x</sub> ​= min<sub>a∈{lhs,rhs}</sub> ​ {l<sub>a</sub> + L<sub>x</sub>(a)}.

## S1.

See <https://www.youtube.com/watch?v=yzZVRXJ0d80&list=PLGboZ4litMr_TOwUANH-s-uFnczzy2uuW>

<br>

<br>

## Q2. 

An investor has a fund. It is worth x pounds at time zero, and the principal cannot be withdrawn. The fund pays interest at rate r × 100% per year for T years. At time t, the investor consumes a proportion a<sub>t</sub> of the interest and reinvests the rest in the fund. What choice of {a<sub>t</sub>} should the investor make in order to maximize total consumption?

## S2. 

See <https://www.youtube.com/watch?v=VMjrzLld9W0&list=PLGboZ4litMr_TOwUANH-s-uFnczzy2uuW&index=3>

The optimal policy is to save all income at first and then, once a certain threshold is reached, switch to consuming all of it.

<br>

<br>

## Q3. 

You want to sell a car. At each time (t = 0, ..., T-1), you choose a price p<sub>t</sub>, and then a customer comes and looks at the car. The probability that the customer buys the car at price p is D(p). If the car has not been sold by time T, it is sold for a fixed price W<sub>T</sub>, where W<sub>T</sub> < 1. Maximize the expected reward from selling the car, and find the recursion (dynamic programming / Bellman equation) for the optimal reward when D(p) = max(1 - p, 0).

## S3. 

See <https://www.youtube.com/watch?v=d1VkSkt0EbY&list=PLGboZ4litMr_TOwUANH-s-uFnczzy2uuW&index=7>

The expected reward becomes larger as t gets closer to 0, and the price p<sub>t</sub> at time t should be set as: p<sub>t</sub> = ((expected gain at t+1) + 1​) / 2.

<br>

---

_Input: 2025.11.21 00:36_
