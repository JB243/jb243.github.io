## **Lecture 3-3. Sigma Algebra**(σ-algebra)

Recommended post: 【Statistics】 Lecture 3. [Probability Space](https://jb243.github.io/pages/1623)

---

**1.** [Sigma Algebra](#1-sigma-algebra)

**2.** [Random Variable](#2-random-variable)

**3.** [Filtration](#3-filtration)

---

<br>

## **1. Sigma Algebra**

⑴ Probability Space (Ω, ℱ)

> ① Ω: Sample Space

> ② ℱ: Sigma Algebra (σ-algebra, event space), i.e., a collection of subsets of Ω

>> ○ **Example 1.** When Ω = {1, 2, 3}, the σ-algebra ℱ = {∅, Ω} corresponds to the case of knowing nothing

>> ○ **Example 2.** When Ω = {1, 2, 3}, the σ-algebra ℱ = {∅, {1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}, {1, 2, 3}, Ω} corresponds to the case of being able to see all events

>> ○ **Example 3.** When Ω = {1, 2, 3}, the σ-algebra ℱ = {∅, {1}, {2, 3}, Ω} represents an intermediate case

> ③ ω ∈ Ω: Realized sample. In a random process, it means a sample path.

⑵ Algebra

> ① **Condition 1.** non-empty: Ω ∈ ℱ or ∅ ∈ ℱ holds

> ② **Condition 2.** Closed under complement: If A ∈ ℱ, then A<sup>C</sup> = Ω - A ∈ ℱ also holds

>> ○ Considering together with the non-empty condition implies that ∅ and Ω must be elements of ℱ

> ③ **Condition 3.** Closed under finite union: If A, B ∈ ℱ, then A ∪ B ∈ ℱ also holds

>> ○ If A<sub>1</sub>, ⋯, A<sub>n</sub> ∈ ℱ, then ∪<sub>i</sub> A<sub>i</sub> = A<sub>1</sub> + ⋯ + A<sub>n</sub> ∈ ℱ also holds

⑶ Sigma Algebra (σ-algebra)

> ① Motivation: When the sample space is very large (e.g., Ω = ℝ), formal probability theory does not apply well (e.g., ℱ = 2<sup>Ω</sup>), so it is necessary to restrict ℱ to a sigma algebra. Related to Caratheodory’s extension theorem.

> ② **Condition 1.** Must be an algebra

> ③ **Condition 2.** Closed under **countably infinite** unions: For A<sub>i</sub> ∈ ℱ, ∪<sub>i</sub> A<sub>i</sub> = A<sub>1</sub> + ⋯ + A<sub>∞</sub> ∈ ℱ

> ④ Intuitive meaning of sigma algebra

>> ○ A collection of subsets on a non-empty set Ω

>> ○ The set of all events to which probability can be assigned

>> ○ The set of all functions/random variables that can be generated

> ⑤ σ-algebras can vary in size

>> ○ Trivial σ-algebra: {∅, ℝ} (smallest)

>> ○ σ(𝒜): The smallest σ-algebra containing all elements of 𝒜, i.e., generated by 𝒜

>> ○ Borel σ-algebra: ℬ(ℝ) (the smallest σ-algebra containing **all open sets**)

>> ○ Countable/co-countable σ-algebra: the collection of sets that are countable or co-countable

>> ○ Power-set σ-algebra: 𝒫(ℝ) (largest)

>> ○ σ-algebra of Lebesgue measurable sets: ℒ (larger than Borel; a prototypical “completion”)

>> ○ Intersections of σ-algebras are again σ-algebras.

> ⑥ Borel σ-algebra: The smallest sigma algebra containing **all open sets**

>> ○ Ω = ℝ, ℱ = ℬ(ℝ)

>> ○ Using the properties of sigma algebra, open intervals → closed intervals, half-open intervals, singletons {x}, [1,3] ∪ [4,5] are also included in the Borel algebra

>> ○ Complicated sets like the set of rationals and irrationals are also Borel sets

>> ○ More complex sets obtained by countably many unions, differences, or intersections of intervals are all Borel sets

>> ○ Not limited only to ℝ; can be defined for any topological space X: for example, on [0,1], on ℝ<sup>n</sup>, or on any general topological space, each has its own Borel σ-algebra

>> ○ In fact, there exist sets such as Lebesgue non-measurable sets that cannot be made by the Borel σ-algebra: related to uncountable infinity

<br>

<br>

## **2. Random Variable**

⑴ Probability Distribution

> ① A function that assigns values to elements of ℱ, i.e., ℙ: ℱ ↦ [0, 1]

> ② **Condition 1.** ℙ(Ω) = 1

> ③ **Condition 2.** For countably infinite, mutually exclusive {A<sub>i</sub>}<sub>i∈ℕ</sub>, ℙ(A<sub>1</sub> + ⋯ + A<sub>∞</sub>) = ℙ(A<sub>1</sub>) + ⋯ + ℙ(A<sub>∞</sub>)

>> ○ Disjoint: A<sub>i</sub> ∩ A<sub>j</sub> = ∅

⑵ Random Variable (measurable function): Linking events to values

> ① **Expression 1.** If there exists a function X such that <sup>∀</sup>B ∈ ℬ(ℝ), X<sup>-1</sup>(B) ∈ ℱ (measurable), then that function is called a random variable

> ② **Expression 2.** X: Ω → ℝ is a random variable ⇔ X<sup>-1</sup>(A) = {ω ∈ Ω: X(ω) ∈ A} ∈ ℱ ∀ A ∈ ℬ(ℝ)

>> ○ **Meaning 1.** Existence of inverse image: i.e., ℬ(ℝ) is **ℱ-measurable**. If X is continuous, this usually holds.

>> ○ **Meaning 2.** Existence of range of inverse image: i.e., the inverse image’s range is a subset of ℱ

>> ○ ℱ can be viewed as equivalent to the collection of all random variables (or functions) measurable with respect to it

>> ○ Example: ℙ<sub>X</sub>(x ∈ A) = ℙ(X<sup>-1</sup>(A))

> ③ **Expression 3.** X is measurable ⇔ ∀a ∈ ℝ, {ω : X(ω) ≤ a} ∈ ℱ

> ④ Precise distinction between a random variable and "measurable"

>> ○ Measurable can be defined without a measure: it only requires the pairs (Ω, ℱ) and (ℝ, 𝒢). In practice, we usually take 𝒢 = ℬ(ℝ).

>> ○ A random variable is a measurable function on a probability space, i.e., with the measure ℙ included.

> ⑤ **Example 1.** Bernoulli distribution 

>> ○ Domain = Ω = {Head, Tail}

>> ○ ℱ = 2<sup>Ω</sup> = {∅, {Head}, {Tail}, {Head, Tail}}

>> ○ Codomain = {0, 1}

>> ○ 𝒢 = 2<sup>Codomain</sup> = {∅, {0}, {1}, {0, 1}}

>> ○ As there is an element of ℱ corresponding to an arbitrary element of 𝒢, X : Ω → {0, 1} is measurable.

> ⑥ **Example 2.** An example of a function which is not measurable

>> ○ Ω = [0, 1], ℱ = {∅, [0, 1]}

>> ○ 𝒢 = ℬ(ℝ) contains [0, 1/2], but there is no element of ℱ corresponding to this.

>> ○ Thus, X : (Ω, ℱ) → (ℝ, 𝒢) is not measurable. Specifically, it is called "not ℱ-measurable", and ℱ needs more information.

> ⑦ General measurable space

>> ○ Definition: If X: Ω → Ω<sub>1</sub> between two measurable spaces (Ω, ℱ) and (Ω<sub>1</sub>, ℱ<sub>1</sub>) satisfies the following condition, then X is called a random variable

<br>

<img width="297" height="28" alt="스크린샷 2025-10-05 오전 10 57 03" src="https://github.com/user-attachments/assets/a4a4364d-ee6e-4c56-9c6f-adbab0387a7a" />

<br>

> ⑧ Random Process (stochastic process)

>> ○ Definition: X: ℐ × Ω ↦ E, where for each i ∈ ℐ, there exists a random variable X(i, **·**): Ω ↦ E

⑶ π-class and λ-class

> ① Definition of π-class: If A, B ∈ 𝒞 ⊂ 2<sup>Ω</sup>, then A ∩ B ∈ 𝒞

> ② Definition of λ-class

<br>

<img width="453" height="133" alt="스크린샷 2025-10-05 오전 10 57 40" src="https://github.com/user-attachments/assets/631065f2-c2e0-4dab-87d8-048b385082ed" />

<br>

> ③ Property of λ-class

<br>

<img width="505" height="133" alt="스크린샷 2025-10-05 오전 10 57 59" src="https://github.com/user-attachments/assets/8810852d-203c-4c94-a0e7-a0863110a39c" />

<br>

> ④ Dynkin's theorem: If 𝒟 is a π-class, 𝒞 is a λ-class, and 𝒟 ⊂ 𝒞, then σ(𝒟) ⊂ 𝒞

⑷ Stationary

> ① Strictly stationary

<br>

<img width="400" height="60" alt="스크린샷 2025-10-05 오전 10 58 21" src="https://github.com/user-attachments/assets/2025080f-9080-4187-9e4d-019b62c260e7" />

<br>

> ② Wide-sense stationary: Strictly stationary is also wide-sense stationary

<br>

<img width="404" height="63" alt="스크린샷 2025-10-05 오전 10 58 45" src="https://github.com/user-attachments/assets/12f06f0d-c95d-4b45-8aeb-2f2cb7e1ed03" />

<br>

⑸ Independence

> ① Definition of independence using joint distribution: ℙ(X<sub>1</sub> ∈ B<sub>1</sub>, X<sub>2</sub> ∈ B<sub>2</sub>) = ℙ(X<sub>1</sub> ∈ B<sub>1</sub>) ℙ(X<sub>2</sub> ∈ B<sub>2</sub>) ∀B<sub>1</sub>, B<sub>2</sub> ∈ ℬ(ℝ)

> ② Definition of independence using moments

> ③ Definition of independence using moment generating function

> ④ Definition of independence using σ-algebra: σ(x<sub>1</sub>) and σ(x<sub>2</sub>) are independent (where σ(X) = {X<sup>-1</sup>(A): A ∈ ℬ(ℝ)})

<br>

<img width="202" height="106" alt="스크린샷 2025-10-05 오전 11 00 03" src="https://github.com/user-attachments/assets/f4819f7a-74d7-44a7-ab66-14dc18a2701e" />

<br>

⑹ Markov Process

> ① Bayes' Rule: ℙ(A <span>|</span> B) = ℙ(A ∩ B) / ℙ(B) if ℙ(B) > 0

> ② Conditional expectation 𝔼[X <span>|</span> 𝒢]

> ③ Markov process: ∀A ∈ 𝓔, ℙ(X<sub>i<sub>n</sub></sub> ∈ A <span>|</span> X<sub>i<sub>1</sub></sub>, X<sub>i<sub>2</sub></sub>, ⋯, X<sub>i<sub>n-1</sub></sub>) = ℙ(X<sub>i<sub>n</sub></sub> ∈ A <span>|</span> X<sub>i<sub>n-1</sub></sub>), i.e., the current state depends only on the immediately preceding state

<br>

<br>

## **3. Filtration**

⑴ **Doob's Theorem**

> ① σ(X<sub>1</sub>, X<sub>2</sub>, ···, X<sub>n</sub>): The smallest σ-algebra making X<sub>1</sub>, X<sub>2</sub>, ···, X<sub>n</sub> measurable

> ② Doob's Theorem: σ(X<sub>1</sub>, X<sub>2</sub>, ···, X<sub>n</sub>) is equivalent to the collection of all functions of the form g(X<sub>1</sub>, X<sub>2</sub>, ···, X<sub>n</sub>)

> ③ The larger the σ-algebra, the greater the number of measurable functions with respect to it — i.e., more information

⑵ Filtration

> ① A collection of σ-algebras arranged in an increasing order by inclusion

> ② Ordered by ⊆, and if ℱ<sub>1</sub> ⊆ ℱ<sub>2</sub>, then ℱ<sub>2</sub> is after ℱ<sub>1</sub>

> ③ For convenience, with time index t = 0, 1, 2, ⋯, filtration is {ℱ<sub>t</sub>}<sub>t∈ℤ<sup>+</sup></sub>, satisfying ℱ<sub>s</sub> ⊆ ℱ<sub>t</sub> for all s ≤ t

> ④ Intuitive meaning: Represents a situation where information increases as time passes and observations accumulate

⑶ **Martingale**

> ① Property of conditional expectation

>> ○ For any random variable Y, 𝔼[Y <span>|</span> X<sub>1</sub>, ···, X<sub>n</sub>] = 𝔼[Y <span>|</span> σ(X<sub>1</sub>, ···, X<sub>n</sub>)] holds

>> ○ Reason: σ(X<sub>1</sub>, ···, X<sub>n</sub>) is equivalent to the set of all functions generated by X<sub>1</sub>, ···, X<sub>n</sub>

> ② Martingale: A stochastic process {X<sub>t</sub>}<sub>t∈ℤ<sup>+</sup></sub> adapted to filtration {ℱ<sub>t</sub>}<sub>t∈ℤ<sup>+</sup></sub> satisfies all the following conditions

>> ○ **Condition 1.** For all t ∈ ℤ<sup>+</sup>, X<sub>t</sub> is ℱ<sub>t</sub>-measurable

>>> ○ If s ≤ t ≤ s', ℱ<sub>s</sub> ⊆ ℱ<sub>t</sub> ⊆ ℱ<sub>s'</sub>, x<sub>t</sub> ∈ ℱ<sub>t</sub> is not ℱ<sub>s</sub>-measurable (∵ lack of information), but ℱ<sub>s'</sub>-measurable.

>> ○ **Condition 2.** For all t ∈ ℤ<sup>+</sup>, 𝔼[<span>|</span>X<sub>t</sub><span>|</span>] is finite

>> ○ **Condition 3.** For all t ∈ ℤ<sup>+</sup>, 𝔼[X<sub>t</sub> <span>|</span> ℱ<sub>s</sub>] = X<sub>s</sub>, almost surely for all s ≤ t

>>> ○ **Interpretation:** Given only the information up to time s (ℱ<sub>s</sub>), the optimal prediction of X<sub>t</sub> equals X<sub>s</sub> (i.e., the prediction is constrained to X<sub>s</sub>).

>>> ○ **Remark:** The martingale property is needed only when predicting the future from the past. In particular, for s > t we have 𝔼[X<sub>t</sub> ㅣ ℱ<sub>s</sub>] = X<sub>t</sub> regardless of whether (X<sub>t</sub>) is a martingale (assuming integrability).

>>> ○ For s < t, 𝔼[X<sub>s</sub> ㅣ ℱ<sub>t</sub>] = Xs also holds, because X<sub>s</sub> is ℱ<sub>s</sub>-measurable, but has insufficient information due to ℱ<sub>s</sub> ⊆ ℱ<sub>t</sub>.

> ③ Note: An i.i.d. process is generally not a martingale (except when it is a constant process)

<br>

---

_Input: 2025.09.07 08:40_
